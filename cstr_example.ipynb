{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "\n",
    "from models import NN, NNOPT\n",
    "from utils import load_data, get_scaledABb, Data_cstr, PINNLoss, Data_plant, Data_distillation\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 3\n",
    "hidden_dim = 12\n",
    "hidden_num = 1\n",
    "z0_dim = 3\n",
    "epochs = 1000\n",
    "batch_size = 16\n",
    "lr = 1e-4\n",
    "eta = 1\n",
    "val_ratio = 0.2\n",
    "dataset_path = 'benchmark_CSTR.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.9073e-06,  0.0000e+00,  0.0000e+00,  7.6294e-06,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  7.6294e-06,  0.0000e+00]])\n",
      "tensor([0., 0.])\n"
     ]
    }
   ],
   "source": [
    "dataset_arr, scaler = load_data(dataset_path)\n",
    "Data_class = Data_cstr\n",
    "\n",
    "params = {'batch_size': batch_size,\n",
    "              'shuffle': True}\n",
    "dataset = Data_class(dataset_arr)\n",
    "dataset.resplit_data(val_ratio)\n",
    "\n",
    "A, B, b = get_scaledABb(dataset.A, dataset.B, dataset.b, scaler)\n",
    "print((torch.mm(A, dataset.X.T.float()) + torch.mm(B, dataset.Y.T.float()))[:, :5])\n",
    "print(b)\n",
    "\n",
    "train_loader = data.DataLoader(dataset.train_set, **params)\n",
    "val_loader = data.DataLoader(dataset.val_set, **params)\n",
    "test_loader = data.DataLoader(dataset.test_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_model = NN(input_dim, hidden_dim, hidden_num, z0_dim)\n",
    "PINN_model = NN(input_dim, hidden_dim, hidden_num, z0_dim)\n",
    "NNOPT_model = NNOPT(input_dim, hidden_dim, hidden_num, z0_dim, A, B, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, loss_func):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_violation = 0\n",
    "    expanded_b = b.unsqueeze(1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (X, Y) in enumerate(test_loader):\n",
    "            pred = model(X)\n",
    "            pred_diff = torch.mm(A, X.T.float()) + \\\n",
    "                        torch.mm(B, pred.T.float()) - \\\n",
    "                        expanded_b.repeat(1, X.T.shape[1])\n",
    "            if isinstance(loss_func, PINNLoss):\n",
    "                test_loss += nn.MSELoss()(pred, Y).item()  # return and record the MSE loss for comparison\n",
    "            elif isinstance(loss_func, nn.MSELoss):\n",
    "                test_loss += loss_func(pred, Y).item()\n",
    "            else:\n",
    "                raise ValueError('Loss function not supported!')\n",
    "            test_violation += torch.abs(pred_diff.view(-1)).mean()\n",
    "    test_loss /= len(test_loader.dataset)  # Test set Average loss\n",
    "    test_violation /= len(test_loader.dataset)  # Test set Average violation\n",
    "    return test_loss, test_violation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, loss_func):\n",
    "    expanded_b = b.unsqueeze(1)\n",
    "    t_total = time.time()\n",
    "    print('Start Training...')\n",
    "    min_loss = 123456789\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_violations = []\n",
    "    val_violations = []\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        t = time.time()\n",
    "        print('-------- Epoch ' + str(epoch + 1) + ' --------')\n",
    "\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_violation = 0\n",
    "        for batch_idx, (X, Y) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(X)\n",
    "            pred_diff = torch.mm(A, X.T.float()) + \\\n",
    "                        torch.mm(B, pred.T.float()) - \\\n",
    "                        expanded_b.repeat(1, X.T.shape[1])\n",
    "\n",
    "            if isinstance(loss_func, PINNLoss):\n",
    "                loss = loss_func(X, pred, Y)\n",
    "                loss2record = nn.MSELoss()(pred, Y)\n",
    "                train_loss += loss2record.item()\n",
    "            elif isinstance(loss_func, nn.MSELoss):\n",
    "                loss = loss_func(pred, Y)\n",
    "                train_loss += loss.item()\n",
    "            else:\n",
    "                raise ValueError('Loss function not supported!')\n",
    "\n",
    "            train_violation += torch.abs(pred_diff.view(-1)).mean()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_violation /= len(train_loader.dataset)\n",
    "        val_loss, val_violation = test(model, val_loader, loss_func)\n",
    "        train_losses.append(train_loss), train_violations.append(train_violation.detach().item())\n",
    "        val_losses.append(val_loss), val_violations.append(val_violation.detach().item())\n",
    "\n",
    "        if np.mean(val_loss) < min_loss:\n",
    "            model_max = copy.deepcopy(model)\n",
    "            min_loss = np.mean(val_losses[-1])\n",
    "            # torch.save(model, path)\n",
    "        print('epoch: {:05d}'.format(epoch + 1),\n",
    "              'loss_train: {:.5f}'.format(train_loss),\n",
    "              'loss_val: {:.5f}'.format(val_loss),\n",
    "              'violation_train: {:.5f}'.format(train_violation),\n",
    "              'violation_val: {:.5f}'.format(val_violation),\n",
    "              'time: {:.4f}s'.format(time.time() - t))\n",
    "    print(\"Optimization Finished!\")\n",
    "    print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "    return train_losses, val_losses, train_violations, val_violations, model_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "-------- Epoch 1 --------\n",
      "epoch: 00001 loss_train: 0.00540 loss_val: 0.00582 violation_train: 1.87260 violation_val: 1.98222 time: 0.0570s\n",
      "-------- Epoch 2 --------\n",
      "epoch: 00002 loss_train: 0.00501 loss_val: 0.00542 violation_train: 1.81229 violation_val: 1.91614 time: 0.0501s\n",
      "-------- Epoch 3 --------\n",
      "epoch: 00003 loss_train: 0.00473 loss_val: 0.00510 violation_train: 1.76044 violation_val: 1.87692 time: 0.0493s\n",
      "-------- Epoch 4 --------\n",
      "epoch: 00004 loss_train: 0.00449 loss_val: 0.00492 violation_train: 1.71225 violation_val: 1.82973 time: 0.0513s\n",
      "-------- Epoch 5 --------\n",
      "epoch: 00005 loss_train: 0.00428 loss_val: 0.00469 violation_train: 1.66359 violation_val: 1.78546 time: 0.0492s\n",
      "-------- Epoch 6 --------\n",
      "epoch: 00006 loss_train: 0.00410 loss_val: 0.00460 violation_train: 1.61537 violation_val: 1.76561 time: 0.0483s\n",
      "-------- Epoch 7 --------\n",
      "epoch: 00007 loss_train: 0.00392 loss_val: 0.00435 violation_train: 1.56405 violation_val: 1.66760 time: 0.0483s\n",
      "-------- Epoch 8 --------\n",
      "epoch: 00008 loss_train: 0.00375 loss_val: 0.00418 violation_train: 1.50724 violation_val: 1.59246 time: 0.0505s\n",
      "-------- Epoch 9 --------\n",
      "epoch: 00009 loss_train: 0.00354 loss_val: 0.00381 violation_train: 1.43208 violation_val: 1.50965 time: 0.0533s\n",
      "-------- Epoch 10 --------\n",
      "epoch: 00010 loss_train: 0.00332 loss_val: 0.00355 violation_train: 1.34028 violation_val: 1.41047 time: 0.0577s\n",
      "-------- Epoch 11 --------\n",
      "epoch: 00011 loss_train: 0.00313 loss_val: 0.00339 violation_train: 1.25742 violation_val: 1.32999 time: 0.0566s\n",
      "-------- Epoch 12 --------\n",
      "epoch: 00012 loss_train: 0.00296 loss_val: 0.00333 violation_train: 1.17632 violation_val: 1.23595 time: 0.0496s\n",
      "-------- Epoch 13 --------\n",
      "epoch: 00013 loss_train: 0.00281 loss_val: 0.00302 violation_train: 1.09570 violation_val: 1.14887 time: 0.0488s\n",
      "-------- Epoch 14 --------\n",
      "epoch: 00014 loss_train: 0.00267 loss_val: 0.00293 violation_train: 1.01844 violation_val: 1.07327 time: 0.0487s\n",
      "-------- Epoch 15 --------\n",
      "epoch: 00015 loss_train: 0.00255 loss_val: 0.00287 violation_train: 0.94678 violation_val: 0.99629 time: 0.0492s\n",
      "-------- Epoch 16 --------\n",
      "epoch: 00016 loss_train: 0.00244 loss_val: 0.00268 violation_train: 0.87748 violation_val: 0.90695 time: 0.0479s\n",
      "-------- Epoch 17 --------\n",
      "epoch: 00017 loss_train: 0.00234 loss_val: 0.00257 violation_train: 0.80848 violation_val: 0.84005 time: 0.0489s\n",
      "-------- Epoch 18 --------\n",
      "epoch: 00018 loss_train: 0.00224 loss_val: 0.00250 violation_train: 0.74241 violation_val: 0.77033 time: 0.0484s\n",
      "-------- Epoch 19 --------\n",
      "epoch: 00019 loss_train: 0.00215 loss_val: 0.00235 violation_train: 0.68099 violation_val: 0.70085 time: 0.0476s\n",
      "-------- Epoch 20 --------\n",
      "epoch: 00020 loss_train: 0.00207 loss_val: 0.00227 violation_train: 0.62343 violation_val: 0.64241 time: 0.0471s\n",
      "-------- Epoch 21 --------\n",
      "epoch: 00021 loss_train: 0.00199 loss_val: 0.00225 violation_train: 0.57288 violation_val: 0.58431 time: 0.0477s\n",
      "-------- Epoch 22 --------\n",
      "epoch: 00022 loss_train: 0.00192 loss_val: 0.00211 violation_train: 0.52312 violation_val: 0.53574 time: 0.0478s\n",
      "-------- Epoch 23 --------\n",
      "epoch: 00023 loss_train: 0.00185 loss_val: 0.00201 violation_train: 0.47837 violation_val: 0.48216 time: 0.0481s\n",
      "-------- Epoch 24 --------\n",
      "epoch: 00024 loss_train: 0.00178 loss_val: 0.00200 violation_train: 0.43801 violation_val: 0.44506 time: 0.0476s\n",
      "-------- Epoch 25 --------\n",
      "epoch: 00025 loss_train: 0.00172 loss_val: 0.00192 violation_train: 0.40107 violation_val: 0.40697 time: 0.0472s\n",
      "-------- Epoch 26 --------\n",
      "epoch: 00026 loss_train: 0.00167 loss_val: 0.00189 violation_train: 0.36715 violation_val: 0.37414 time: 0.0477s\n",
      "-------- Epoch 27 --------\n",
      "epoch: 00027 loss_train: 0.00162 loss_val: 0.00181 violation_train: 0.33671 violation_val: 0.33630 time: 0.0475s\n",
      "-------- Epoch 28 --------\n",
      "epoch: 00028 loss_train: 0.00158 loss_val: 0.00178 violation_train: 0.30722 violation_val: 0.30690 time: 0.0483s\n",
      "-------- Epoch 29 --------\n",
      "epoch: 00029 loss_train: 0.00154 loss_val: 0.00172 violation_train: 0.28074 violation_val: 0.28507 time: 0.0473s\n",
      "-------- Epoch 30 --------\n",
      "epoch: 00030 loss_train: 0.00150 loss_val: 0.00171 violation_train: 0.25755 violation_val: 0.25812 time: 0.0472s\n",
      "-------- Epoch 31 --------\n",
      "epoch: 00031 loss_train: 0.00147 loss_val: 0.00164 violation_train: 0.23622 violation_val: 0.23601 time: 0.0468s\n",
      "-------- Epoch 32 --------\n",
      "epoch: 00032 loss_train: 0.00143 loss_val: 0.00164 violation_train: 0.21389 violation_val: 0.21700 time: 0.0478s\n",
      "-------- Epoch 33 --------\n",
      "epoch: 00033 loss_train: 0.00140 loss_val: 0.00158 violation_train: 0.19695 violation_val: 0.20310 time: 0.0475s\n",
      "-------- Epoch 34 --------\n",
      "epoch: 00034 loss_train: 0.00138 loss_val: 0.00160 violation_train: 0.18122 violation_val: 0.18857 time: 0.0476s\n",
      "-------- Epoch 35 --------\n",
      "epoch: 00035 loss_train: 0.00135 loss_val: 0.00152 violation_train: 0.16730 violation_val: 0.17011 time: 0.0487s\n",
      "-------- Epoch 36 --------\n",
      "epoch: 00036 loss_train: 0.00133 loss_val: 0.00151 violation_train: 0.15361 violation_val: 0.16450 time: 0.0490s\n",
      "-------- Epoch 37 --------\n",
      "epoch: 00037 loss_train: 0.00130 loss_val: 0.00146 violation_train: 0.14305 violation_val: 0.14901 time: 0.0480s\n",
      "-------- Epoch 38 --------\n",
      "epoch: 00038 loss_train: 0.00128 loss_val: 0.00152 violation_train: 0.13379 violation_val: 0.14004 time: 0.0476s\n",
      "-------- Epoch 39 --------\n",
      "epoch: 00039 loss_train: 0.00126 loss_val: 0.00144 violation_train: 0.12496 violation_val: 0.13453 time: 0.0476s\n",
      "-------- Epoch 40 --------\n",
      "epoch: 00040 loss_train: 0.00124 loss_val: 0.00141 violation_train: 0.11630 violation_val: 0.13053 time: 0.0508s\n",
      "-------- Epoch 41 --------\n",
      "epoch: 00041 loss_train: 0.00122 loss_val: 0.00137 violation_train: 0.11218 violation_val: 0.12053 time: 0.0482s\n",
      "-------- Epoch 42 --------\n",
      "epoch: 00042 loss_train: 0.00119 loss_val: 0.00137 violation_train: 0.10656 violation_val: 0.11393 time: 0.0480s\n",
      "-------- Epoch 43 --------\n",
      "epoch: 00043 loss_train: 0.00117 loss_val: 0.00132 violation_train: 0.10128 violation_val: 0.10862 time: 0.0486s\n",
      "-------- Epoch 44 --------\n",
      "epoch: 00044 loss_train: 0.00115 loss_val: 0.00132 violation_train: 0.09754 violation_val: 0.10514 time: 0.0524s\n",
      "-------- Epoch 45 --------\n",
      "epoch: 00045 loss_train: 0.00114 loss_val: 0.00129 violation_train: 0.09459 violation_val: 0.10492 time: 0.0523s\n",
      "-------- Epoch 46 --------\n",
      "epoch: 00046 loss_train: 0.00111 loss_val: 0.00136 violation_train: 0.09194 violation_val: 0.10740 time: 0.0539s\n",
      "-------- Epoch 47 --------\n",
      "epoch: 00047 loss_train: 0.00109 loss_val: 0.00123 violation_train: 0.09173 violation_val: 0.09899 time: 0.0537s\n",
      "-------- Epoch 48 --------\n",
      "epoch: 00048 loss_train: 0.00108 loss_val: 0.00126 violation_train: 0.09054 violation_val: 0.09895 time: 0.0513s\n",
      "-------- Epoch 49 --------\n",
      "epoch: 00049 loss_train: 0.00106 loss_val: 0.00125 violation_train: 0.08882 violation_val: 0.10133 time: 0.0514s\n",
      "-------- Epoch 50 --------\n",
      "epoch: 00050 loss_train: 0.00104 loss_val: 0.00124 violation_train: 0.08860 violation_val: 0.09781 time: 0.0515s\n",
      "-------- Epoch 51 --------\n",
      "epoch: 00051 loss_train: 0.00102 loss_val: 0.00118 violation_train: 0.08812 violation_val: 0.09904 time: 0.0531s\n",
      "-------- Epoch 52 --------\n",
      "epoch: 00052 loss_train: 0.00100 loss_val: 0.00113 violation_train: 0.08875 violation_val: 0.09729 time: 0.0513s\n",
      "-------- Epoch 53 --------\n",
      "epoch: 00053 loss_train: 0.00098 loss_val: 0.00110 violation_train: 0.08883 violation_val: 0.09695 time: 0.0477s\n",
      "-------- Epoch 54 --------\n",
      "epoch: 00054 loss_train: 0.00095 loss_val: 0.00109 violation_train: 0.08943 violation_val: 0.09913 time: 0.0481s\n",
      "-------- Epoch 55 --------\n",
      "epoch: 00055 loss_train: 0.00094 loss_val: 0.00107 violation_train: 0.09040 violation_val: 0.09709 time: 0.0496s\n",
      "-------- Epoch 56 --------\n",
      "epoch: 00056 loss_train: 0.00092 loss_val: 0.00103 violation_train: 0.09021 violation_val: 0.09917 time: 0.0511s\n",
      "-------- Epoch 57 --------\n",
      "epoch: 00057 loss_train: 0.00090 loss_val: 0.00104 violation_train: 0.09078 violation_val: 0.10017 time: 0.0527s\n",
      "-------- Epoch 58 --------\n",
      "epoch: 00058 loss_train: 0.00088 loss_val: 0.00099 violation_train: 0.09165 violation_val: 0.10093 time: 0.0530s\n",
      "-------- Epoch 59 --------\n",
      "epoch: 00059 loss_train: 0.00086 loss_val: 0.00097 violation_train: 0.09266 violation_val: 0.10121 time: 0.0527s\n",
      "-------- Epoch 60 --------\n",
      "epoch: 00060 loss_train: 0.00084 loss_val: 0.00095 violation_train: 0.09345 violation_val: 0.10203 time: 0.0493s\n",
      "-------- Epoch 61 --------\n",
      "epoch: 00061 loss_train: 0.00082 loss_val: 0.00094 violation_train: 0.09361 violation_val: 0.10321 time: 0.0487s\n",
      "-------- Epoch 62 --------\n",
      "epoch: 00062 loss_train: 0.00080 loss_val: 0.00092 violation_train: 0.09476 violation_val: 0.10150 time: 0.0489s\n",
      "-------- Epoch 63 --------\n",
      "epoch: 00063 loss_train: 0.00079 loss_val: 0.00097 violation_train: 0.09562 violation_val: 0.10556 time: 0.0480s\n",
      "-------- Epoch 64 --------\n",
      "epoch: 00064 loss_train: 0.00077 loss_val: 0.00087 violation_train: 0.09625 violation_val: 0.10487 time: 0.0480s\n",
      "-------- Epoch 65 --------\n",
      "epoch: 00065 loss_train: 0.00075 loss_val: 0.00087 violation_train: 0.09727 violation_val: 0.10622 time: 0.0480s\n",
      "-------- Epoch 66 --------\n",
      "epoch: 00066 loss_train: 0.00074 loss_val: 0.00084 violation_train: 0.09748 violation_val: 0.10702 time: 0.0474s\n",
      "-------- Epoch 67 --------\n",
      "epoch: 00067 loss_train: 0.00072 loss_val: 0.00082 violation_train: 0.09842 violation_val: 0.10791 time: 0.0477s\n",
      "-------- Epoch 68 --------\n",
      "epoch: 00068 loss_train: 0.00070 loss_val: 0.00080 violation_train: 0.09936 violation_val: 0.11003 time: 0.0475s\n",
      "-------- Epoch 69 --------\n",
      "epoch: 00069 loss_train: 0.00069 loss_val: 0.00080 violation_train: 0.09957 violation_val: 0.10672 time: 0.0475s\n",
      "-------- Epoch 70 --------\n",
      "epoch: 00070 loss_train: 0.00067 loss_val: 0.00083 violation_train: 0.10089 violation_val: 0.10932 time: 0.0475s\n",
      "-------- Epoch 71 --------\n",
      "epoch: 00071 loss_train: 0.00066 loss_val: 0.00074 violation_train: 0.10154 violation_val: 0.10879 time: 0.0483s\n",
      "-------- Epoch 72 --------\n",
      "epoch: 00072 loss_train: 0.00065 loss_val: 0.00074 violation_train: 0.10145 violation_val: 0.11209 time: 0.0489s\n",
      "-------- Epoch 73 --------\n",
      "epoch: 00073 loss_train: 0.00063 loss_val: 0.00072 violation_train: 0.10245 violation_val: 0.10892 time: 0.0476s\n",
      "-------- Epoch 74 --------\n",
      "epoch: 00074 loss_train: 0.00062 loss_val: 0.00070 violation_train: 0.10258 violation_val: 0.11016 time: 0.0479s\n",
      "-------- Epoch 75 --------\n",
      "epoch: 00075 loss_train: 0.00061 loss_val: 0.00072 violation_train: 0.10314 violation_val: 0.11014 time: 0.0477s\n",
      "-------- Epoch 76 --------\n",
      "epoch: 00076 loss_train: 0.00059 loss_val: 0.00068 violation_train: 0.10327 violation_val: 0.11422 time: 0.0476s\n",
      "-------- Epoch 77 --------\n",
      "epoch: 00077 loss_train: 0.00058 loss_val: 0.00066 violation_train: 0.10420 violation_val: 0.11008 time: 0.0474s\n",
      "-------- Epoch 78 --------\n",
      "epoch: 00078 loss_train: 0.00057 loss_val: 0.00066 violation_train: 0.10397 violation_val: 0.11078 time: 0.0474s\n",
      "-------- Epoch 79 --------\n",
      "epoch: 00079 loss_train: 0.00056 loss_val: 0.00063 violation_train: 0.10431 violation_val: 0.10819 time: 0.0478s\n",
      "-------- Epoch 80 --------\n",
      "epoch: 00080 loss_train: 0.00055 loss_val: 0.00062 violation_train: 0.10442 violation_val: 0.11164 time: 0.0477s\n",
      "-------- Epoch 81 --------\n",
      "epoch: 00081 loss_train: 0.00054 loss_val: 0.00062 violation_train: 0.10505 violation_val: 0.10920 time: 0.0484s\n",
      "-------- Epoch 82 --------\n",
      "epoch: 00082 loss_train: 0.00053 loss_val: 0.00061 violation_train: 0.10495 violation_val: 0.11243 time: 0.0477s\n",
      "-------- Epoch 83 --------\n",
      "epoch: 00083 loss_train: 0.00052 loss_val: 0.00061 violation_train: 0.10623 violation_val: 0.11085 time: 0.0473s\n",
      "-------- Epoch 84 --------\n",
      "epoch: 00084 loss_train: 0.00051 loss_val: 0.00057 violation_train: 0.10540 violation_val: 0.11195 time: 0.0479s\n",
      "-------- Epoch 85 --------\n",
      "epoch: 00085 loss_train: 0.00050 loss_val: 0.00056 violation_train: 0.10529 violation_val: 0.10998 time: 0.0482s\n",
      "-------- Epoch 86 --------\n",
      "epoch: 00086 loss_train: 0.00050 loss_val: 0.00060 violation_train: 0.10559 violation_val: 0.11250 time: 0.0474s\n",
      "-------- Epoch 87 --------\n",
      "epoch: 00087 loss_train: 0.00049 loss_val: 0.00055 violation_train: 0.10540 violation_val: 0.11202 time: 0.0478s\n",
      "-------- Epoch 88 --------\n",
      "epoch: 00088 loss_train: 0.00048 loss_val: 0.00056 violation_train: 0.10505 violation_val: 0.11183 time: 0.0469s\n",
      "-------- Epoch 89 --------\n",
      "epoch: 00089 loss_train: 0.00047 loss_val: 0.00052 violation_train: 0.10477 violation_val: 0.10999 time: 0.0475s\n",
      "-------- Epoch 90 --------\n",
      "epoch: 00090 loss_train: 0.00047 loss_val: 0.00051 violation_train: 0.10499 violation_val: 0.10889 time: 0.0482s\n",
      "-------- Epoch 91 --------\n",
      "epoch: 00091 loss_train: 0.00046 loss_val: 0.00050 violation_train: 0.10551 violation_val: 0.10892 time: 0.0475s\n",
      "-------- Epoch 92 --------\n",
      "epoch: 00092 loss_train: 0.00045 loss_val: 0.00052 violation_train: 0.10436 violation_val: 0.10977 time: 0.0468s\n",
      "-------- Epoch 93 --------\n",
      "epoch: 00093 loss_train: 0.00045 loss_val: 0.00052 violation_train: 0.10438 violation_val: 0.11026 time: 0.0471s\n",
      "-------- Epoch 94 --------\n",
      "epoch: 00094 loss_train: 0.00044 loss_val: 0.00051 violation_train: 0.10476 violation_val: 0.11109 time: 0.0471s\n",
      "-------- Epoch 95 --------\n",
      "epoch: 00095 loss_train: 0.00044 loss_val: 0.00050 violation_train: 0.10411 violation_val: 0.10835 time: 0.0477s\n",
      "-------- Epoch 96 --------\n",
      "epoch: 00096 loss_train: 0.00044 loss_val: 0.00048 violation_train: 0.10340 violation_val: 0.10982 time: 0.0474s\n",
      "-------- Epoch 97 --------\n",
      "epoch: 00097 loss_train: 0.00043 loss_val: 0.00048 violation_train: 0.10333 violation_val: 0.10960 time: 0.0472s\n",
      "-------- Epoch 98 --------\n",
      "epoch: 00098 loss_train: 0.00043 loss_val: 0.00049 violation_train: 0.10363 violation_val: 0.10799 time: 0.0475s\n",
      "-------- Epoch 99 --------\n",
      "epoch: 00099 loss_train: 0.00042 loss_val: 0.00048 violation_train: 0.10308 violation_val: 0.10858 time: 0.0476s\n",
      "-------- Epoch 100 --------\n",
      "epoch: 00100 loss_train: 0.00042 loss_val: 0.00046 violation_train: 0.10297 violation_val: 0.11028 time: 0.0486s\n",
      "-------- Epoch 101 --------\n",
      "epoch: 00101 loss_train: 0.00041 loss_val: 0.00045 violation_train: 0.10393 violation_val: 0.11161 time: 0.0477s\n",
      "-------- Epoch 102 --------\n",
      "epoch: 00102 loss_train: 0.00041 loss_val: 0.00046 violation_train: 0.10274 violation_val: 0.10911 time: 0.0471s\n",
      "-------- Epoch 103 --------\n",
      "epoch: 00103 loss_train: 0.00041 loss_val: 0.00047 violation_train: 0.10263 violation_val: 0.10869 time: 0.0467s\n",
      "-------- Epoch 104 --------\n",
      "epoch: 00104 loss_train: 0.00040 loss_val: 0.00045 violation_train: 0.10199 violation_val: 0.10806 time: 0.0472s\n",
      "-------- Epoch 105 --------\n",
      "epoch: 00105 loss_train: 0.00040 loss_val: 0.00044 violation_train: 0.10235 violation_val: 0.10713 time: 0.0478s\n",
      "-------- Epoch 106 --------\n",
      "epoch: 00106 loss_train: 0.00040 loss_val: 0.00044 violation_train: 0.10213 violation_val: 0.10702 time: 0.0476s\n",
      "-------- Epoch 107 --------\n",
      "epoch: 00107 loss_train: 0.00039 loss_val: 0.00043 violation_train: 0.10206 violation_val: 0.10671 time: 0.0473s\n",
      "-------- Epoch 108 --------\n",
      "epoch: 00108 loss_train: 0.00039 loss_val: 0.00042 violation_train: 0.10151 violation_val: 0.10629 time: 0.0470s\n",
      "-------- Epoch 109 --------\n",
      "epoch: 00109 loss_train: 0.00039 loss_val: 0.00042 violation_train: 0.10136 violation_val: 0.10726 time: 0.0467s\n",
      "-------- Epoch 110 --------\n",
      "epoch: 00110 loss_train: 0.00039 loss_val: 0.00043 violation_train: 0.10118 violation_val: 0.10845 time: 0.0478s\n",
      "-------- Epoch 111 --------\n",
      "epoch: 00111 loss_train: 0.00038 loss_val: 0.00044 violation_train: 0.10144 violation_val: 0.10868 time: 0.0471s\n",
      "-------- Epoch 112 --------\n",
      "epoch: 00112 loss_train: 0.00038 loss_val: 0.00042 violation_train: 0.10135 violation_val: 0.10858 time: 0.0473s\n",
      "-------- Epoch 113 --------\n",
      "epoch: 00113 loss_train: 0.00038 loss_val: 0.00041 violation_train: 0.10070 violation_val: 0.10720 time: 0.0475s\n",
      "-------- Epoch 114 --------\n",
      "epoch: 00114 loss_train: 0.00038 loss_val: 0.00040 violation_train: 0.10095 violation_val: 0.10528 time: 0.0478s\n",
      "-------- Epoch 115 --------\n",
      "epoch: 00115 loss_train: 0.00038 loss_val: 0.00043 violation_train: 0.10030 violation_val: 0.10612 time: 0.0478s\n",
      "-------- Epoch 116 --------\n",
      "epoch: 00116 loss_train: 0.00037 loss_val: 0.00040 violation_train: 0.10031 violation_val: 0.10639 time: 0.0513s\n",
      "-------- Epoch 117 --------\n",
      "epoch: 00117 loss_train: 0.00037 loss_val: 0.00041 violation_train: 0.09987 violation_val: 0.10664 time: 0.0518s\n",
      "-------- Epoch 118 --------\n",
      "epoch: 00118 loss_train: 0.00037 loss_val: 0.00040 violation_train: 0.09961 violation_val: 0.10749 time: 0.0485s\n",
      "-------- Epoch 119 --------\n",
      "epoch: 00119 loss_train: 0.00037 loss_val: 0.00042 violation_train: 0.10020 violation_val: 0.10596 time: 0.0475s\n",
      "-------- Epoch 120 --------\n",
      "epoch: 00120 loss_train: 0.00037 loss_val: 0.00041 violation_train: 0.10023 violation_val: 0.10829 time: 0.0483s\n",
      "-------- Epoch 121 --------\n",
      "epoch: 00121 loss_train: 0.00037 loss_val: 0.00042 violation_train: 0.09995 violation_val: 0.10855 time: 0.0475s\n",
      "-------- Epoch 122 --------\n",
      "epoch: 00122 loss_train: 0.00036 loss_val: 0.00042 violation_train: 0.09978 violation_val: 0.10772 time: 0.0474s\n",
      "-------- Epoch 123 --------\n",
      "epoch: 00123 loss_train: 0.00036 loss_val: 0.00039 violation_train: 0.09944 violation_val: 0.10611 time: 0.0472s\n",
      "-------- Epoch 124 --------\n",
      "epoch: 00124 loss_train: 0.00036 loss_val: 0.00038 violation_train: 0.09968 violation_val: 0.10582 time: 0.0479s\n",
      "-------- Epoch 125 --------\n",
      "epoch: 00125 loss_train: 0.00036 loss_val: 0.00039 violation_train: 0.09916 violation_val: 0.10471 time: 0.0478s\n",
      "-------- Epoch 126 --------\n",
      "epoch: 00126 loss_train: 0.00036 loss_val: 0.00039 violation_train: 0.09985 violation_val: 0.10602 time: 0.0472s\n",
      "-------- Epoch 127 --------\n",
      "epoch: 00127 loss_train: 0.00036 loss_val: 0.00039 violation_train: 0.09998 violation_val: 0.10679 time: 0.0467s\n",
      "-------- Epoch 128 --------\n",
      "epoch: 00128 loss_train: 0.00036 loss_val: 0.00038 violation_train: 0.10027 violation_val: 0.10560 time: 0.0472s\n",
      "-------- Epoch 129 --------\n",
      "epoch: 00129 loss_train: 0.00035 loss_val: 0.00038 violation_train: 0.09966 violation_val: 0.10612 time: 0.0472s\n",
      "-------- Epoch 130 --------\n",
      "epoch: 00130 loss_train: 0.00035 loss_val: 0.00037 violation_train: 0.09944 violation_val: 0.10500 time: 0.0484s\n",
      "-------- Epoch 131 --------\n",
      "epoch: 00131 loss_train: 0.00035 loss_val: 0.00037 violation_train: 0.09920 violation_val: 0.10416 time: 0.0475s\n",
      "-------- Epoch 132 --------\n",
      "epoch: 00132 loss_train: 0.00035 loss_val: 0.00037 violation_train: 0.09963 violation_val: 0.10545 time: 0.0473s\n",
      "-------- Epoch 133 --------\n",
      "epoch: 00133 loss_train: 0.00035 loss_val: 0.00036 violation_train: 0.10010 violation_val: 0.10674 time: 0.0472s\n",
      "-------- Epoch 134 --------\n",
      "epoch: 00134 loss_train: 0.00035 loss_val: 0.00039 violation_train: 0.09985 violation_val: 0.10892 time: 0.0470s\n",
      "-------- Epoch 135 --------\n",
      "epoch: 00135 loss_train: 0.00035 loss_val: 0.00036 violation_train: 0.09986 violation_val: 0.10770 time: 0.0481s\n",
      "-------- Epoch 136 --------\n",
      "epoch: 00136 loss_train: 0.00034 loss_val: 0.00037 violation_train: 0.10008 violation_val: 0.10783 time: 0.0471s\n",
      "-------- Epoch 137 --------\n",
      "epoch: 00137 loss_train: 0.00034 loss_val: 0.00037 violation_train: 0.09948 violation_val: 0.11017 time: 0.0467s\n",
      "-------- Epoch 138 --------\n",
      "epoch: 00138 loss_train: 0.00034 loss_val: 0.00037 violation_train: 0.09933 violation_val: 0.10887 time: 0.0471s\n",
      "-------- Epoch 139 --------\n",
      "epoch: 00139 loss_train: 0.00034 loss_val: 0.00036 violation_train: 0.09955 violation_val: 0.11050 time: 0.0509s\n",
      "-------- Epoch 140 --------\n",
      "epoch: 00140 loss_train: 0.00034 loss_val: 0.00036 violation_train: 0.09962 violation_val: 0.10837 time: 0.0518s\n",
      "-------- Epoch 141 --------\n",
      "epoch: 00141 loss_train: 0.00034 loss_val: 0.00035 violation_train: 0.09968 violation_val: 0.10676 time: 0.0537s\n",
      "-------- Epoch 142 --------\n",
      "epoch: 00142 loss_train: 0.00033 loss_val: 0.00035 violation_train: 0.09970 violation_val: 0.10897 time: 0.0512s\n",
      "-------- Epoch 143 --------\n",
      "epoch: 00143 loss_train: 0.00033 loss_val: 0.00040 violation_train: 0.10035 violation_val: 0.11079 time: 0.0494s\n",
      "-------- Epoch 144 --------\n",
      "epoch: 00144 loss_train: 0.00033 loss_val: 0.00034 violation_train: 0.10128 violation_val: 0.10930 time: 0.0491s\n",
      "-------- Epoch 145 --------\n",
      "epoch: 00145 loss_train: 0.00033 loss_val: 0.00035 violation_train: 0.10041 violation_val: 0.11023 time: 0.0476s\n",
      "-------- Epoch 146 --------\n",
      "epoch: 00146 loss_train: 0.00033 loss_val: 0.00036 violation_train: 0.10036 violation_val: 0.11332 time: 0.0468s\n",
      "-------- Epoch 147 --------\n",
      "epoch: 00147 loss_train: 0.00033 loss_val: 0.00034 violation_train: 0.10025 violation_val: 0.11087 time: 0.0470s\n",
      "-------- Epoch 148 --------\n",
      "epoch: 00148 loss_train: 0.00033 loss_val: 0.00034 violation_train: 0.10107 violation_val: 0.11141 time: 0.0470s\n",
      "-------- Epoch 149 --------\n",
      "epoch: 00149 loss_train: 0.00033 loss_val: 0.00034 violation_train: 0.10049 violation_val: 0.11074 time: 0.0481s\n",
      "-------- Epoch 150 --------\n",
      "epoch: 00150 loss_train: 0.00032 loss_val: 0.00035 violation_train: 0.10054 violation_val: 0.10969 time: 0.0492s\n",
      "-------- Epoch 151 --------\n",
      "epoch: 00151 loss_train: 0.00032 loss_val: 0.00034 violation_train: 0.10018 violation_val: 0.11351 time: 0.0492s\n",
      "-------- Epoch 152 --------\n",
      "epoch: 00152 loss_train: 0.00032 loss_val: 0.00034 violation_train: 0.10055 violation_val: 0.11151 time: 0.0517s\n",
      "-------- Epoch 153 --------\n",
      "epoch: 00153 loss_train: 0.00032 loss_val: 0.00033 violation_train: 0.10150 violation_val: 0.10912 time: 0.0513s\n",
      "-------- Epoch 154 --------\n",
      "epoch: 00154 loss_train: 0.00032 loss_val: 0.00034 violation_train: 0.10160 violation_val: 0.11221 time: 0.0518s\n",
      "-------- Epoch 155 --------\n",
      "epoch: 00155 loss_train: 0.00032 loss_val: 0.00032 violation_train: 0.10152 violation_val: 0.11489 time: 0.0525s\n",
      "-------- Epoch 156 --------\n",
      "epoch: 00156 loss_train: 0.00031 loss_val: 0.00033 violation_train: 0.10193 violation_val: 0.11283 time: 0.0479s\n",
      "-------- Epoch 157 --------\n",
      "epoch: 00157 loss_train: 0.00031 loss_val: 0.00034 violation_train: 0.10144 violation_val: 0.11507 time: 0.0480s\n",
      "-------- Epoch 158 --------\n",
      "epoch: 00158 loss_train: 0.00031 loss_val: 0.00032 violation_train: 0.10206 violation_val: 0.11167 time: 0.0486s\n",
      "-------- Epoch 159 --------\n",
      "epoch: 00159 loss_train: 0.00031 loss_val: 0.00032 violation_train: 0.10285 violation_val: 0.11489 time: 0.0495s\n",
      "-------- Epoch 160 --------\n",
      "epoch: 00160 loss_train: 0.00031 loss_val: 0.00033 violation_train: 0.10222 violation_val: 0.11332 time: 0.0478s\n",
      "-------- Epoch 161 --------\n",
      "epoch: 00161 loss_train: 0.00031 loss_val: 0.00035 violation_train: 0.10208 violation_val: 0.11147 time: 0.0478s\n",
      "-------- Epoch 162 --------\n",
      "epoch: 00162 loss_train: 0.00031 loss_val: 0.00033 violation_train: 0.10221 violation_val: 0.11158 time: 0.0477s\n",
      "-------- Epoch 163 --------\n",
      "epoch: 00163 loss_train: 0.00030 loss_val: 0.00033 violation_train: 0.10244 violation_val: 0.11214 time: 0.0477s\n",
      "-------- Epoch 164 --------\n",
      "epoch: 00164 loss_train: 0.00030 loss_val: 0.00031 violation_train: 0.10284 violation_val: 0.11278 time: 0.0487s\n",
      "-------- Epoch 165 --------\n",
      "epoch: 00165 loss_train: 0.00030 loss_val: 0.00031 violation_train: 0.10265 violation_val: 0.11220 time: 0.0479s\n",
      "-------- Epoch 166 --------\n",
      "epoch: 00166 loss_train: 0.00030 loss_val: 0.00032 violation_train: 0.10353 violation_val: 0.11043 time: 0.0474s\n",
      "-------- Epoch 167 --------\n",
      "epoch: 00167 loss_train: 0.00030 loss_val: 0.00031 violation_train: 0.10283 violation_val: 0.10939 time: 0.0472s\n",
      "-------- Epoch 168 --------\n",
      "epoch: 00168 loss_train: 0.00030 loss_val: 0.00031 violation_train: 0.10356 violation_val: 0.11072 time: 0.0479s\n",
      "-------- Epoch 169 --------\n",
      "epoch: 00169 loss_train: 0.00029 loss_val: 0.00032 violation_train: 0.10363 violation_val: 0.11117 time: 0.0485s\n",
      "-------- Epoch 170 --------\n",
      "epoch: 00170 loss_train: 0.00029 loss_val: 0.00032 violation_train: 0.10413 violation_val: 0.11143 time: 0.0471s\n",
      "-------- Epoch 171 --------\n",
      "epoch: 00171 loss_train: 0.00029 loss_val: 0.00031 violation_train: 0.10361 violation_val: 0.10907 time: 0.0479s\n",
      "-------- Epoch 172 --------\n",
      "epoch: 00172 loss_train: 0.00029 loss_val: 0.00030 violation_train: 0.10489 violation_val: 0.11027 time: 0.0475s\n",
      "-------- Epoch 173 --------\n",
      "epoch: 00173 loss_train: 0.00029 loss_val: 0.00030 violation_train: 0.10454 violation_val: 0.10800 time: 0.0477s\n",
      "-------- Epoch 174 --------\n",
      "epoch: 00174 loss_train: 0.00029 loss_val: 0.00032 violation_train: 0.10267 violation_val: 0.11135 time: 0.0483s\n",
      "-------- Epoch 175 --------\n",
      "epoch: 00175 loss_train: 0.00029 loss_val: 0.00029 violation_train: 0.10474 violation_val: 0.10868 time: 0.0476s\n",
      "-------- Epoch 176 --------\n",
      "epoch: 00176 loss_train: 0.00028 loss_val: 0.00029 violation_train: 0.10437 violation_val: 0.11006 time: 0.0473s\n",
      "-------- Epoch 177 --------\n",
      "epoch: 00177 loss_train: 0.00028 loss_val: 0.00029 violation_train: 0.10372 violation_val: 0.10980 time: 0.0483s\n",
      "-------- Epoch 178 --------\n",
      "epoch: 00178 loss_train: 0.00028 loss_val: 0.00031 violation_train: 0.10400 violation_val: 0.11068 time: 0.0508s\n",
      "-------- Epoch 179 --------\n",
      "epoch: 00179 loss_train: 0.00028 loss_val: 0.00030 violation_train: 0.10325 violation_val: 0.11086 time: 0.0527s\n",
      "-------- Epoch 180 --------\n",
      "epoch: 00180 loss_train: 0.00028 loss_val: 0.00029 violation_train: 0.10374 violation_val: 0.10796 time: 0.0522s\n",
      "-------- Epoch 181 --------\n",
      "epoch: 00181 loss_train: 0.00028 loss_val: 0.00031 violation_train: 0.10438 violation_val: 0.10983 time: 0.0532s\n",
      "-------- Epoch 182 --------\n",
      "epoch: 00182 loss_train: 0.00028 loss_val: 0.00028 violation_train: 0.10348 violation_val: 0.11436 time: 0.0499s\n",
      "-------- Epoch 183 --------\n",
      "epoch: 00183 loss_train: 0.00027 loss_val: 0.00029 violation_train: 0.10302 violation_val: 0.10704 time: 0.0482s\n",
      "-------- Epoch 184 --------\n",
      "epoch: 00184 loss_train: 0.00027 loss_val: 0.00028 violation_train: 0.10428 violation_val: 0.10741 time: 0.0484s\n",
      "-------- Epoch 185 --------\n",
      "epoch: 00185 loss_train: 0.00027 loss_val: 0.00028 violation_train: 0.10368 violation_val: 0.10845 time: 0.0478s\n",
      "-------- Epoch 186 --------\n",
      "epoch: 00186 loss_train: 0.00027 loss_val: 0.00027 violation_train: 0.10460 violation_val: 0.10928 time: 0.0475s\n",
      "-------- Epoch 187 --------\n",
      "epoch: 00187 loss_train: 0.00027 loss_val: 0.00027 violation_train: 0.10342 violation_val: 0.10863 time: 0.0476s\n",
      "-------- Epoch 188 --------\n",
      "epoch: 00188 loss_train: 0.00027 loss_val: 0.00027 violation_train: 0.10398 violation_val: 0.10456 time: 0.0489s\n",
      "-------- Epoch 189 --------\n",
      "epoch: 00189 loss_train: 0.00027 loss_val: 0.00026 violation_train: 0.10359 violation_val: 0.10648 time: 0.0483s\n",
      "-------- Epoch 190 --------\n",
      "epoch: 00190 loss_train: 0.00026 loss_val: 0.00030 violation_train: 0.10337 violation_val: 0.10754 time: 0.0471s\n",
      "-------- Epoch 191 --------\n",
      "epoch: 00191 loss_train: 0.00026 loss_val: 0.00028 violation_train: 0.10393 violation_val: 0.10612 time: 0.0470s\n",
      "-------- Epoch 192 --------\n",
      "epoch: 00192 loss_train: 0.00026 loss_val: 0.00027 violation_train: 0.10357 violation_val: 0.10652 time: 0.0468s\n",
      "-------- Epoch 193 --------\n",
      "epoch: 00193 loss_train: 0.00026 loss_val: 0.00026 violation_train: 0.10367 violation_val: 0.10775 time: 0.0482s\n",
      "-------- Epoch 194 --------\n",
      "epoch: 00194 loss_train: 0.00026 loss_val: 0.00027 violation_train: 0.10333 violation_val: 0.10484 time: 0.0475s\n",
      "-------- Epoch 195 --------\n",
      "epoch: 00195 loss_train: 0.00026 loss_val: 0.00026 violation_train: 0.10399 violation_val: 0.10707 time: 0.0469s\n",
      "-------- Epoch 196 --------\n",
      "epoch: 00196 loss_train: 0.00026 loss_val: 0.00027 violation_train: 0.10376 violation_val: 0.10638 time: 0.0475s\n",
      "-------- Epoch 197 --------\n",
      "epoch: 00197 loss_train: 0.00026 loss_val: 0.00026 violation_train: 0.10322 violation_val: 0.10297 time: 0.0474s\n",
      "-------- Epoch 198 --------\n",
      "epoch: 00198 loss_train: 0.00025 loss_val: 0.00026 violation_train: 0.10441 violation_val: 0.10249 time: 0.0485s\n",
      "-------- Epoch 199 --------\n",
      "epoch: 00199 loss_train: 0.00025 loss_val: 0.00026 violation_train: 0.10338 violation_val: 0.10466 time: 0.0478s\n",
      "-------- Epoch 200 --------\n",
      "epoch: 00200 loss_train: 0.00025 loss_val: 0.00027 violation_train: 0.10308 violation_val: 0.10274 time: 0.0473s\n",
      "-------- Epoch 201 --------\n",
      "epoch: 00201 loss_train: 0.00025 loss_val: 0.00026 violation_train: 0.10313 violation_val: 0.10606 time: 0.0471s\n",
      "-------- Epoch 202 --------\n",
      "epoch: 00202 loss_train: 0.00025 loss_val: 0.00025 violation_train: 0.10250 violation_val: 0.10398 time: 0.0475s\n",
      "-------- Epoch 203 --------\n",
      "epoch: 00203 loss_train: 0.00025 loss_val: 0.00025 violation_train: 0.10316 violation_val: 0.10490 time: 0.0485s\n",
      "-------- Epoch 204 --------\n",
      "epoch: 00204 loss_train: 0.00025 loss_val: 0.00025 violation_train: 0.10263 violation_val: 0.10504 time: 0.0478s\n",
      "-------- Epoch 205 --------\n",
      "epoch: 00205 loss_train: 0.00025 loss_val: 0.00025 violation_train: 0.10307 violation_val: 0.10067 time: 0.0470s\n",
      "-------- Epoch 206 --------\n",
      "epoch: 00206 loss_train: 0.00024 loss_val: 0.00025 violation_train: 0.10227 violation_val: 0.10435 time: 0.0471s\n",
      "-------- Epoch 207 --------\n",
      "epoch: 00207 loss_train: 0.00024 loss_val: 0.00026 violation_train: 0.10248 violation_val: 0.10373 time: 0.0473s\n",
      "-------- Epoch 208 --------\n",
      "epoch: 00208 loss_train: 0.00024 loss_val: 0.00025 violation_train: 0.10227 violation_val: 0.10160 time: 0.0485s\n",
      "-------- Epoch 209 --------\n",
      "epoch: 00209 loss_train: 0.00024 loss_val: 0.00025 violation_train: 0.10218 violation_val: 0.10417 time: 0.0481s\n",
      "-------- Epoch 210 --------\n",
      "epoch: 00210 loss_train: 0.00024 loss_val: 0.00026 violation_train: 0.10208 violation_val: 0.10277 time: 0.0472s\n",
      "-------- Epoch 211 --------\n",
      "epoch: 00211 loss_train: 0.00024 loss_val: 0.00024 violation_train: 0.10221 violation_val: 0.10437 time: 0.0498s\n",
      "-------- Epoch 212 --------\n",
      "epoch: 00212 loss_train: 0.00024 loss_val: 0.00025 violation_train: 0.10182 violation_val: 0.10177 time: 0.0521s\n",
      "-------- Epoch 213 --------\n",
      "epoch: 00213 loss_train: 0.00024 loss_val: 0.00025 violation_train: 0.10185 violation_val: 0.10659 time: 0.0510s\n",
      "-------- Epoch 214 --------\n",
      "epoch: 00214 loss_train: 0.00023 loss_val: 0.00025 violation_train: 0.10110 violation_val: 0.10464 time: 0.0493s\n",
      "-------- Epoch 215 --------\n",
      "epoch: 00215 loss_train: 0.00023 loss_val: 0.00023 violation_train: 0.10150 violation_val: 0.10022 time: 0.0510s\n",
      "-------- Epoch 216 --------\n",
      "epoch: 00216 loss_train: 0.00023 loss_val: 0.00024 violation_train: 0.10061 violation_val: 0.10539 time: 0.0490s\n",
      "-------- Epoch 217 --------\n",
      "epoch: 00217 loss_train: 0.00023 loss_val: 0.00024 violation_train: 0.10085 violation_val: 0.10299 time: 0.0483s\n",
      "-------- Epoch 218 --------\n",
      "epoch: 00218 loss_train: 0.00023 loss_val: 0.00023 violation_train: 0.10033 violation_val: 0.10482 time: 0.0489s\n",
      "-------- Epoch 219 --------\n",
      "epoch: 00219 loss_train: 0.00023 loss_val: 0.00023 violation_train: 0.10022 violation_val: 0.10177 time: 0.0501s\n",
      "-------- Epoch 220 --------\n",
      "epoch: 00220 loss_train: 0.00023 loss_val: 0.00023 violation_train: 0.10072 violation_val: 0.09973 time: 0.0511s\n",
      "-------- Epoch 221 --------\n",
      "epoch: 00221 loss_train: 0.00023 loss_val: 0.00023 violation_train: 0.10019 violation_val: 0.10055 time: 0.0478s\n",
      "-------- Epoch 222 --------\n",
      "epoch: 00222 loss_train: 0.00023 loss_val: 0.00023 violation_train: 0.10036 violation_val: 0.10112 time: 0.0471s\n",
      "-------- Epoch 223 --------\n",
      "epoch: 00223 loss_train: 0.00022 loss_val: 0.00023 violation_train: 0.10005 violation_val: 0.10319 time: 0.0485s\n",
      "-------- Epoch 224 --------\n",
      "epoch: 00224 loss_train: 0.00022 loss_val: 0.00024 violation_train: 0.09991 violation_val: 0.09952 time: 0.0474s\n",
      "-------- Epoch 225 --------\n",
      "epoch: 00225 loss_train: 0.00022 loss_val: 0.00022 violation_train: 0.09975 violation_val: 0.09937 time: 0.0470s\n",
      "-------- Epoch 226 --------\n",
      "epoch: 00226 loss_train: 0.00022 loss_val: 0.00024 violation_train: 0.09957 violation_val: 0.10106 time: 0.0478s\n",
      "-------- Epoch 227 --------\n",
      "epoch: 00227 loss_train: 0.00022 loss_val: 0.00023 violation_train: 0.09887 violation_val: 0.10186 time: 0.0471s\n",
      "-------- Epoch 228 --------\n",
      "epoch: 00228 loss_train: 0.00022 loss_val: 0.00022 violation_train: 0.09881 violation_val: 0.10089 time: 0.0485s\n",
      "-------- Epoch 229 --------\n",
      "epoch: 00229 loss_train: 0.00022 loss_val: 0.00022 violation_train: 0.09899 violation_val: 0.09968 time: 0.0489s\n",
      "-------- Epoch 230 --------\n",
      "epoch: 00230 loss_train: 0.00021 loss_val: 0.00022 violation_train: 0.09880 violation_val: 0.10268 time: 0.0494s\n",
      "-------- Epoch 231 --------\n",
      "epoch: 00231 loss_train: 0.00021 loss_val: 0.00022 violation_train: 0.09824 violation_val: 0.10206 time: 0.0472s\n",
      "-------- Epoch 232 --------\n",
      "epoch: 00232 loss_train: 0.00021 loss_val: 0.00022 violation_train: 0.09823 violation_val: 0.09852 time: 0.0480s\n",
      "-------- Epoch 233 --------\n",
      "epoch: 00233 loss_train: 0.00021 loss_val: 0.00021 violation_train: 0.09758 violation_val: 0.10154 time: 0.0513s\n",
      "-------- Epoch 234 --------\n",
      "epoch: 00234 loss_train: 0.00021 loss_val: 0.00021 violation_train: 0.09840 violation_val: 0.09861 time: 0.0515s\n",
      "-------- Epoch 235 --------\n",
      "epoch: 00235 loss_train: 0.00021 loss_val: 0.00021 violation_train: 0.09752 violation_val: 0.10819 time: 0.0474s\n",
      "-------- Epoch 236 --------\n",
      "epoch: 00236 loss_train: 0.00021 loss_val: 0.00022 violation_train: 0.09812 violation_val: 0.09987 time: 0.0474s\n",
      "-------- Epoch 237 --------\n",
      "epoch: 00237 loss_train: 0.00021 loss_val: 0.00021 violation_train: 0.09762 violation_val: 0.10185 time: 0.0480s\n",
      "-------- Epoch 238 --------\n",
      "epoch: 00238 loss_train: 0.00021 loss_val: 0.00021 violation_train: 0.09857 violation_val: 0.10292 time: 0.0493s\n",
      "-------- Epoch 239 --------\n",
      "epoch: 00239 loss_train: 0.00020 loss_val: 0.00021 violation_train: 0.09694 violation_val: 0.10028 time: 0.0476s\n",
      "-------- Epoch 240 --------\n",
      "epoch: 00240 loss_train: 0.00020 loss_val: 0.00020 violation_train: 0.09636 violation_val: 0.09719 time: 0.0473s\n",
      "-------- Epoch 241 --------\n",
      "epoch: 00241 loss_train: 0.00020 loss_val: 0.00020 violation_train: 0.09640 violation_val: 0.09826 time: 0.0478s\n",
      "-------- Epoch 242 --------\n",
      "epoch: 00242 loss_train: 0.00020 loss_val: 0.00020 violation_train: 0.09583 violation_val: 0.09990 time: 0.0474s\n",
      "-------- Epoch 243 --------\n",
      "epoch: 00243 loss_train: 0.00020 loss_val: 0.00021 violation_train: 0.09639 violation_val: 0.09693 time: 0.0483s\n",
      "-------- Epoch 244 --------\n",
      "epoch: 00244 loss_train: 0.00020 loss_val: 0.00020 violation_train: 0.09539 violation_val: 0.09728 time: 0.0478s\n",
      "-------- Epoch 245 --------\n",
      "epoch: 00245 loss_train: 0.00020 loss_val: 0.00021 violation_train: 0.09529 violation_val: 0.09746 time: 0.0474s\n",
      "-------- Epoch 246 --------\n",
      "epoch: 00246 loss_train: 0.00020 loss_val: 0.00022 violation_train: 0.09558 violation_val: 0.09785 time: 0.0475s\n",
      "-------- Epoch 247 --------\n",
      "epoch: 00247 loss_train: 0.00019 loss_val: 0.00020 violation_train: 0.09501 violation_val: 0.09646 time: 0.0542s\n",
      "-------- Epoch 248 --------\n",
      "epoch: 00248 loss_train: 0.00020 loss_val: 0.00020 violation_train: 0.09552 violation_val: 0.09655 time: 0.0513s\n",
      "-------- Epoch 249 --------\n",
      "epoch: 00249 loss_train: 0.00019 loss_val: 0.00019 violation_train: 0.09509 violation_val: 0.09897 time: 0.0481s\n",
      "-------- Epoch 250 --------\n",
      "epoch: 00250 loss_train: 0.00019 loss_val: 0.00020 violation_train: 0.09463 violation_val: 0.09480 time: 0.0491s\n",
      "-------- Epoch 251 --------\n",
      "epoch: 00251 loss_train: 0.00019 loss_val: 0.00020 violation_train: 0.09440 violation_val: 0.09683 time: 0.0473s\n",
      "-------- Epoch 252 --------\n",
      "epoch: 00252 loss_train: 0.00019 loss_val: 0.00020 violation_train: 0.09401 violation_val: 0.09837 time: 0.0469s\n",
      "-------- Epoch 253 --------\n",
      "epoch: 00253 loss_train: 0.00019 loss_val: 0.00019 violation_train: 0.09467 violation_val: 0.09596 time: 0.0481s\n",
      "-------- Epoch 254 --------\n",
      "epoch: 00254 loss_train: 0.00019 loss_val: 0.00019 violation_train: 0.09357 violation_val: 0.10017 time: 0.0484s\n",
      "-------- Epoch 255 --------\n",
      "epoch: 00255 loss_train: 0.00019 loss_val: 0.00020 violation_train: 0.09370 violation_val: 0.09876 time: 0.0483s\n",
      "-------- Epoch 256 --------\n",
      "epoch: 00256 loss_train: 0.00019 loss_val: 0.00019 violation_train: 0.09393 violation_val: 0.09673 time: 0.0481s\n",
      "-------- Epoch 257 --------\n",
      "epoch: 00257 loss_train: 0.00019 loss_val: 0.00019 violation_train: 0.09472 violation_val: 0.09806 time: 0.0526s\n",
      "-------- Epoch 258 --------\n",
      "epoch: 00258 loss_train: 0.00018 loss_val: 0.00019 violation_train: 0.09409 violation_val: 0.09520 time: 0.0488s\n",
      "-------- Epoch 259 --------\n",
      "epoch: 00259 loss_train: 0.00018 loss_val: 0.00019 violation_train: 0.09347 violation_val: 0.09910 time: 0.0483s\n",
      "-------- Epoch 260 --------\n",
      "epoch: 00260 loss_train: 0.00018 loss_val: 0.00019 violation_train: 0.09324 violation_val: 0.09517 time: 0.0480s\n",
      "-------- Epoch 261 --------\n",
      "epoch: 00261 loss_train: 0.00018 loss_val: 0.00019 violation_train: 0.09316 violation_val: 0.09741 time: 0.0481s\n",
      "-------- Epoch 262 --------\n",
      "epoch: 00262 loss_train: 0.00018 loss_val: 0.00020 violation_train: 0.09288 violation_val: 0.09604 time: 0.0479s\n",
      "-------- Epoch 263 --------\n",
      "epoch: 00263 loss_train: 0.00018 loss_val: 0.00019 violation_train: 0.09344 violation_val: 0.09561 time: 0.0489s\n",
      "-------- Epoch 264 --------\n",
      "epoch: 00264 loss_train: 0.00018 loss_val: 0.00019 violation_train: 0.09222 violation_val: 0.09763 time: 0.0475s\n",
      "-------- Epoch 265 --------\n",
      "epoch: 00265 loss_train: 0.00018 loss_val: 0.00019 violation_train: 0.09215 violation_val: 0.09471 time: 0.0469s\n",
      "-------- Epoch 266 --------\n",
      "epoch: 00266 loss_train: 0.00018 loss_val: 0.00019 violation_train: 0.09210 violation_val: 0.09489 time: 0.0474s\n",
      "-------- Epoch 267 --------\n",
      "epoch: 00267 loss_train: 0.00018 loss_val: 0.00019 violation_train: 0.09277 violation_val: 0.09490 time: 0.0469s\n",
      "-------- Epoch 268 --------\n",
      "epoch: 00268 loss_train: 0.00017 loss_val: 0.00018 violation_train: 0.09152 violation_val: 0.09272 time: 0.0486s\n",
      "-------- Epoch 269 --------\n",
      "epoch: 00269 loss_train: 0.00017 loss_val: 0.00018 violation_train: 0.09200 violation_val: 0.09692 time: 0.0484s\n",
      "-------- Epoch 270 --------\n",
      "epoch: 00270 loss_train: 0.00017 loss_val: 0.00018 violation_train: 0.09159 violation_val: 0.09714 time: 0.0471s\n",
      "-------- Epoch 271 --------\n",
      "epoch: 00271 loss_train: 0.00017 loss_val: 0.00018 violation_train: 0.09156 violation_val: 0.09590 time: 0.0471s\n",
      "-------- Epoch 272 --------\n",
      "epoch: 00272 loss_train: 0.00017 loss_val: 0.00018 violation_train: 0.09173 violation_val: 0.09399 time: 0.0474s\n",
      "-------- Epoch 273 --------\n",
      "epoch: 00273 loss_train: 0.00017 loss_val: 0.00018 violation_train: 0.09164 violation_val: 0.09695 time: 0.0481s\n",
      "-------- Epoch 274 --------\n",
      "epoch: 00274 loss_train: 0.00017 loss_val: 0.00018 violation_train: 0.09160 violation_val: 0.09305 time: 0.0485s\n",
      "-------- Epoch 275 --------\n",
      "epoch: 00275 loss_train: 0.00017 loss_val: 0.00018 violation_train: 0.09071 violation_val: 0.09401 time: 0.0472s\n",
      "-------- Epoch 276 --------\n",
      "epoch: 00276 loss_train: 0.00017 loss_val: 0.00018 violation_train: 0.09137 violation_val: 0.09493 time: 0.0473s\n",
      "-------- Epoch 277 --------\n",
      "epoch: 00277 loss_train: 0.00017 loss_val: 0.00017 violation_train: 0.09153 violation_val: 0.09833 time: 0.0473s\n",
      "-------- Epoch 278 --------\n",
      "epoch: 00278 loss_train: 0.00017 loss_val: 0.00017 violation_train: 0.09148 violation_val: 0.09467 time: 0.0483s\n",
      "-------- Epoch 279 --------\n",
      "epoch: 00279 loss_train: 0.00016 loss_val: 0.00017 violation_train: 0.09088 violation_val: 0.09468 time: 0.0474s\n",
      "-------- Epoch 280 --------\n",
      "epoch: 00280 loss_train: 0.00017 loss_val: 0.00016 violation_train: 0.09217 violation_val: 0.09382 time: 0.0473s\n",
      "-------- Epoch 281 --------\n",
      "epoch: 00281 loss_train: 0.00016 loss_val: 0.00017 violation_train: 0.09183 violation_val: 0.09199 time: 0.0474s\n",
      "-------- Epoch 282 --------\n",
      "epoch: 00282 loss_train: 0.00016 loss_val: 0.00016 violation_train: 0.09115 violation_val: 0.09054 time: 0.0472s\n",
      "-------- Epoch 283 --------\n",
      "epoch: 00283 loss_train: 0.00016 loss_val: 0.00017 violation_train: 0.09122 violation_val: 0.09189 time: 0.0484s\n",
      "-------- Epoch 284 --------\n",
      "epoch: 00284 loss_train: 0.00016 loss_val: 0.00017 violation_train: 0.09026 violation_val: 0.09558 time: 0.0481s\n",
      "-------- Epoch 285 --------\n",
      "epoch: 00285 loss_train: 0.00016 loss_val: 0.00018 violation_train: 0.09027 violation_val: 0.09488 time: 0.0473s\n",
      "-------- Epoch 286 --------\n",
      "epoch: 00286 loss_train: 0.00016 loss_val: 0.00017 violation_train: 0.09175 violation_val: 0.09920 time: 0.0473s\n",
      "-------- Epoch 287 --------\n",
      "epoch: 00287 loss_train: 0.00016 loss_val: 0.00017 violation_train: 0.09071 violation_val: 0.09268 time: 0.0469s\n",
      "-------- Epoch 288 --------\n",
      "epoch: 00288 loss_train: 0.00016 loss_val: 0.00016 violation_train: 0.09027 violation_val: 0.09521 time: 0.0486s\n",
      "-------- Epoch 289 --------\n",
      "epoch: 00289 loss_train: 0.00016 loss_val: 0.00017 violation_train: 0.08984 violation_val: 0.09112 time: 0.0473s\n",
      "-------- Epoch 290 --------\n",
      "epoch: 00290 loss_train: 0.00016 loss_val: 0.00017 violation_train: 0.09078 violation_val: 0.09437 time: 0.0472s\n",
      "-------- Epoch 291 --------\n",
      "epoch: 00291 loss_train: 0.00015 loss_val: 0.00017 violation_train: 0.09018 violation_val: 0.09267 time: 0.0468s\n",
      "-------- Epoch 292 --------\n",
      "epoch: 00292 loss_train: 0.00015 loss_val: 0.00016 violation_train: 0.09035 violation_val: 0.09821 time: 0.0470s\n",
      "-------- Epoch 293 --------\n",
      "epoch: 00293 loss_train: 0.00015 loss_val: 0.00016 violation_train: 0.09111 violation_val: 0.09394 time: 0.0486s\n",
      "-------- Epoch 294 --------\n",
      "epoch: 00294 loss_train: 0.00015 loss_val: 0.00016 violation_train: 0.09071 violation_val: 0.09138 time: 0.0475s\n",
      "-------- Epoch 295 --------\n",
      "epoch: 00295 loss_train: 0.00015 loss_val: 0.00016 violation_train: 0.09039 violation_val: 0.09071 time: 0.0476s\n",
      "-------- Epoch 296 --------\n",
      "epoch: 00296 loss_train: 0.00015 loss_val: 0.00017 violation_train: 0.08944 violation_val: 0.09216 time: 0.0468s\n",
      "-------- Epoch 297 --------\n",
      "epoch: 00297 loss_train: 0.00015 loss_val: 0.00017 violation_train: 0.08962 violation_val: 0.09061 time: 0.0471s\n",
      "-------- Epoch 298 --------\n",
      "epoch: 00298 loss_train: 0.00015 loss_val: 0.00016 violation_train: 0.09001 violation_val: 0.09203 time: 0.0488s\n",
      "-------- Epoch 299 --------\n",
      "epoch: 00299 loss_train: 0.00015 loss_val: 0.00016 violation_train: 0.08945 violation_val: 0.09242 time: 0.0473s\n",
      "-------- Epoch 300 --------\n",
      "epoch: 00300 loss_train: 0.00015 loss_val: 0.00015 violation_train: 0.08939 violation_val: 0.09069 time: 0.0474s\n",
      "-------- Epoch 301 --------\n",
      "epoch: 00301 loss_train: 0.00015 loss_val: 0.00016 violation_train: 0.08887 violation_val: 0.09163 time: 0.0475s\n",
      "-------- Epoch 302 --------\n",
      "epoch: 00302 loss_train: 0.00014 loss_val: 0.00017 violation_train: 0.08876 violation_val: 0.09128 time: 0.0473s\n",
      "-------- Epoch 303 --------\n",
      "epoch: 00303 loss_train: 0.00014 loss_val: 0.00016 violation_train: 0.08820 violation_val: 0.09105 time: 0.0487s\n",
      "-------- Epoch 304 --------\n",
      "epoch: 00304 loss_train: 0.00014 loss_val: 0.00015 violation_train: 0.08878 violation_val: 0.08882 time: 0.0480s\n",
      "-------- Epoch 305 --------\n",
      "epoch: 00305 loss_train: 0.00014 loss_val: 0.00016 violation_train: 0.08876 violation_val: 0.09176 time: 0.0469s\n",
      "-------- Epoch 306 --------\n",
      "epoch: 00306 loss_train: 0.00014 loss_val: 0.00015 violation_train: 0.08860 violation_val: 0.09321 time: 0.0471s\n",
      "-------- Epoch 307 --------\n",
      "epoch: 00307 loss_train: 0.00014 loss_val: 0.00016 violation_train: 0.08769 violation_val: 0.09324 time: 0.0475s\n",
      "-------- Epoch 308 --------\n",
      "epoch: 00308 loss_train: 0.00014 loss_val: 0.00015 violation_train: 0.08806 violation_val: 0.09159 time: 0.0488s\n",
      "-------- Epoch 309 --------\n",
      "epoch: 00309 loss_train: 0.00014 loss_val: 0.00016 violation_train: 0.08772 violation_val: 0.08845 time: 0.0476s\n",
      "-------- Epoch 310 --------\n",
      "epoch: 00310 loss_train: 0.00014 loss_val: 0.00015 violation_train: 0.08742 violation_val: 0.09708 time: 0.0476s\n",
      "-------- Epoch 311 --------\n",
      "epoch: 00311 loss_train: 0.00014 loss_val: 0.00015 violation_train: 0.08800 violation_val: 0.08869 time: 0.0472s\n",
      "-------- Epoch 312 --------\n",
      "epoch: 00312 loss_train: 0.00014 loss_val: 0.00015 violation_train: 0.08667 violation_val: 0.08911 time: 0.0473s\n",
      "-------- Epoch 313 --------\n",
      "epoch: 00313 loss_train: 0.00014 loss_val: 0.00014 violation_train: 0.08700 violation_val: 0.08982 time: 0.0487s\n",
      "-------- Epoch 314 --------\n",
      "epoch: 00314 loss_train: 0.00013 loss_val: 0.00015 violation_train: 0.08681 violation_val: 0.09025 time: 0.0480s\n",
      "-------- Epoch 315 --------\n",
      "epoch: 00315 loss_train: 0.00014 loss_val: 0.00014 violation_train: 0.08773 violation_val: 0.09201 time: 0.0477s\n",
      "-------- Epoch 316 --------\n",
      "epoch: 00316 loss_train: 0.00013 loss_val: 0.00015 violation_train: 0.08659 violation_val: 0.09073 time: 0.0478s\n",
      "-------- Epoch 317 --------\n",
      "epoch: 00317 loss_train: 0.00013 loss_val: 0.00014 violation_train: 0.08692 violation_val: 0.09226 time: 0.0502s\n",
      "-------- Epoch 318 --------\n",
      "epoch: 00318 loss_train: 0.00013 loss_val: 0.00014 violation_train: 0.08640 violation_val: 0.08817 time: 0.0509s\n",
      "-------- Epoch 319 --------\n",
      "epoch: 00319 loss_train: 0.00013 loss_val: 0.00014 violation_train: 0.08636 violation_val: 0.09022 time: 0.0490s\n",
      "-------- Epoch 320 --------\n",
      "epoch: 00320 loss_train: 0.00013 loss_val: 0.00014 violation_train: 0.08625 violation_val: 0.08599 time: 0.0489s\n",
      "-------- Epoch 321 --------\n",
      "epoch: 00321 loss_train: 0.00013 loss_val: 0.00014 violation_train: 0.08628 violation_val: 0.08728 time: 0.0481s\n",
      "-------- Epoch 322 --------\n",
      "epoch: 00322 loss_train: 0.00013 loss_val: 0.00014 violation_train: 0.08575 violation_val: 0.09239 time: 0.0488s\n",
      "-------- Epoch 323 --------\n",
      "epoch: 00323 loss_train: 0.00013 loss_val: 0.00013 violation_train: 0.08583 violation_val: 0.08635 time: 0.0524s\n",
      "-------- Epoch 324 --------\n",
      "epoch: 00324 loss_train: 0.00013 loss_val: 0.00013 violation_train: 0.08554 violation_val: 0.08697 time: 0.0490s\n",
      "-------- Epoch 325 --------\n",
      "epoch: 00325 loss_train: 0.00013 loss_val: 0.00014 violation_train: 0.08584 violation_val: 0.08647 time: 0.0482s\n",
      "-------- Epoch 326 --------\n",
      "epoch: 00326 loss_train: 0.00012 loss_val: 0.00014 violation_train: 0.08504 violation_val: 0.08865 time: 0.0492s\n",
      "-------- Epoch 327 --------\n",
      "epoch: 00327 loss_train: 0.00012 loss_val: 0.00014 violation_train: 0.08521 violation_val: 0.08787 time: 0.0480s\n",
      "-------- Epoch 328 --------\n",
      "epoch: 00328 loss_train: 0.00012 loss_val: 0.00014 violation_train: 0.08501 violation_val: 0.09206 time: 0.0485s\n",
      "-------- Epoch 329 --------\n",
      "epoch: 00329 loss_train: 0.00012 loss_val: 0.00013 violation_train: 0.08441 violation_val: 0.08597 time: 0.0480s\n",
      "-------- Epoch 330 --------\n",
      "epoch: 00330 loss_train: 0.00012 loss_val: 0.00013 violation_train: 0.08501 violation_val: 0.09100 time: 0.0471s\n",
      "-------- Epoch 331 --------\n",
      "epoch: 00331 loss_train: 0.00012 loss_val: 0.00013 violation_train: 0.08479 violation_val: 0.08855 time: 0.0470s\n",
      "-------- Epoch 332 --------\n",
      "epoch: 00332 loss_train: 0.00012 loss_val: 0.00014 violation_train: 0.08391 violation_val: 0.08536 time: 0.0492s\n",
      "-------- Epoch 333 --------\n",
      "epoch: 00333 loss_train: 0.00012 loss_val: 0.00013 violation_train: 0.08400 violation_val: 0.08541 time: 0.0499s\n",
      "-------- Epoch 334 --------\n",
      "epoch: 00334 loss_train: 0.00012 loss_val: 0.00013 violation_train: 0.08425 violation_val: 0.08454 time: 0.0505s\n",
      "-------- Epoch 335 --------\n",
      "epoch: 00335 loss_train: 0.00012 loss_val: 0.00013 violation_train: 0.08389 violation_val: 0.08531 time: 0.0491s\n",
      "-------- Epoch 336 --------\n",
      "epoch: 00336 loss_train: 0.00012 loss_val: 0.00013 violation_train: 0.08340 violation_val: 0.08979 time: 0.0487s\n",
      "-------- Epoch 337 --------\n",
      "epoch: 00337 loss_train: 0.00012 loss_val: 0.00012 violation_train: 0.08358 violation_val: 0.08532 time: 0.0484s\n",
      "-------- Epoch 338 --------\n",
      "epoch: 00338 loss_train: 0.00012 loss_val: 0.00013 violation_train: 0.08360 violation_val: 0.08437 time: 0.0491s\n",
      "-------- Epoch 339 --------\n",
      "epoch: 00339 loss_train: 0.00011 loss_val: 0.00013 violation_train: 0.08378 violation_val: 0.08332 time: 0.0476s\n",
      "-------- Epoch 340 --------\n",
      "epoch: 00340 loss_train: 0.00011 loss_val: 0.00013 violation_train: 0.08279 violation_val: 0.08532 time: 0.0479s\n",
      "-------- Epoch 341 --------\n",
      "epoch: 00341 loss_train: 0.00011 loss_val: 0.00012 violation_train: 0.08277 violation_val: 0.08588 time: 0.0475s\n",
      "-------- Epoch 342 --------\n",
      "epoch: 00342 loss_train: 0.00011 loss_val: 0.00012 violation_train: 0.08252 violation_val: 0.08463 time: 0.0478s\n",
      "-------- Epoch 343 --------\n",
      "epoch: 00343 loss_train: 0.00011 loss_val: 0.00012 violation_train: 0.08283 violation_val: 0.08500 time: 0.0493s\n",
      "-------- Epoch 344 --------\n",
      "epoch: 00344 loss_train: 0.00011 loss_val: 0.00012 violation_train: 0.08190 violation_val: 0.08564 time: 0.0496s\n",
      "-------- Epoch 345 --------\n",
      "epoch: 00345 loss_train: 0.00011 loss_val: 0.00012 violation_train: 0.08206 violation_val: 0.08289 time: 0.0486s\n",
      "-------- Epoch 346 --------\n",
      "epoch: 00346 loss_train: 0.00011 loss_val: 0.00012 violation_train: 0.08174 violation_val: 0.08274 time: 0.0493s\n",
      "-------- Epoch 347 --------\n",
      "epoch: 00347 loss_train: 0.00011 loss_val: 0.00012 violation_train: 0.08158 violation_val: 0.08164 time: 0.0490s\n",
      "-------- Epoch 348 --------\n",
      "epoch: 00348 loss_train: 0.00011 loss_val: 0.00012 violation_train: 0.08162 violation_val: 0.08327 time: 0.0493s\n",
      "-------- Epoch 349 --------\n",
      "epoch: 00349 loss_train: 0.00011 loss_val: 0.00012 violation_train: 0.08141 violation_val: 0.08206 time: 0.0487s\n",
      "-------- Epoch 350 --------\n",
      "epoch: 00350 loss_train: 0.00011 loss_val: 0.00012 violation_train: 0.08099 violation_val: 0.08179 time: 0.0482s\n",
      "-------- Epoch 351 --------\n",
      "epoch: 00351 loss_train: 0.00011 loss_val: 0.00012 violation_train: 0.08149 violation_val: 0.08210 time: 0.0480s\n",
      "-------- Epoch 352 --------\n",
      "epoch: 00352 loss_train: 0.00011 loss_val: 0.00011 violation_train: 0.08060 violation_val: 0.08588 time: 0.0473s\n",
      "-------- Epoch 353 --------\n",
      "epoch: 00353 loss_train: 0.00010 loss_val: 0.00011 violation_train: 0.08085 violation_val: 0.08596 time: 0.0499s\n",
      "-------- Epoch 354 --------\n",
      "epoch: 00354 loss_train: 0.00010 loss_val: 0.00012 violation_train: 0.08033 violation_val: 0.08155 time: 0.0487s\n",
      "-------- Epoch 355 --------\n",
      "epoch: 00355 loss_train: 0.00010 loss_val: 0.00011 violation_train: 0.08058 violation_val: 0.08194 time: 0.0481s\n",
      "-------- Epoch 356 --------\n",
      "epoch: 00356 loss_train: 0.00010 loss_val: 0.00011 violation_train: 0.07994 violation_val: 0.07903 time: 0.0483s\n",
      "-------- Epoch 357 --------\n",
      "epoch: 00357 loss_train: 0.00010 loss_val: 0.00011 violation_train: 0.08006 violation_val: 0.07958 time: 0.0494s\n",
      "-------- Epoch 358 --------\n",
      "epoch: 00358 loss_train: 0.00010 loss_val: 0.00011 violation_train: 0.07963 violation_val: 0.08196 time: 0.0491s\n",
      "-------- Epoch 359 --------\n",
      "epoch: 00359 loss_train: 0.00010 loss_val: 0.00011 violation_train: 0.08000 violation_val: 0.07977 time: 0.0485s\n",
      "-------- Epoch 360 --------\n",
      "epoch: 00360 loss_train: 0.00010 loss_val: 0.00011 violation_train: 0.07895 violation_val: 0.07945 time: 0.0476s\n",
      "-------- Epoch 361 --------\n",
      "epoch: 00361 loss_train: 0.00010 loss_val: 0.00011 violation_train: 0.07923 violation_val: 0.07910 time: 0.0469s\n",
      "-------- Epoch 362 --------\n",
      "epoch: 00362 loss_train: 0.00010 loss_val: 0.00011 violation_train: 0.07898 violation_val: 0.08488 time: 0.0470s\n",
      "-------- Epoch 363 --------\n",
      "epoch: 00363 loss_train: 0.00010 loss_val: 0.00011 violation_train: 0.07944 violation_val: 0.08125 time: 0.0492s\n",
      "-------- Epoch 364 --------\n",
      "epoch: 00364 loss_train: 0.00010 loss_val: 0.00010 violation_train: 0.07858 violation_val: 0.07820 time: 0.0481s\n",
      "-------- Epoch 365 --------\n",
      "epoch: 00365 loss_train: 0.00010 loss_val: 0.00011 violation_train: 0.07911 violation_val: 0.08516 time: 0.0470s\n",
      "-------- Epoch 366 --------\n",
      "epoch: 00366 loss_train: 0.00010 loss_val: 0.00011 violation_train: 0.07864 violation_val: 0.08222 time: 0.0474s\n",
      "-------- Epoch 367 --------\n",
      "epoch: 00367 loss_train: 0.00010 loss_val: 0.00011 violation_train: 0.07783 violation_val: 0.07829 time: 0.0478s\n",
      "-------- Epoch 368 --------\n",
      "epoch: 00368 loss_train: 0.00010 loss_val: 0.00010 violation_train: 0.07769 violation_val: 0.07871 time: 0.0489s\n",
      "-------- Epoch 369 --------\n",
      "epoch: 00369 loss_train: 0.00010 loss_val: 0.00010 violation_train: 0.07740 violation_val: 0.08127 time: 0.0474s\n",
      "-------- Epoch 370 --------\n",
      "epoch: 00370 loss_train: 0.00009 loss_val: 0.00011 violation_train: 0.07716 violation_val: 0.07791 time: 0.0473s\n",
      "-------- Epoch 371 --------\n",
      "epoch: 00371 loss_train: 0.00009 loss_val: 0.00010 violation_train: 0.07664 violation_val: 0.08055 time: 0.0475s\n",
      "-------- Epoch 372 --------\n",
      "epoch: 00372 loss_train: 0.00009 loss_val: 0.00010 violation_train: 0.07690 violation_val: 0.07969 time: 0.0479s\n",
      "-------- Epoch 373 --------\n",
      "epoch: 00373 loss_train: 0.00009 loss_val: 0.00010 violation_train: 0.07626 violation_val: 0.07632 time: 0.0490s\n",
      "-------- Epoch 374 --------\n",
      "epoch: 00374 loss_train: 0.00009 loss_val: 0.00010 violation_train: 0.07640 violation_val: 0.07830 time: 0.0473s\n",
      "-------- Epoch 375 --------\n",
      "epoch: 00375 loss_train: 0.00009 loss_val: 0.00010 violation_train: 0.07560 violation_val: 0.07784 time: 0.0475s\n",
      "-------- Epoch 376 --------\n",
      "epoch: 00376 loss_train: 0.00009 loss_val: 0.00010 violation_train: 0.07600 violation_val: 0.07750 time: 0.0471s\n",
      "-------- Epoch 377 --------\n",
      "epoch: 00377 loss_train: 0.00009 loss_val: 0.00010 violation_train: 0.07548 violation_val: 0.07555 time: 0.0478s\n",
      "-------- Epoch 378 --------\n",
      "epoch: 00378 loss_train: 0.00009 loss_val: 0.00010 violation_train: 0.07514 violation_val: 0.07614 time: 0.0481s\n",
      "-------- Epoch 379 --------\n",
      "epoch: 00379 loss_train: 0.00009 loss_val: 0.00010 violation_train: 0.07505 violation_val: 0.07641 time: 0.0478s\n",
      "-------- Epoch 380 --------\n",
      "epoch: 00380 loss_train: 0.00009 loss_val: 0.00010 violation_train: 0.07472 violation_val: 0.07625 time: 0.0472s\n",
      "-------- Epoch 381 --------\n",
      "epoch: 00381 loss_train: 0.00009 loss_val: 0.00009 violation_train: 0.07477 violation_val: 0.07684 time: 0.0470s\n",
      "-------- Epoch 382 --------\n",
      "epoch: 00382 loss_train: 0.00009 loss_val: 0.00009 violation_train: 0.07450 violation_val: 0.07626 time: 0.0466s\n",
      "-------- Epoch 383 --------\n",
      "epoch: 00383 loss_train: 0.00009 loss_val: 0.00010 violation_train: 0.07427 violation_val: 0.07559 time: 0.0485s\n",
      "-------- Epoch 384 --------\n",
      "epoch: 00384 loss_train: 0.00009 loss_val: 0.00010 violation_train: 0.07370 violation_val: 0.07786 time: 0.0479s\n",
      "-------- Epoch 385 --------\n",
      "epoch: 00385 loss_train: 0.00009 loss_val: 0.00009 violation_train: 0.07329 violation_val: 0.07590 time: 0.0473s\n",
      "-------- Epoch 386 --------\n",
      "epoch: 00386 loss_train: 0.00009 loss_val: 0.00009 violation_train: 0.07288 violation_val: 0.07415 time: 0.0476s\n",
      "-------- Epoch 387 --------\n",
      "epoch: 00387 loss_train: 0.00009 loss_val: 0.00009 violation_train: 0.07293 violation_val: 0.07515 time: 0.0476s\n",
      "-------- Epoch 388 --------\n",
      "epoch: 00388 loss_train: 0.00009 loss_val: 0.00009 violation_train: 0.07284 violation_val: 0.07539 time: 0.0492s\n",
      "-------- Epoch 389 --------\n",
      "epoch: 00389 loss_train: 0.00008 loss_val: 0.00009 violation_train: 0.07213 violation_val: 0.07349 time: 0.0482s\n",
      "-------- Epoch 390 --------\n",
      "epoch: 00390 loss_train: 0.00008 loss_val: 0.00009 violation_train: 0.07210 violation_val: 0.07209 time: 0.0475s\n",
      "-------- Epoch 391 --------\n",
      "epoch: 00391 loss_train: 0.00008 loss_val: 0.00010 violation_train: 0.07187 violation_val: 0.07277 time: 0.0472s\n",
      "-------- Epoch 392 --------\n",
      "epoch: 00392 loss_train: 0.00008 loss_val: 0.00009 violation_train: 0.07183 violation_val: 0.07260 time: 0.0474s\n",
      "-------- Epoch 393 --------\n",
      "epoch: 00393 loss_train: 0.00008 loss_val: 0.00009 violation_train: 0.07154 violation_val: 0.07340 time: 0.0486s\n",
      "-------- Epoch 394 --------\n",
      "epoch: 00394 loss_train: 0.00008 loss_val: 0.00009 violation_train: 0.07152 violation_val: 0.07313 time: 0.0473s\n",
      "-------- Epoch 395 --------\n",
      "epoch: 00395 loss_train: 0.00008 loss_val: 0.00009 violation_train: 0.07044 violation_val: 0.07174 time: 0.0473s\n",
      "-------- Epoch 396 --------\n",
      "epoch: 00396 loss_train: 0.00008 loss_val: 0.00009 violation_train: 0.07097 violation_val: 0.07396 time: 0.0486s\n",
      "-------- Epoch 397 --------\n",
      "epoch: 00397 loss_train: 0.00008 loss_val: 0.00009 violation_train: 0.07034 violation_val: 0.07329 time: 0.0473s\n",
      "-------- Epoch 398 --------\n",
      "epoch: 00398 loss_train: 0.00008 loss_val: 0.00009 violation_train: 0.07013 violation_val: 0.07658 time: 0.0484s\n",
      "-------- Epoch 399 --------\n",
      "epoch: 00399 loss_train: 0.00008 loss_val: 0.00009 violation_train: 0.07005 violation_val: 0.07136 time: 0.0480s\n",
      "-------- Epoch 400 --------\n",
      "epoch: 00400 loss_train: 0.00008 loss_val: 0.00009 violation_train: 0.06937 violation_val: 0.07236 time: 0.0477s\n",
      "-------- Epoch 401 --------\n",
      "epoch: 00401 loss_train: 0.00008 loss_val: 0.00009 violation_train: 0.06960 violation_val: 0.07381 time: 0.0479s\n",
      "-------- Epoch 402 --------\n",
      "epoch: 00402 loss_train: 0.00008 loss_val: 0.00009 violation_train: 0.06915 violation_val: 0.07017 time: 0.0473s\n",
      "-------- Epoch 403 --------\n",
      "epoch: 00403 loss_train: 0.00008 loss_val: 0.00008 violation_train: 0.06857 violation_val: 0.07089 time: 0.0487s\n",
      "-------- Epoch 404 --------\n",
      "epoch: 00404 loss_train: 0.00008 loss_val: 0.00008 violation_train: 0.06898 violation_val: 0.07007 time: 0.0476s\n",
      "-------- Epoch 405 --------\n",
      "epoch: 00405 loss_train: 0.00008 loss_val: 0.00008 violation_train: 0.06840 violation_val: 0.07099 time: 0.0472s\n",
      "-------- Epoch 406 --------\n",
      "epoch: 00406 loss_train: 0.00008 loss_val: 0.00009 violation_train: 0.06812 violation_val: 0.07044 time: 0.0474s\n",
      "-------- Epoch 407 --------\n",
      "epoch: 00407 loss_train: 0.00008 loss_val: 0.00009 violation_train: 0.06773 violation_val: 0.07080 time: 0.0475s\n",
      "-------- Epoch 408 --------\n",
      "epoch: 00408 loss_train: 0.00008 loss_val: 0.00009 violation_train: 0.06745 violation_val: 0.07001 time: 0.0479s\n",
      "-------- Epoch 409 --------\n",
      "epoch: 00409 loss_train: 0.00008 loss_val: 0.00008 violation_train: 0.06733 violation_val: 0.07114 time: 0.0474s\n",
      "-------- Epoch 410 --------\n",
      "epoch: 00410 loss_train: 0.00008 loss_val: 0.00008 violation_train: 0.06704 violation_val: 0.07042 time: 0.0477s\n",
      "-------- Epoch 411 --------\n",
      "epoch: 00411 loss_train: 0.00008 loss_val: 0.00008 violation_train: 0.06655 violation_val: 0.07121 time: 0.0475s\n",
      "-------- Epoch 412 --------\n",
      "epoch: 00412 loss_train: 0.00008 loss_val: 0.00008 violation_train: 0.06686 violation_val: 0.06843 time: 0.0473s\n",
      "-------- Epoch 413 --------\n",
      "epoch: 00413 loss_train: 0.00007 loss_val: 0.00009 violation_train: 0.06619 violation_val: 0.06830 time: 0.0481s\n",
      "-------- Epoch 414 --------\n",
      "epoch: 00414 loss_train: 0.00008 loss_val: 0.00008 violation_train: 0.06604 violation_val: 0.06716 time: 0.0474s\n",
      "-------- Epoch 415 --------\n",
      "epoch: 00415 loss_train: 0.00007 loss_val: 0.00008 violation_train: 0.06610 violation_val: 0.06997 time: 0.0469s\n",
      "-------- Epoch 416 --------\n",
      "epoch: 00416 loss_train: 0.00007 loss_val: 0.00008 violation_train: 0.06573 violation_val: 0.06816 time: 0.0472s\n",
      "-------- Epoch 417 --------\n",
      "epoch: 00417 loss_train: 0.00007 loss_val: 0.00008 violation_train: 0.06583 violation_val: 0.06743 time: 0.0468s\n",
      "-------- Epoch 418 --------\n",
      "epoch: 00418 loss_train: 0.00007 loss_val: 0.00008 violation_train: 0.06495 violation_val: 0.06826 time: 0.0481s\n",
      "-------- Epoch 419 --------\n",
      "epoch: 00419 loss_train: 0.00007 loss_val: 0.00008 violation_train: 0.06492 violation_val: 0.06829 time: 0.0478s\n",
      "-------- Epoch 420 --------\n",
      "epoch: 00420 loss_train: 0.00007 loss_val: 0.00008 violation_train: 0.06461 violation_val: 0.06731 time: 0.0472s\n",
      "-------- Epoch 421 --------\n",
      "epoch: 00421 loss_train: 0.00007 loss_val: 0.00008 violation_train: 0.06477 violation_val: 0.06709 time: 0.0470s\n",
      "-------- Epoch 422 --------\n",
      "epoch: 00422 loss_train: 0.00007 loss_val: 0.00008 violation_train: 0.06431 violation_val: 0.06784 time: 0.0477s\n",
      "-------- Epoch 423 --------\n",
      "epoch: 00423 loss_train: 0.00007 loss_val: 0.00008 violation_train: 0.06371 violation_val: 0.06690 time: 0.0480s\n",
      "-------- Epoch 424 --------\n",
      "epoch: 00424 loss_train: 0.00007 loss_val: 0.00008 violation_train: 0.06401 violation_val: 0.06813 time: 0.0479s\n",
      "-------- Epoch 425 --------\n",
      "epoch: 00425 loss_train: 0.00007 loss_val: 0.00008 violation_train: 0.06327 violation_val: 0.06586 time: 0.0477s\n",
      "-------- Epoch 426 --------\n",
      "epoch: 00426 loss_train: 0.00007 loss_val: 0.00008 violation_train: 0.06349 violation_val: 0.06961 time: 0.0474s\n",
      "-------- Epoch 427 --------\n",
      "epoch: 00427 loss_train: 0.00007 loss_val: 0.00008 violation_train: 0.06298 violation_val: 0.06578 time: 0.0473s\n",
      "-------- Epoch 428 --------\n",
      "epoch: 00428 loss_train: 0.00007 loss_val: 0.00008 violation_train: 0.06277 violation_val: 0.06701 time: 0.0489s\n",
      "-------- Epoch 429 --------\n",
      "epoch: 00429 loss_train: 0.00007 loss_val: 0.00008 violation_train: 0.06256 violation_val: 0.06522 time: 0.0479s\n",
      "-------- Epoch 430 --------\n",
      "epoch: 00430 loss_train: 0.00007 loss_val: 0.00008 violation_train: 0.06248 violation_val: 0.06491 time: 0.0467s\n",
      "-------- Epoch 431 --------\n",
      "epoch: 00431 loss_train: 0.00007 loss_val: 0.00008 violation_train: 0.06185 violation_val: 0.06501 time: 0.0476s\n",
      "-------- Epoch 432 --------\n",
      "epoch: 00432 loss_train: 0.00007 loss_val: 0.00008 violation_train: 0.06165 violation_val: 0.06426 time: 0.0478s\n",
      "-------- Epoch 433 --------\n",
      "epoch: 00433 loss_train: 0.00007 loss_val: 0.00008 violation_train: 0.06166 violation_val: 0.06762 time: 0.0490s\n",
      "-------- Epoch 434 --------\n",
      "epoch: 00434 loss_train: 0.00007 loss_val: 0.00008 violation_train: 0.06146 violation_val: 0.06295 time: 0.0478s\n",
      "-------- Epoch 435 --------\n",
      "epoch: 00435 loss_train: 0.00007 loss_val: 0.00008 violation_train: 0.06109 violation_val: 0.06295 time: 0.0478s\n",
      "-------- Epoch 436 --------\n",
      "epoch: 00436 loss_train: 0.00007 loss_val: 0.00008 violation_train: 0.06063 violation_val: 0.06390 time: 0.0469s\n",
      "-------- Epoch 437 --------\n",
      "epoch: 00437 loss_train: 0.00007 loss_val: 0.00008 violation_train: 0.06066 violation_val: 0.06344 time: 0.0471s\n",
      "-------- Epoch 438 --------\n",
      "epoch: 00438 loss_train: 0.00007 loss_val: 0.00007 violation_train: 0.06064 violation_val: 0.06274 time: 0.0484s\n",
      "-------- Epoch 439 --------\n",
      "epoch: 00439 loss_train: 0.00007 loss_val: 0.00008 violation_train: 0.06017 violation_val: 0.06242 time: 0.0474s\n",
      "-------- Epoch 440 --------\n",
      "epoch: 00440 loss_train: 0.00007 loss_val: 0.00007 violation_train: 0.06069 violation_val: 0.06326 time: 0.0476s\n",
      "-------- Epoch 441 --------\n",
      "epoch: 00441 loss_train: 0.00007 loss_val: 0.00007 violation_train: 0.06013 violation_val: 0.06205 time: 0.0471s\n",
      "-------- Epoch 442 --------\n",
      "epoch: 00442 loss_train: 0.00007 loss_val: 0.00008 violation_train: 0.05968 violation_val: 0.06232 time: 0.0469s\n",
      "-------- Epoch 443 --------\n",
      "epoch: 00443 loss_train: 0.00007 loss_val: 0.00007 violation_train: 0.05963 violation_val: 0.06246 time: 0.0483s\n",
      "-------- Epoch 444 --------\n",
      "epoch: 00444 loss_train: 0.00007 loss_val: 0.00007 violation_train: 0.05928 violation_val: 0.06306 time: 0.0481s\n",
      "-------- Epoch 445 --------\n",
      "epoch: 00445 loss_train: 0.00007 loss_val: 0.00007 violation_train: 0.05954 violation_val: 0.06213 time: 0.0472s\n",
      "-------- Epoch 446 --------\n",
      "epoch: 00446 loss_train: 0.00007 loss_val: 0.00007 violation_train: 0.05929 violation_val: 0.06230 time: 0.0475s\n",
      "-------- Epoch 447 --------\n",
      "epoch: 00447 loss_train: 0.00007 loss_val: 0.00008 violation_train: 0.05877 violation_val: 0.06422 time: 0.0471s\n",
      "-------- Epoch 448 --------\n",
      "epoch: 00448 loss_train: 0.00007 loss_val: 0.00007 violation_train: 0.05877 violation_val: 0.06116 time: 0.0487s\n",
      "-------- Epoch 449 --------\n",
      "epoch: 00449 loss_train: 0.00007 loss_val: 0.00007 violation_train: 0.05880 violation_val: 0.06589 time: 0.0475s\n",
      "-------- Epoch 450 --------\n",
      "epoch: 00450 loss_train: 0.00007 loss_val: 0.00007 violation_train: 0.05854 violation_val: 0.06106 time: 0.0474s\n",
      "-------- Epoch 451 --------\n",
      "epoch: 00451 loss_train: 0.00007 loss_val: 0.00007 violation_train: 0.05811 violation_val: 0.06233 time: 0.0474s\n",
      "-------- Epoch 452 --------\n",
      "epoch: 00452 loss_train: 0.00007 loss_val: 0.00007 violation_train: 0.05769 violation_val: 0.06283 time: 0.0475s\n",
      "-------- Epoch 453 --------\n",
      "epoch: 00453 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.05811 violation_val: 0.06289 time: 0.0480s\n",
      "-------- Epoch 454 --------\n",
      "epoch: 00454 loss_train: 0.00007 loss_val: 0.00007 violation_train: 0.05758 violation_val: 0.06020 time: 0.0493s\n",
      "-------- Epoch 455 --------\n",
      "epoch: 00455 loss_train: 0.00006 loss_val: 0.00008 violation_train: 0.05743 violation_val: 0.06264 time: 0.0500s\n",
      "-------- Epoch 456 --------\n",
      "epoch: 00456 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.05695 violation_val: 0.05974 time: 0.0508s\n",
      "-------- Epoch 457 --------\n",
      "epoch: 00457 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.05719 violation_val: 0.06183 time: 0.0505s\n",
      "-------- Epoch 458 --------\n",
      "epoch: 00458 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.05709 violation_val: 0.05945 time: 0.0523s\n",
      "-------- Epoch 459 --------\n",
      "epoch: 00459 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.05630 violation_val: 0.06342 time: 0.0483s\n",
      "-------- Epoch 460 --------\n",
      "epoch: 00460 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.05669 violation_val: 0.06162 time: 0.0472s\n",
      "-------- Epoch 461 --------\n",
      "epoch: 00461 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.05625 violation_val: 0.05907 time: 0.0468s\n",
      "-------- Epoch 462 --------\n",
      "epoch: 00462 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.05655 violation_val: 0.05889 time: 0.0474s\n",
      "-------- Epoch 463 --------\n",
      "epoch: 00463 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.05597 violation_val: 0.05931 time: 0.0478s\n",
      "-------- Epoch 464 --------\n",
      "epoch: 00464 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.05580 violation_val: 0.05860 time: 0.0474s\n",
      "-------- Epoch 465 --------\n",
      "epoch: 00465 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.05551 violation_val: 0.05916 time: 0.0472s\n",
      "-------- Epoch 466 --------\n",
      "epoch: 00466 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.05543 violation_val: 0.05758 time: 0.0479s\n",
      "-------- Epoch 467 --------\n",
      "epoch: 00467 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.05524 violation_val: 0.06099 time: 0.0498s\n",
      "-------- Epoch 468 --------\n",
      "epoch: 00468 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.05497 violation_val: 0.06230 time: 0.0509s\n",
      "-------- Epoch 469 --------\n",
      "epoch: 00469 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.05530 violation_val: 0.05757 time: 0.0505s\n",
      "-------- Epoch 470 --------\n",
      "epoch: 00470 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.05439 violation_val: 0.05985 time: 0.0506s\n",
      "-------- Epoch 471 --------\n",
      "epoch: 00471 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.05426 violation_val: 0.05763 time: 0.0522s\n",
      "-------- Epoch 472 --------\n",
      "epoch: 00472 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.05431 violation_val: 0.05675 time: 0.0513s\n",
      "-------- Epoch 473 --------\n",
      "epoch: 00473 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.05387 violation_val: 0.05715 time: 0.0506s\n",
      "-------- Epoch 474 --------\n",
      "epoch: 00474 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.05346 violation_val: 0.05727 time: 0.0484s\n",
      "-------- Epoch 475 --------\n",
      "epoch: 00475 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.05331 violation_val: 0.05609 time: 0.0481s\n",
      "-------- Epoch 476 --------\n",
      "epoch: 00476 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.05318 violation_val: 0.05590 time: 0.0499s\n",
      "-------- Epoch 477 --------\n",
      "epoch: 00477 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.05268 violation_val: 0.05525 time: 0.0507s\n",
      "-------- Epoch 478 --------\n",
      "epoch: 00478 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.05277 violation_val: 0.05628 time: 0.0495s\n",
      "-------- Epoch 479 --------\n",
      "epoch: 00479 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.05363 violation_val: 0.05655 time: 0.0509s\n",
      "-------- Epoch 480 --------\n",
      "epoch: 00480 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.05267 violation_val: 0.05648 time: 0.0499s\n",
      "-------- Epoch 481 --------\n",
      "epoch: 00481 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.05236 violation_val: 0.05681 time: 0.0504s\n",
      "-------- Epoch 482 --------\n",
      "epoch: 00482 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.05212 violation_val: 0.05503 time: 0.0496s\n",
      "-------- Epoch 483 --------\n",
      "epoch: 00483 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.05255 violation_val: 0.05620 time: 0.0481s\n",
      "-------- Epoch 484 --------\n",
      "epoch: 00484 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.05190 violation_val: 0.05543 time: 0.0473s\n",
      "-------- Epoch 485 --------\n",
      "epoch: 00485 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.05180 violation_val: 0.05737 time: 0.0479s\n",
      "-------- Epoch 486 --------\n",
      "epoch: 00486 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.05161 violation_val: 0.05439 time: 0.0469s\n",
      "-------- Epoch 487 --------\n",
      "epoch: 00487 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.05130 violation_val: 0.05506 time: 0.0478s\n",
      "-------- Epoch 488 --------\n",
      "epoch: 00488 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.05131 violation_val: 0.05576 time: 0.0476s\n",
      "-------- Epoch 489 --------\n",
      "epoch: 00489 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.05078 violation_val: 0.05570 time: 0.0472s\n",
      "-------- Epoch 490 --------\n",
      "epoch: 00490 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.05073 violation_val: 0.05469 time: 0.0471s\n",
      "-------- Epoch 491 --------\n",
      "epoch: 00491 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.05044 violation_val: 0.05450 time: 0.0468s\n",
      "-------- Epoch 492 --------\n",
      "epoch: 00492 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.05107 violation_val: 0.05579 time: 0.0486s\n",
      "-------- Epoch 493 --------\n",
      "epoch: 00493 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.05025 violation_val: 0.05441 time: 0.0498s\n",
      "-------- Epoch 494 --------\n",
      "epoch: 00494 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.05021 violation_val: 0.05328 time: 0.0483s\n",
      "-------- Epoch 495 --------\n",
      "epoch: 00495 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.04981 violation_val: 0.05306 time: 0.0482s\n",
      "-------- Epoch 496 --------\n",
      "epoch: 00496 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.04968 violation_val: 0.05353 time: 0.0469s\n",
      "-------- Epoch 497 --------\n",
      "epoch: 00497 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.04993 violation_val: 0.05503 time: 0.0484s\n",
      "-------- Epoch 498 --------\n",
      "epoch: 00498 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.04960 violation_val: 0.05428 time: 0.0476s\n",
      "-------- Epoch 499 --------\n",
      "epoch: 00499 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.04998 violation_val: 0.05252 time: 0.0474s\n",
      "-------- Epoch 500 --------\n",
      "epoch: 00500 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.04917 violation_val: 0.05522 time: 0.0471s\n",
      "-------- Epoch 501 --------\n",
      "epoch: 00501 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.04907 violation_val: 0.05361 time: 0.0470s\n",
      "-------- Epoch 502 --------\n",
      "epoch: 00502 loss_train: 0.00006 loss_val: 0.00006 violation_train: 0.04907 violation_val: 0.05323 time: 0.0479s\n",
      "-------- Epoch 503 --------\n",
      "epoch: 00503 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.04976 violation_val: 0.05234 time: 0.0473s\n",
      "-------- Epoch 504 --------\n",
      "epoch: 00504 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.04971 violation_val: 0.05313 time: 0.0493s\n",
      "-------- Epoch 505 --------\n",
      "epoch: 00505 loss_train: 0.00006 loss_val: 0.00006 violation_train: 0.04907 violation_val: 0.05388 time: 0.0494s\n",
      "-------- Epoch 506 --------\n",
      "epoch: 00506 loss_train: 0.00006 loss_val: 0.00006 violation_train: 0.04840 violation_val: 0.05236 time: 0.0481s\n",
      "-------- Epoch 507 --------\n",
      "epoch: 00507 loss_train: 0.00006 loss_val: 0.00006 violation_train: 0.04829 violation_val: 0.05277 time: 0.0481s\n",
      "-------- Epoch 508 --------\n",
      "epoch: 00508 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.04833 violation_val: 0.05144 time: 0.0472s\n",
      "-------- Epoch 509 --------\n",
      "epoch: 00509 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.04843 violation_val: 0.05157 time: 0.0468s\n",
      "-------- Epoch 510 --------\n",
      "epoch: 00510 loss_train: 0.00006 loss_val: 0.00006 violation_train: 0.04770 violation_val: 0.05098 time: 0.0473s\n",
      "-------- Epoch 511 --------\n",
      "epoch: 00511 loss_train: 0.00006 loss_val: 0.00006 violation_train: 0.04775 violation_val: 0.05365 time: 0.0469s\n",
      "-------- Epoch 512 --------\n",
      "epoch: 00512 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.04777 violation_val: 0.05203 time: 0.0479s\n",
      "-------- Epoch 513 --------\n",
      "epoch: 00513 loss_train: 0.00006 loss_val: 0.00006 violation_train: 0.04755 violation_val: 0.05082 time: 0.0473s\n",
      "-------- Epoch 514 --------\n",
      "epoch: 00514 loss_train: 0.00006 loss_val: 0.00006 violation_train: 0.04752 violation_val: 0.05186 time: 0.0474s\n",
      "-------- Epoch 515 --------\n",
      "epoch: 00515 loss_train: 0.00006 loss_val: 0.00006 violation_train: 0.04729 violation_val: 0.05083 time: 0.0473s\n",
      "-------- Epoch 516 --------\n",
      "epoch: 00516 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.04755 violation_val: 0.05108 time: 0.0476s\n",
      "-------- Epoch 517 --------\n",
      "epoch: 00517 loss_train: 0.00006 loss_val: 0.00007 violation_train: 0.04686 violation_val: 0.05310 time: 0.0478s\n",
      "-------- Epoch 518 --------\n",
      "epoch: 00518 loss_train: 0.00006 loss_val: 0.00006 violation_train: 0.04738 violation_val: 0.05196 time: 0.0470s\n",
      "-------- Epoch 519 --------\n",
      "epoch: 00519 loss_train: 0.00006 loss_val: 0.00006 violation_train: 0.04703 violation_val: 0.05019 time: 0.0474s\n",
      "-------- Epoch 520 --------\n",
      "epoch: 00520 loss_train: 0.00006 loss_val: 0.00006 violation_train: 0.04686 violation_val: 0.05043 time: 0.0471s\n",
      "-------- Epoch 521 --------\n",
      "epoch: 00521 loss_train: 0.00006 loss_val: 0.00006 violation_train: 0.04670 violation_val: 0.04967 time: 0.0469s\n",
      "-------- Epoch 522 --------\n",
      "epoch: 00522 loss_train: 0.00006 loss_val: 0.00006 violation_train: 0.04636 violation_val: 0.05013 time: 0.0480s\n",
      "-------- Epoch 523 --------\n",
      "epoch: 00523 loss_train: 0.00006 loss_val: 0.00006 violation_train: 0.04619 violation_val: 0.04963 time: 0.0478s\n",
      "-------- Epoch 524 --------\n",
      "epoch: 00524 loss_train: 0.00006 loss_val: 0.00006 violation_train: 0.04643 violation_val: 0.04974 time: 0.0472s\n",
      "-------- Epoch 525 --------\n",
      "epoch: 00525 loss_train: 0.00006 loss_val: 0.00006 violation_train: 0.04634 violation_val: 0.04989 time: 0.0470s\n",
      "-------- Epoch 526 --------\n",
      "epoch: 00526 loss_train: 0.00006 loss_val: 0.00006 violation_train: 0.04603 violation_val: 0.05045 time: 0.0472s\n",
      "-------- Epoch 527 --------\n",
      "epoch: 00527 loss_train: 0.00006 loss_val: 0.00006 violation_train: 0.04640 violation_val: 0.05140 time: 0.0476s\n",
      "-------- Epoch 528 --------\n",
      "epoch: 00528 loss_train: 0.00006 loss_val: 0.00006 violation_train: 0.04629 violation_val: 0.04905 time: 0.0474s\n",
      "-------- Epoch 529 --------\n",
      "epoch: 00529 loss_train: 0.00006 loss_val: 0.00006 violation_train: 0.04551 violation_val: 0.04861 time: 0.0476s\n",
      "-------- Epoch 530 --------\n",
      "epoch: 00530 loss_train: 0.00006 loss_val: 0.00006 violation_train: 0.04575 violation_val: 0.04990 time: 0.0477s\n",
      "-------- Epoch 531 --------\n",
      "epoch: 00531 loss_train: 0.00006 loss_val: 0.00006 violation_train: 0.04531 violation_val: 0.04949 time: 0.0480s\n",
      "-------- Epoch 532 --------\n",
      "epoch: 00532 loss_train: 0.00006 loss_val: 0.00006 violation_train: 0.04546 violation_val: 0.04924 time: 0.0477s\n",
      "-------- Epoch 533 --------\n",
      "epoch: 00533 loss_train: 0.00006 loss_val: 0.00006 violation_train: 0.04519 violation_val: 0.04843 time: 0.0469s\n",
      "-------- Epoch 534 --------\n",
      "epoch: 00534 loss_train: 0.00006 loss_val: 0.00006 violation_train: 0.04540 violation_val: 0.04827 time: 0.0469s\n",
      "-------- Epoch 535 --------\n",
      "epoch: 00535 loss_train: 0.00006 loss_val: 0.00006 violation_train: 0.04512 violation_val: 0.04812 time: 0.0470s\n",
      "-------- Epoch 536 --------\n",
      "epoch: 00536 loss_train: 0.00006 loss_val: 0.00006 violation_train: 0.04485 violation_val: 0.04858 time: 0.0508s\n",
      "-------- Epoch 537 --------\n",
      "epoch: 00537 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04465 violation_val: 0.04901 time: 0.0525s\n",
      "-------- Epoch 538 --------\n",
      "epoch: 00538 loss_train: 0.00006 loss_val: 0.00006 violation_train: 0.04537 violation_val: 0.04735 time: 0.0496s\n",
      "-------- Epoch 539 --------\n",
      "epoch: 00539 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04439 violation_val: 0.04876 time: 0.0510s\n",
      "-------- Epoch 540 --------\n",
      "epoch: 00540 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04465 violation_val: 0.04832 time: 0.0498s\n",
      "-------- Epoch 541 --------\n",
      "epoch: 00541 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04414 violation_val: 0.04834 time: 0.0523s\n",
      "-------- Epoch 542 --------\n",
      "epoch: 00542 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04433 violation_val: 0.04769 time: 0.0560s\n",
      "-------- Epoch 543 --------\n",
      "epoch: 00543 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04455 violation_val: 0.04752 time: 0.0504s\n",
      "-------- Epoch 544 --------\n",
      "epoch: 00544 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04389 violation_val: 0.04828 time: 0.0503s\n",
      "-------- Epoch 545 --------\n",
      "epoch: 00545 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04371 violation_val: 0.04755 time: 0.0500s\n",
      "-------- Epoch 546 --------\n",
      "epoch: 00546 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04416 violation_val: 0.05042 time: 0.0488s\n",
      "-------- Epoch 547 --------\n",
      "epoch: 00547 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04359 violation_val: 0.04693 time: 0.0481s\n",
      "-------- Epoch 548 --------\n",
      "epoch: 00548 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04375 violation_val: 0.04754 time: 0.0469s\n",
      "-------- Epoch 549 --------\n",
      "epoch: 00549 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04348 violation_val: 0.04704 time: 0.0472s\n",
      "-------- Epoch 550 --------\n",
      "epoch: 00550 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04348 violation_val: 0.04746 time: 0.0478s\n",
      "-------- Epoch 551 --------\n",
      "epoch: 00551 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04309 violation_val: 0.04649 time: 0.0480s\n",
      "-------- Epoch 552 --------\n",
      "epoch: 00552 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04334 violation_val: 0.04626 time: 0.0474s\n",
      "-------- Epoch 553 --------\n",
      "epoch: 00553 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04313 violation_val: 0.04671 time: 0.0490s\n",
      "-------- Epoch 554 --------\n",
      "epoch: 00554 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04327 violation_val: 0.04672 time: 0.0480s\n",
      "-------- Epoch 555 --------\n",
      "epoch: 00555 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04274 violation_val: 0.04616 time: 0.0490s\n",
      "-------- Epoch 556 --------\n",
      "epoch: 00556 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04333 violation_val: 0.04565 time: 0.0475s\n",
      "-------- Epoch 557 --------\n",
      "epoch: 00557 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04216 violation_val: 0.04705 time: 0.0472s\n",
      "-------- Epoch 558 --------\n",
      "epoch: 00558 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04301 violation_val: 0.04936 time: 0.0473s\n",
      "-------- Epoch 559 --------\n",
      "epoch: 00559 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04341 violation_val: 0.04589 time: 0.0501s\n",
      "-------- Epoch 560 --------\n",
      "epoch: 00560 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04232 violation_val: 0.04570 time: 0.0554s\n",
      "-------- Epoch 561 --------\n",
      "epoch: 00561 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04213 violation_val: 0.04776 time: 0.0540s\n",
      "-------- Epoch 562 --------\n",
      "epoch: 00562 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04271 violation_val: 0.04537 time: 0.0504s\n",
      "-------- Epoch 563 --------\n",
      "epoch: 00563 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04264 violation_val: 0.04548 time: 0.0505s\n",
      "-------- Epoch 564 --------\n",
      "epoch: 00564 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04228 violation_val: 0.04518 time: 0.0574s\n",
      "-------- Epoch 565 --------\n",
      "epoch: 00565 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04200 violation_val: 0.04562 time: 0.0548s\n",
      "-------- Epoch 566 --------\n",
      "epoch: 00566 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04173 violation_val: 0.04588 time: 0.0513s\n",
      "-------- Epoch 567 --------\n",
      "epoch: 00567 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04149 violation_val: 0.04572 time: 0.0528s\n",
      "-------- Epoch 568 --------\n",
      "epoch: 00568 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04171 violation_val: 0.04710 time: 0.0482s\n",
      "-------- Epoch 569 --------\n",
      "epoch: 00569 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04170 violation_val: 0.04653 time: 0.0471s\n",
      "-------- Epoch 570 --------\n",
      "epoch: 00570 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04173 violation_val: 0.04514 time: 0.0469s\n",
      "-------- Epoch 571 --------\n",
      "epoch: 00571 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04155 violation_val: 0.04500 time: 0.0514s\n",
      "-------- Epoch 572 --------\n",
      "epoch: 00572 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04150 violation_val: 0.04497 time: 0.0511s\n",
      "-------- Epoch 573 --------\n",
      "epoch: 00573 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04127 violation_val: 0.04417 time: 0.0498s\n",
      "-------- Epoch 574 --------\n",
      "epoch: 00574 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04103 violation_val: 0.04477 time: 0.0491s\n",
      "-------- Epoch 575 --------\n",
      "epoch: 00575 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04098 violation_val: 0.04376 time: 0.0499s\n",
      "-------- Epoch 576 --------\n",
      "epoch: 00576 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04126 violation_val: 0.04545 time: 0.0488s\n",
      "-------- Epoch 577 --------\n",
      "epoch: 00577 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04062 violation_val: 0.04379 time: 0.0496s\n",
      "-------- Epoch 578 --------\n",
      "epoch: 00578 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04048 violation_val: 0.04396 time: 0.0490s\n",
      "-------- Epoch 579 --------\n",
      "epoch: 00579 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04066 violation_val: 0.04384 time: 0.0494s\n",
      "-------- Epoch 580 --------\n",
      "epoch: 00580 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04089 violation_val: 0.04495 time: 0.0486s\n",
      "-------- Epoch 581 --------\n",
      "epoch: 00581 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04042 violation_val: 0.04593 time: 0.0479s\n",
      "-------- Epoch 582 --------\n",
      "epoch: 00582 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04027 violation_val: 0.04403 time: 0.0478s\n",
      "-------- Epoch 583 --------\n",
      "epoch: 00583 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04030 violation_val: 0.04318 time: 0.0497s\n",
      "-------- Epoch 584 --------\n",
      "epoch: 00584 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04054 violation_val: 0.04358 time: 0.0490s\n",
      "-------- Epoch 585 --------\n",
      "epoch: 00585 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04107 violation_val: 0.04356 time: 0.0487s\n",
      "-------- Epoch 586 --------\n",
      "epoch: 00586 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04015 violation_val: 0.04431 time: 0.0481s\n",
      "-------- Epoch 587 --------\n",
      "epoch: 00587 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04010 violation_val: 0.04365 time: 0.0478s\n",
      "-------- Epoch 588 --------\n",
      "epoch: 00588 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.03980 violation_val: 0.04262 time: 0.0478s\n",
      "-------- Epoch 589 --------\n",
      "epoch: 00589 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.03972 violation_val: 0.04377 time: 0.0471s\n",
      "-------- Epoch 590 --------\n",
      "epoch: 00590 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.03986 violation_val: 0.04304 time: 0.0464s\n",
      "-------- Epoch 591 --------\n",
      "epoch: 00591 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.04005 violation_val: 0.04515 time: 0.0463s\n",
      "-------- Epoch 592 --------\n",
      "epoch: 00592 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.03989 violation_val: 0.04211 time: 0.0469s\n",
      "-------- Epoch 593 --------\n",
      "epoch: 00593 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.03932 violation_val: 0.04262 time: 0.0480s\n",
      "-------- Epoch 594 --------\n",
      "epoch: 00594 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.03941 violation_val: 0.04237 time: 0.0499s\n",
      "-------- Epoch 595 --------\n",
      "epoch: 00595 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03952 violation_val: 0.04255 time: 0.0490s\n",
      "-------- Epoch 596 --------\n",
      "epoch: 00596 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.03950 violation_val: 0.04246 time: 0.0481s\n",
      "-------- Epoch 597 --------\n",
      "epoch: 00597 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03945 violation_val: 0.04238 time: 0.0478s\n",
      "-------- Epoch 598 --------\n",
      "epoch: 00598 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03930 violation_val: 0.04266 time: 0.0477s\n",
      "-------- Epoch 599 --------\n",
      "epoch: 00599 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.03941 violation_val: 0.04339 time: 0.0469s\n",
      "-------- Epoch 600 --------\n",
      "epoch: 00600 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.03985 violation_val: 0.04236 time: 0.0466s\n",
      "-------- Epoch 601 --------\n",
      "epoch: 00601 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03919 violation_val: 0.04445 time: 0.0468s\n",
      "-------- Epoch 602 --------\n",
      "epoch: 00602 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03936 violation_val: 0.04264 time: 0.0464s\n",
      "-------- Epoch 603 --------\n",
      "epoch: 00603 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03887 violation_val: 0.04244 time: 0.0476s\n",
      "-------- Epoch 604 --------\n",
      "epoch: 00604 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.03894 violation_val: 0.04223 time: 0.0469s\n",
      "-------- Epoch 605 --------\n",
      "epoch: 00605 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03937 violation_val: 0.04197 time: 0.0467s\n",
      "-------- Epoch 606 --------\n",
      "epoch: 00606 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.03861 violation_val: 0.04172 time: 0.0464s\n",
      "-------- Epoch 607 --------\n",
      "epoch: 00607 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03875 violation_val: 0.04165 time: 0.0469s\n",
      "-------- Epoch 608 --------\n",
      "epoch: 00608 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.03910 violation_val: 0.04421 time: 0.0488s\n",
      "-------- Epoch 609 --------\n",
      "epoch: 00609 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03868 violation_val: 0.04108 time: 0.0469s\n",
      "-------- Epoch 610 --------\n",
      "epoch: 00610 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03812 violation_val: 0.04218 time: 0.0467s\n",
      "-------- Epoch 611 --------\n",
      "epoch: 00611 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03831 violation_val: 0.04149 time: 0.0465s\n",
      "-------- Epoch 612 --------\n",
      "epoch: 00612 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03868 violation_val: 0.04164 time: 0.0464s\n",
      "-------- Epoch 613 --------\n",
      "epoch: 00613 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.03808 violation_val: 0.04177 time: 0.0473s\n",
      "-------- Epoch 614 --------\n",
      "epoch: 00614 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03822 violation_val: 0.04050 time: 0.0467s\n",
      "-------- Epoch 615 --------\n",
      "epoch: 00615 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03810 violation_val: 0.04121 time: 0.0465s\n",
      "-------- Epoch 616 --------\n",
      "epoch: 00616 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03777 violation_val: 0.04053 time: 0.0465s\n",
      "-------- Epoch 617 --------\n",
      "epoch: 00617 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03843 violation_val: 0.04133 time: 0.0465s\n",
      "-------- Epoch 618 --------\n",
      "epoch: 00618 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.03782 violation_val: 0.04091 time: 0.0474s\n",
      "-------- Epoch 619 --------\n",
      "epoch: 00619 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03749 violation_val: 0.04046 time: 0.0466s\n",
      "-------- Epoch 620 --------\n",
      "epoch: 00620 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03756 violation_val: 0.04034 time: 0.0464s\n",
      "-------- Epoch 621 --------\n",
      "epoch: 00621 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03780 violation_val: 0.04012 time: 0.0467s\n",
      "-------- Epoch 622 --------\n",
      "epoch: 00622 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03754 violation_val: 0.04003 time: 0.0464s\n",
      "-------- Epoch 623 --------\n",
      "epoch: 00623 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03742 violation_val: 0.04097 time: 0.0475s\n",
      "-------- Epoch 624 --------\n",
      "epoch: 00624 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03770 violation_val: 0.04026 time: 0.0466s\n",
      "-------- Epoch 625 --------\n",
      "epoch: 00625 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.03737 violation_val: 0.04052 time: 0.0463s\n",
      "-------- Epoch 626 --------\n",
      "epoch: 00626 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03747 violation_val: 0.04000 time: 0.0464s\n",
      "-------- Epoch 627 --------\n",
      "epoch: 00627 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.03757 violation_val: 0.04009 time: 0.0463s\n",
      "-------- Epoch 628 --------\n",
      "epoch: 00628 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.03722 violation_val: 0.04069 time: 0.0470s\n",
      "-------- Epoch 629 --------\n",
      "epoch: 00629 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03800 violation_val: 0.04001 time: 0.0468s\n",
      "-------- Epoch 630 --------\n",
      "epoch: 00630 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03692 violation_val: 0.04063 time: 0.0464s\n",
      "-------- Epoch 631 --------\n",
      "epoch: 00631 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03703 violation_val: 0.03978 time: 0.0465s\n",
      "-------- Epoch 632 --------\n",
      "epoch: 00632 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03710 violation_val: 0.04004 time: 0.0466s\n",
      "-------- Epoch 633 --------\n",
      "epoch: 00633 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03647 violation_val: 0.03947 time: 0.0474s\n",
      "-------- Epoch 634 --------\n",
      "epoch: 00634 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.03732 violation_val: 0.03997 time: 0.0468s\n",
      "-------- Epoch 635 --------\n",
      "epoch: 00635 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03684 violation_val: 0.04025 time: 0.0466s\n",
      "-------- Epoch 636 --------\n",
      "epoch: 00636 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03612 violation_val: 0.03960 time: 0.0464s\n",
      "-------- Epoch 637 --------\n",
      "epoch: 00637 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03679 violation_val: 0.03930 time: 0.0467s\n",
      "-------- Epoch 638 --------\n",
      "epoch: 00638 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.03647 violation_val: 0.03973 time: 0.0468s\n",
      "-------- Epoch 639 --------\n",
      "epoch: 00639 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03660 violation_val: 0.03998 time: 0.0473s\n",
      "-------- Epoch 640 --------\n",
      "epoch: 00640 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03615 violation_val: 0.03999 time: 0.0464s\n",
      "-------- Epoch 641 --------\n",
      "epoch: 00641 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03670 violation_val: 0.04075 time: 0.0463s\n",
      "-------- Epoch 642 --------\n",
      "epoch: 00642 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03654 violation_val: 0.04000 time: 0.0464s\n",
      "-------- Epoch 643 --------\n",
      "epoch: 00643 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03637 violation_val: 0.03880 time: 0.0475s\n",
      "-------- Epoch 644 --------\n",
      "epoch: 00644 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03638 violation_val: 0.03864 time: 0.0469s\n",
      "-------- Epoch 645 --------\n",
      "epoch: 00645 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.03649 violation_val: 0.04087 time: 0.0466s\n",
      "-------- Epoch 646 --------\n",
      "epoch: 00646 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03625 violation_val: 0.03885 time: 0.0465s\n",
      "-------- Epoch 647 --------\n",
      "epoch: 00647 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03617 violation_val: 0.03888 time: 0.0464s\n",
      "-------- Epoch 648 --------\n",
      "epoch: 00648 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03592 violation_val: 0.03834 time: 0.0474s\n",
      "-------- Epoch 649 --------\n",
      "epoch: 00649 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03573 violation_val: 0.03867 time: 0.0467s\n",
      "-------- Epoch 650 --------\n",
      "epoch: 00650 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03645 violation_val: 0.03843 time: 0.0497s\n",
      "-------- Epoch 651 --------\n",
      "epoch: 00651 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03677 violation_val: 0.03925 time: 0.0499s\n",
      "-------- Epoch 652 --------\n",
      "epoch: 00652 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03677 violation_val: 0.03834 time: 0.0500s\n",
      "-------- Epoch 653 --------\n",
      "epoch: 00653 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03575 violation_val: 0.03768 time: 0.0508s\n",
      "-------- Epoch 654 --------\n",
      "epoch: 00654 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03516 violation_val: 0.03936 time: 0.0503s\n",
      "-------- Epoch 655 --------\n",
      "epoch: 00655 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03563 violation_val: 0.03836 time: 0.0483s\n",
      "-------- Epoch 656 --------\n",
      "epoch: 00656 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03581 violation_val: 0.03761 time: 0.0478s\n",
      "-------- Epoch 657 --------\n",
      "epoch: 00657 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03547 violation_val: 0.03953 time: 0.0477s\n",
      "-------- Epoch 658 --------\n",
      "epoch: 00658 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03574 violation_val: 0.03835 time: 0.0480s\n",
      "-------- Epoch 659 --------\n",
      "epoch: 00659 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03586 violation_val: 0.03867 time: 0.0471s\n",
      "-------- Epoch 660 --------\n",
      "epoch: 00660 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03542 violation_val: 0.03820 time: 0.0478s\n",
      "-------- Epoch 661 --------\n",
      "epoch: 00661 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03509 violation_val: 0.03990 time: 0.0471s\n",
      "-------- Epoch 662 --------\n",
      "epoch: 00662 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03519 violation_val: 0.03746 time: 0.0464s\n",
      "-------- Epoch 663 --------\n",
      "epoch: 00663 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03554 violation_val: 0.03805 time: 0.0474s\n",
      "-------- Epoch 664 --------\n",
      "epoch: 00664 loss_train: 0.00005 loss_val: 0.00006 violation_train: 0.03543 violation_val: 0.03753 time: 0.0467s\n",
      "-------- Epoch 665 --------\n",
      "epoch: 00665 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03557 violation_val: 0.03727 time: 0.0465s\n",
      "-------- Epoch 666 --------\n",
      "epoch: 00666 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03472 violation_val: 0.03737 time: 0.0467s\n",
      "-------- Epoch 667 --------\n",
      "epoch: 00667 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03479 violation_val: 0.03744 time: 0.0466s\n",
      "-------- Epoch 668 --------\n",
      "epoch: 00668 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03538 violation_val: 0.03907 time: 0.0496s\n",
      "-------- Epoch 669 --------\n",
      "epoch: 00669 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03494 violation_val: 0.03728 time: 0.0485s\n",
      "-------- Epoch 670 --------\n",
      "epoch: 00670 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03472 violation_val: 0.03674 time: 0.0469s\n",
      "-------- Epoch 671 --------\n",
      "epoch: 00671 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03486 violation_val: 0.03710 time: 0.0465s\n",
      "-------- Epoch 672 --------\n",
      "epoch: 00672 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03511 violation_val: 0.03742 time: 0.0465s\n",
      "-------- Epoch 673 --------\n",
      "epoch: 00673 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03470 violation_val: 0.03834 time: 0.0479s\n",
      "-------- Epoch 674 --------\n",
      "epoch: 00674 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03472 violation_val: 0.03847 time: 0.0467s\n",
      "-------- Epoch 675 --------\n",
      "epoch: 00675 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03470 violation_val: 0.03687 time: 0.0465s\n",
      "-------- Epoch 676 --------\n",
      "epoch: 00676 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03451 violation_val: 0.03802 time: 0.0466s\n",
      "-------- Epoch 677 --------\n",
      "epoch: 00677 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03447 violation_val: 0.03626 time: 0.0464s\n",
      "-------- Epoch 678 --------\n",
      "epoch: 00678 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03409 violation_val: 0.03610 time: 0.0478s\n",
      "-------- Epoch 679 --------\n",
      "epoch: 00679 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03437 violation_val: 0.03660 time: 0.0467s\n",
      "-------- Epoch 680 --------\n",
      "epoch: 00680 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03468 violation_val: 0.03719 time: 0.0464s\n",
      "-------- Epoch 681 --------\n",
      "epoch: 00681 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03433 violation_val: 0.03662 time: 0.0464s\n",
      "-------- Epoch 682 --------\n",
      "epoch: 00682 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03546 violation_val: 0.03698 time: 0.0463s\n",
      "-------- Epoch 683 --------\n",
      "epoch: 00683 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03445 violation_val: 0.03676 time: 0.0474s\n",
      "-------- Epoch 684 --------\n",
      "epoch: 00684 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03412 violation_val: 0.03630 time: 0.0465s\n",
      "-------- Epoch 685 --------\n",
      "epoch: 00685 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03457 violation_val: 0.03718 time: 0.0463s\n",
      "-------- Epoch 686 --------\n",
      "epoch: 00686 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03427 violation_val: 0.03764 time: 0.0463s\n",
      "-------- Epoch 687 --------\n",
      "epoch: 00687 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03419 violation_val: 0.03713 time: 0.0463s\n",
      "-------- Epoch 688 --------\n",
      "epoch: 00688 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03393 violation_val: 0.03665 time: 0.0473s\n",
      "-------- Epoch 689 --------\n",
      "epoch: 00689 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03407 violation_val: 0.03566 time: 0.0470s\n",
      "-------- Epoch 690 --------\n",
      "epoch: 00690 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03459 violation_val: 0.03612 time: 0.0466s\n",
      "-------- Epoch 691 --------\n",
      "epoch: 00691 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03349 violation_val: 0.03622 time: 0.0464s\n",
      "-------- Epoch 692 --------\n",
      "epoch: 00692 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03347 violation_val: 0.03757 time: 0.0466s\n",
      "-------- Epoch 693 --------\n",
      "epoch: 00693 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03433 violation_val: 0.03575 time: 0.0480s\n",
      "-------- Epoch 694 --------\n",
      "epoch: 00694 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03358 violation_val: 0.03601 time: 0.0469s\n",
      "-------- Epoch 695 --------\n",
      "epoch: 00695 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03402 violation_val: 0.03549 time: 0.0469s\n",
      "-------- Epoch 696 --------\n",
      "epoch: 00696 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03341 violation_val: 0.03543 time: 0.0465s\n",
      "-------- Epoch 697 --------\n",
      "epoch: 00697 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03322 violation_val: 0.03554 time: 0.0467s\n",
      "-------- Epoch 698 --------\n",
      "epoch: 00698 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03376 violation_val: 0.03618 time: 0.0470s\n",
      "-------- Epoch 699 --------\n",
      "epoch: 00699 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03346 violation_val: 0.03870 time: 0.0467s\n",
      "-------- Epoch 700 --------\n",
      "epoch: 00700 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03391 violation_val: 0.03511 time: 0.0464s\n",
      "-------- Epoch 701 --------\n",
      "epoch: 00701 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03336 violation_val: 0.03486 time: 0.0464s\n",
      "-------- Epoch 702 --------\n",
      "epoch: 00702 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03356 violation_val: 0.03564 time: 0.0464s\n",
      "-------- Epoch 703 --------\n",
      "epoch: 00703 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03336 violation_val: 0.03552 time: 0.0475s\n",
      "-------- Epoch 704 --------\n",
      "epoch: 00704 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03349 violation_val: 0.03518 time: 0.0468s\n",
      "-------- Epoch 705 --------\n",
      "epoch: 00705 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03275 violation_val: 0.03547 time: 0.0486s\n",
      "-------- Epoch 706 --------\n",
      "epoch: 00706 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03363 violation_val: 0.03506 time: 0.0504s\n",
      "-------- Epoch 707 --------\n",
      "epoch: 00707 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03280 violation_val: 0.03531 time: 0.0488s\n",
      "-------- Epoch 708 --------\n",
      "epoch: 00708 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03311 violation_val: 0.03535 time: 0.0501s\n",
      "-------- Epoch 709 --------\n",
      "epoch: 00709 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03265 violation_val: 0.03701 time: 0.0497s\n",
      "-------- Epoch 710 --------\n",
      "epoch: 00710 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03272 violation_val: 0.03468 time: 0.0531s\n",
      "-------- Epoch 711 --------\n",
      "epoch: 00711 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03323 violation_val: 0.03588 time: 0.0514s\n",
      "-------- Epoch 712 --------\n",
      "epoch: 00712 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03296 violation_val: 0.03745 time: 0.0511s\n",
      "-------- Epoch 713 --------\n",
      "epoch: 00713 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03340 violation_val: 0.03523 time: 0.0499s\n",
      "-------- Epoch 714 --------\n",
      "epoch: 00714 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03299 violation_val: 0.03419 time: 0.0484s\n",
      "-------- Epoch 715 --------\n",
      "epoch: 00715 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03269 violation_val: 0.03450 time: 0.0476s\n",
      "-------- Epoch 716 --------\n",
      "epoch: 00716 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03286 violation_val: 0.03533 time: 0.0485s\n",
      "-------- Epoch 717 --------\n",
      "epoch: 00717 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03226 violation_val: 0.03472 time: 0.0520s\n",
      "-------- Epoch 718 --------\n",
      "epoch: 00718 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03273 violation_val: 0.03651 time: 0.0492s\n",
      "-------- Epoch 719 --------\n",
      "epoch: 00719 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03273 violation_val: 0.03542 time: 0.0493s\n",
      "-------- Epoch 720 --------\n",
      "epoch: 00720 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03236 violation_val: 0.03430 time: 0.0480s\n",
      "-------- Epoch 721 --------\n",
      "epoch: 00721 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03229 violation_val: 0.03400 time: 0.0468s\n",
      "-------- Epoch 722 --------\n",
      "epoch: 00722 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03306 violation_val: 0.03610 time: 0.0478s\n",
      "-------- Epoch 723 --------\n",
      "epoch: 00723 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03252 violation_val: 0.03474 time: 0.0486s\n",
      "-------- Epoch 724 --------\n",
      "epoch: 00724 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03264 violation_val: 0.03370 time: 0.0482s\n",
      "-------- Epoch 725 --------\n",
      "epoch: 00725 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03271 violation_val: 0.03403 time: 0.0476s\n",
      "-------- Epoch 726 --------\n",
      "epoch: 00726 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03245 violation_val: 0.03372 time: 0.0475s\n",
      "-------- Epoch 727 --------\n",
      "epoch: 00727 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03227 violation_val: 0.03375 time: 0.0480s\n",
      "-------- Epoch 728 --------\n",
      "epoch: 00728 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03235 violation_val: 0.03383 time: 0.0470s\n",
      "-------- Epoch 729 --------\n",
      "epoch: 00729 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03203 violation_val: 0.03527 time: 0.0472s\n",
      "-------- Epoch 730 --------\n",
      "epoch: 00730 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03197 violation_val: 0.03376 time: 0.0469s\n",
      "-------- Epoch 731 --------\n",
      "epoch: 00731 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03216 violation_val: 0.03397 time: 0.0472s\n",
      "-------- Epoch 732 --------\n",
      "epoch: 00732 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03184 violation_val: 0.03354 time: 0.0533s\n",
      "-------- Epoch 733 --------\n",
      "epoch: 00733 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03294 violation_val: 0.03534 time: 0.0479s\n",
      "-------- Epoch 734 --------\n",
      "epoch: 00734 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.03208 violation_val: 0.03316 time: 0.0469s\n",
      "-------- Epoch 735 --------\n",
      "epoch: 00735 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03204 violation_val: 0.03381 time: 0.0468s\n",
      "-------- Epoch 736 --------\n",
      "epoch: 00736 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03215 violation_val: 0.03313 time: 0.0470s\n",
      "-------- Epoch 737 --------\n",
      "epoch: 00737 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03219 violation_val: 0.03301 time: 0.0479s\n",
      "-------- Epoch 738 --------\n",
      "epoch: 00738 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03144 violation_val: 0.03305 time: 0.0470s\n",
      "-------- Epoch 739 --------\n",
      "epoch: 00739 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03136 violation_val: 0.03293 time: 0.0465s\n",
      "-------- Epoch 740 --------\n",
      "epoch: 00740 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03177 violation_val: 0.03526 time: 0.0466s\n",
      "-------- Epoch 741 --------\n",
      "epoch: 00741 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03121 violation_val: 0.03373 time: 0.0475s\n",
      "-------- Epoch 742 --------\n",
      "epoch: 00742 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03199 violation_val: 0.03340 time: 0.0474s\n",
      "-------- Epoch 743 --------\n",
      "epoch: 00743 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03110 violation_val: 0.03280 time: 0.0472s\n",
      "-------- Epoch 744 --------\n",
      "epoch: 00744 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03127 violation_val: 0.03284 time: 0.0465s\n",
      "-------- Epoch 745 --------\n",
      "epoch: 00745 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03232 violation_val: 0.03525 time: 0.0465s\n",
      "-------- Epoch 746 --------\n",
      "epoch: 00746 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03182 violation_val: 0.03361 time: 0.0464s\n",
      "-------- Epoch 747 --------\n",
      "epoch: 00747 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03145 violation_val: 0.03304 time: 0.0477s\n",
      "-------- Epoch 748 --------\n",
      "epoch: 00748 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03176 violation_val: 0.03312 time: 0.0475s\n",
      "-------- Epoch 749 --------\n",
      "epoch: 00749 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03143 violation_val: 0.03336 time: 0.0474s\n",
      "-------- Epoch 750 --------\n",
      "epoch: 00750 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03195 violation_val: 0.03459 time: 0.0479s\n",
      "-------- Epoch 751 --------\n",
      "epoch: 00751 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03150 violation_val: 0.03408 time: 0.0470s\n",
      "-------- Epoch 752 --------\n",
      "epoch: 00752 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03131 violation_val: 0.03498 time: 0.0476s\n",
      "-------- Epoch 753 --------\n",
      "epoch: 00753 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03141 violation_val: 0.03294 time: 0.0468s\n",
      "-------- Epoch 754 --------\n",
      "epoch: 00754 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03080 violation_val: 0.03280 time: 0.0486s\n",
      "-------- Epoch 755 --------\n",
      "epoch: 00755 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03138 violation_val: 0.03344 time: 0.0509s\n",
      "-------- Epoch 756 --------\n",
      "epoch: 00756 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03119 violation_val: 0.03185 time: 0.0502s\n",
      "-------- Epoch 757 --------\n",
      "epoch: 00757 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03113 violation_val: 0.03380 time: 0.0516s\n",
      "-------- Epoch 758 --------\n",
      "epoch: 00758 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03103 violation_val: 0.03191 time: 0.0507s\n",
      "-------- Epoch 759 --------\n",
      "epoch: 00759 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03069 violation_val: 0.03265 time: 0.0510s\n",
      "-------- Epoch 760 --------\n",
      "epoch: 00760 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03091 violation_val: 0.03212 time: 0.0485s\n",
      "-------- Epoch 761 --------\n",
      "epoch: 00761 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03095 violation_val: 0.03230 time: 0.0534s\n",
      "-------- Epoch 762 --------\n",
      "epoch: 00762 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03091 violation_val: 0.03460 time: 0.0520s\n",
      "-------- Epoch 763 --------\n",
      "epoch: 00763 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03088 violation_val: 0.03353 time: 0.0569s\n",
      "-------- Epoch 764 --------\n",
      "epoch: 00764 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03118 violation_val: 0.03293 time: 0.0532s\n",
      "-------- Epoch 765 --------\n",
      "epoch: 00765 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03078 violation_val: 0.03254 time: 0.0506s\n",
      "-------- Epoch 766 --------\n",
      "epoch: 00766 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.03068 violation_val: 0.03430 time: 0.0483s\n",
      "-------- Epoch 767 --------\n",
      "epoch: 00767 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.03102 violation_val: 0.03208 time: 0.0497s\n",
      "-------- Epoch 768 --------\n",
      "epoch: 00768 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03025 violation_val: 0.03150 time: 0.0512s\n",
      "-------- Epoch 769 --------\n",
      "epoch: 00769 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03054 violation_val: 0.03553 time: 0.0500s\n",
      "-------- Epoch 770 --------\n",
      "epoch: 00770 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03065 violation_val: 0.03183 time: 0.0519s\n",
      "-------- Epoch 771 --------\n",
      "epoch: 00771 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03068 violation_val: 0.03207 time: 0.0521s\n",
      "-------- Epoch 772 --------\n",
      "epoch: 00772 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03068 violation_val: 0.03420 time: 0.0521s\n",
      "-------- Epoch 773 --------\n",
      "epoch: 00773 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.03056 violation_val: 0.03285 time: 0.0499s\n",
      "-------- Epoch 774 --------\n",
      "epoch: 00774 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03027 violation_val: 0.03182 time: 0.0498s\n",
      "-------- Epoch 775 --------\n",
      "epoch: 00775 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03054 violation_val: 0.03311 time: 0.0484s\n",
      "-------- Epoch 776 --------\n",
      "epoch: 00776 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.03069 violation_val: 0.03277 time: 0.0479s\n",
      "-------- Epoch 777 --------\n",
      "epoch: 00777 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.03020 violation_val: 0.03174 time: 0.0474s\n",
      "-------- Epoch 778 --------\n",
      "epoch: 00778 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03041 violation_val: 0.03226 time: 0.0474s\n",
      "-------- Epoch 779 --------\n",
      "epoch: 00779 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.03011 violation_val: 0.03156 time: 0.0478s\n",
      "-------- Epoch 780 --------\n",
      "epoch: 00780 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.02983 violation_val: 0.03171 time: 0.0482s\n",
      "-------- Epoch 781 --------\n",
      "epoch: 00781 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03032 violation_val: 0.03280 time: 0.0514s\n",
      "-------- Epoch 782 --------\n",
      "epoch: 00782 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03039 violation_val: 0.03294 time: 0.0502s\n",
      "-------- Epoch 783 --------\n",
      "epoch: 00783 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.03015 violation_val: 0.03098 time: 0.0504s\n",
      "-------- Epoch 784 --------\n",
      "epoch: 00784 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.02978 violation_val: 0.03173 time: 0.0492s\n",
      "-------- Epoch 785 --------\n",
      "epoch: 00785 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03026 violation_val: 0.03133 time: 0.0481s\n",
      "-------- Epoch 786 --------\n",
      "epoch: 00786 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02977 violation_val: 0.03173 time: 0.0477s\n",
      "-------- Epoch 787 --------\n",
      "epoch: 00787 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03043 violation_val: 0.03185 time: 0.0478s\n",
      "-------- Epoch 788 --------\n",
      "epoch: 00788 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03030 violation_val: 0.03192 time: 0.0474s\n",
      "-------- Epoch 789 --------\n",
      "epoch: 00789 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.03067 violation_val: 0.03263 time: 0.0474s\n",
      "-------- Epoch 790 --------\n",
      "epoch: 00790 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.03056 violation_val: 0.03316 time: 0.0471s\n",
      "-------- Epoch 791 --------\n",
      "epoch: 00791 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.03020 violation_val: 0.03269 time: 0.0465s\n",
      "-------- Epoch 792 --------\n",
      "epoch: 00792 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.03002 violation_val: 0.03284 time: 0.0464s\n",
      "-------- Epoch 793 --------\n",
      "epoch: 00793 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.03007 violation_val: 0.03140 time: 0.0465s\n",
      "-------- Epoch 794 --------\n",
      "epoch: 00794 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.03017 violation_val: 0.03140 time: 0.0476s\n",
      "-------- Epoch 795 --------\n",
      "epoch: 00795 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02974 violation_val: 0.03160 time: 0.0468s\n",
      "-------- Epoch 796 --------\n",
      "epoch: 00796 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.03014 violation_val: 0.03100 time: 0.0467s\n",
      "-------- Epoch 797 --------\n",
      "epoch: 00797 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.03013 violation_val: 0.03220 time: 0.0468s\n",
      "-------- Epoch 798 --------\n",
      "epoch: 00798 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.03019 violation_val: 0.03157 time: 0.0493s\n",
      "-------- Epoch 799 --------\n",
      "epoch: 00799 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03018 violation_val: 0.03144 time: 0.0512s\n",
      "-------- Epoch 800 --------\n",
      "epoch: 00800 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03037 violation_val: 0.03332 time: 0.0496s\n",
      "-------- Epoch 801 --------\n",
      "epoch: 00801 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.03007 violation_val: 0.03230 time: 0.0524s\n",
      "-------- Epoch 802 --------\n",
      "epoch: 00802 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.03018 violation_val: 0.03323 time: 0.0508s\n",
      "-------- Epoch 803 --------\n",
      "epoch: 00803 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02983 violation_val: 0.03162 time: 0.0516s\n",
      "-------- Epoch 804 --------\n",
      "epoch: 00804 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03010 violation_val: 0.03086 time: 0.0488s\n",
      "-------- Epoch 805 --------\n",
      "epoch: 00805 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02977 violation_val: 0.03174 time: 0.0483s\n",
      "-------- Epoch 806 --------\n",
      "epoch: 00806 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.03028 violation_val: 0.03216 time: 0.0479s\n",
      "-------- Epoch 807 --------\n",
      "epoch: 00807 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.03076 violation_val: 0.03473 time: 0.0475s\n",
      "-------- Epoch 808 --------\n",
      "epoch: 00808 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.03005 violation_val: 0.03074 time: 0.0475s\n",
      "-------- Epoch 809 --------\n",
      "epoch: 00809 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02989 violation_val: 0.03108 time: 0.0478s\n",
      "-------- Epoch 810 --------\n",
      "epoch: 00810 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02955 violation_val: 0.03237 time: 0.0481s\n",
      "-------- Epoch 811 --------\n",
      "epoch: 00811 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02919 violation_val: 0.03037 time: 0.0477s\n",
      "-------- Epoch 812 --------\n",
      "epoch: 00812 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.02950 violation_val: 0.03364 time: 0.0474s\n",
      "-------- Epoch 813 --------\n",
      "epoch: 00813 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02958 violation_val: 0.03104 time: 0.0515s\n",
      "-------- Epoch 814 --------\n",
      "epoch: 00814 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02946 violation_val: 0.03067 time: 0.0504s\n",
      "-------- Epoch 815 --------\n",
      "epoch: 00815 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.02923 violation_val: 0.03051 time: 0.0497s\n",
      "-------- Epoch 816 --------\n",
      "epoch: 00816 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02949 violation_val: 0.03118 time: 0.0475s\n",
      "-------- Epoch 817 --------\n",
      "epoch: 00817 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02879 violation_val: 0.03035 time: 0.0507s\n",
      "-------- Epoch 818 --------\n",
      "epoch: 00818 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02893 violation_val: 0.03037 time: 0.0512s\n",
      "-------- Epoch 819 --------\n",
      "epoch: 00819 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.03051 violation_val: 0.03169 time: 0.0507s\n",
      "-------- Epoch 820 --------\n",
      "epoch: 00820 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02959 violation_val: 0.03074 time: 0.0487s\n",
      "-------- Epoch 821 --------\n",
      "epoch: 00821 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02928 violation_val: 0.03104 time: 0.0500s\n",
      "-------- Epoch 822 --------\n",
      "epoch: 00822 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02933 violation_val: 0.03044 time: 0.0522s\n",
      "-------- Epoch 823 --------\n",
      "epoch: 00823 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02873 violation_val: 0.03053 time: 0.0516s\n",
      "-------- Epoch 824 --------\n",
      "epoch: 00824 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02950 violation_val: 0.03188 time: 0.0509s\n",
      "-------- Epoch 825 --------\n",
      "epoch: 00825 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02887 violation_val: 0.03053 time: 0.0482s\n",
      "-------- Epoch 826 --------\n",
      "epoch: 00826 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02949 violation_val: 0.03459 time: 0.0477s\n",
      "-------- Epoch 827 --------\n",
      "epoch: 00827 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02931 violation_val: 0.03056 time: 0.0479s\n",
      "-------- Epoch 828 --------\n",
      "epoch: 00828 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.02931 violation_val: 0.03080 time: 0.0509s\n",
      "-------- Epoch 829 --------\n",
      "epoch: 00829 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02891 violation_val: 0.03042 time: 0.0500s\n",
      "-------- Epoch 830 --------\n",
      "epoch: 00830 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02877 violation_val: 0.03329 time: 0.0507s\n",
      "-------- Epoch 831 --------\n",
      "epoch: 00831 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02940 violation_val: 0.03351 time: 0.0500s\n",
      "-------- Epoch 832 --------\n",
      "epoch: 00832 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02849 violation_val: 0.03033 time: 0.0501s\n",
      "-------- Epoch 833 --------\n",
      "epoch: 00833 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02869 violation_val: 0.03062 time: 0.0506s\n",
      "-------- Epoch 834 --------\n",
      "epoch: 00834 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02863 violation_val: 0.02976 time: 0.0499s\n",
      "-------- Epoch 835 --------\n",
      "epoch: 00835 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02920 violation_val: 0.02972 time: 0.0497s\n",
      "-------- Epoch 836 --------\n",
      "epoch: 00836 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02845 violation_val: 0.03089 time: 0.0480s\n",
      "-------- Epoch 837 --------\n",
      "epoch: 00837 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02849 violation_val: 0.02989 time: 0.0486s\n",
      "-------- Epoch 838 --------\n",
      "epoch: 00838 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02863 violation_val: 0.03243 time: 0.0489s\n",
      "-------- Epoch 839 --------\n",
      "epoch: 00839 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02860 violation_val: 0.03014 time: 0.0470s\n",
      "-------- Epoch 840 --------\n",
      "epoch: 00840 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02851 violation_val: 0.03100 time: 0.0504s\n",
      "-------- Epoch 841 --------\n",
      "epoch: 00841 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.02862 violation_val: 0.03000 time: 0.0520s\n",
      "-------- Epoch 842 --------\n",
      "epoch: 00842 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02838 violation_val: 0.02933 time: 0.0526s\n",
      "-------- Epoch 843 --------\n",
      "epoch: 00843 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02880 violation_val: 0.03008 time: 0.0488s\n",
      "-------- Epoch 844 --------\n",
      "epoch: 00844 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02838 violation_val: 0.03159 time: 0.0481s\n",
      "-------- Epoch 845 --------\n",
      "epoch: 00845 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02848 violation_val: 0.03025 time: 0.0475s\n",
      "-------- Epoch 846 --------\n",
      "epoch: 00846 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02876 violation_val: 0.02993 time: 0.0730s\n",
      "-------- Epoch 847 --------\n",
      "epoch: 00847 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02865 violation_val: 0.02929 time: 0.0844s\n",
      "-------- Epoch 848 --------\n",
      "epoch: 00848 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02832 violation_val: 0.02920 time: 0.0551s\n",
      "-------- Epoch 849 --------\n",
      "epoch: 00849 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02814 violation_val: 0.02996 time: 0.0586s\n",
      "-------- Epoch 850 --------\n",
      "epoch: 00850 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02858 violation_val: 0.02960 time: 0.0546s\n",
      "-------- Epoch 851 --------\n",
      "epoch: 00851 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02849 violation_val: 0.03126 time: 0.0717s\n",
      "-------- Epoch 852 --------\n",
      "epoch: 00852 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02877 violation_val: 0.02979 time: 0.0661s\n",
      "-------- Epoch 853 --------\n",
      "epoch: 00853 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02862 violation_val: 0.02898 time: 0.0535s\n",
      "-------- Epoch 854 --------\n",
      "epoch: 00854 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02817 violation_val: 0.02994 time: 0.0528s\n",
      "-------- Epoch 855 --------\n",
      "epoch: 00855 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02850 violation_val: 0.02985 time: 0.0504s\n",
      "-------- Epoch 856 --------\n",
      "epoch: 00856 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02790 violation_val: 0.03189 time: 0.0516s\n",
      "-------- Epoch 857 --------\n",
      "epoch: 00857 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02805 violation_val: 0.03127 time: 0.0542s\n",
      "-------- Epoch 858 --------\n",
      "epoch: 00858 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02832 violation_val: 0.03061 time: 0.0532s\n",
      "-------- Epoch 859 --------\n",
      "epoch: 00859 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02815 violation_val: 0.02953 time: 0.0523s\n",
      "-------- Epoch 860 --------\n",
      "epoch: 00860 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02772 violation_val: 0.02950 time: 0.0539s\n",
      "-------- Epoch 861 --------\n",
      "epoch: 00861 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02816 violation_val: 0.03036 time: 0.0512s\n",
      "-------- Epoch 862 --------\n",
      "epoch: 00862 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02798 violation_val: 0.02925 time: 0.0491s\n",
      "-------- Epoch 863 --------\n",
      "epoch: 00863 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02794 violation_val: 0.03041 time: 0.0515s\n",
      "-------- Epoch 864 --------\n",
      "epoch: 00864 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02782 violation_val: 0.03218 time: 0.0521s\n",
      "-------- Epoch 865 --------\n",
      "epoch: 00865 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02836 violation_val: 0.02926 time: 0.0490s\n",
      "-------- Epoch 866 --------\n",
      "epoch: 00866 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02849 violation_val: 0.02984 time: 0.0480s\n",
      "-------- Epoch 867 --------\n",
      "epoch: 00867 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02743 violation_val: 0.03136 time: 0.0488s\n",
      "-------- Epoch 868 --------\n",
      "epoch: 00868 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02875 violation_val: 0.03079 time: 0.0482s\n",
      "-------- Epoch 869 --------\n",
      "epoch: 00869 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02763 violation_val: 0.03057 time: 0.0476s\n",
      "-------- Epoch 870 --------\n",
      "epoch: 00870 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02734 violation_val: 0.02916 time: 0.0513s\n",
      "-------- Epoch 871 --------\n",
      "epoch: 00871 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02801 violation_val: 0.02943 time: 0.0502s\n",
      "-------- Epoch 872 --------\n",
      "epoch: 00872 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02727 violation_val: 0.02865 time: 0.0521s\n",
      "-------- Epoch 873 --------\n",
      "epoch: 00873 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02772 violation_val: 0.03175 time: 0.0510s\n",
      "-------- Epoch 874 --------\n",
      "epoch: 00874 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02792 violation_val: 0.02940 time: 0.0488s\n",
      "-------- Epoch 875 --------\n",
      "epoch: 00875 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02784 violation_val: 0.03090 time: 0.0481s\n",
      "-------- Epoch 876 --------\n",
      "epoch: 00876 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02783 violation_val: 0.02932 time: 0.0475s\n",
      "-------- Epoch 877 --------\n",
      "epoch: 00877 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02775 violation_val: 0.03010 time: 0.0484s\n",
      "-------- Epoch 878 --------\n",
      "epoch: 00878 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02770 violation_val: 0.02954 time: 0.0474s\n",
      "-------- Epoch 879 --------\n",
      "epoch: 00879 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02814 violation_val: 0.02986 time: 0.0474s\n",
      "-------- Epoch 880 --------\n",
      "epoch: 00880 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02712 violation_val: 0.02889 time: 0.0505s\n",
      "-------- Epoch 881 --------\n",
      "epoch: 00881 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02804 violation_val: 0.03056 time: 0.0496s\n",
      "-------- Epoch 882 --------\n",
      "epoch: 00882 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02749 violation_val: 0.03038 time: 0.0481s\n",
      "-------- Epoch 883 --------\n",
      "epoch: 00883 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02789 violation_val: 0.03029 time: 0.0472s\n",
      "-------- Epoch 884 --------\n",
      "epoch: 00884 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02751 violation_val: 0.02931 time: 0.0464s\n",
      "-------- Epoch 885 --------\n",
      "epoch: 00885 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02748 violation_val: 0.03313 time: 0.0464s\n",
      "-------- Epoch 886 --------\n",
      "epoch: 00886 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02772 violation_val: 0.02912 time: 0.0481s\n",
      "-------- Epoch 887 --------\n",
      "epoch: 00887 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02854 violation_val: 0.03074 time: 0.0484s\n",
      "-------- Epoch 888 --------\n",
      "epoch: 00888 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02815 violation_val: 0.02956 time: 0.0469s\n",
      "-------- Epoch 889 --------\n",
      "epoch: 00889 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02747 violation_val: 0.03007 time: 0.0465s\n",
      "-------- Epoch 890 --------\n",
      "epoch: 00890 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02787 violation_val: 0.03380 time: 0.0464s\n",
      "-------- Epoch 891 --------\n",
      "epoch: 00891 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02800 violation_val: 0.03048 time: 0.0464s\n",
      "-------- Epoch 892 --------\n",
      "epoch: 00892 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02744 violation_val: 0.02964 time: 0.0521s\n",
      "-------- Epoch 893 --------\n",
      "epoch: 00893 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02787 violation_val: 0.02982 time: 0.0527s\n",
      "-------- Epoch 894 --------\n",
      "epoch: 00894 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02747 violation_val: 0.02944 time: 0.0517s\n",
      "-------- Epoch 895 --------\n",
      "epoch: 00895 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02802 violation_val: 0.03078 time: 0.0508s\n",
      "-------- Epoch 896 --------\n",
      "epoch: 00896 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02794 violation_val: 0.02902 time: 0.0504s\n",
      "-------- Epoch 897 --------\n",
      "epoch: 00897 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02809 violation_val: 0.03016 time: 0.0490s\n",
      "-------- Epoch 898 --------\n",
      "epoch: 00898 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02765 violation_val: 0.03075 time: 0.0476s\n",
      "-------- Epoch 899 --------\n",
      "epoch: 00899 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02765 violation_val: 0.02914 time: 0.0474s\n",
      "-------- Epoch 900 --------\n",
      "epoch: 00900 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02792 violation_val: 0.02988 time: 0.0474s\n",
      "-------- Epoch 901 --------\n",
      "epoch: 00901 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02880 violation_val: 0.03150 time: 0.0478s\n",
      "-------- Epoch 902 --------\n",
      "epoch: 00902 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02796 violation_val: 0.03015 time: 0.0468s\n",
      "-------- Epoch 903 --------\n",
      "epoch: 00903 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02796 violation_val: 0.02933 time: 0.0466s\n",
      "-------- Epoch 904 --------\n",
      "epoch: 00904 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02769 violation_val: 0.02907 time: 0.0467s\n",
      "-------- Epoch 905 --------\n",
      "epoch: 00905 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02773 violation_val: 0.03208 time: 0.0466s\n",
      "-------- Epoch 906 --------\n",
      "epoch: 00906 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02902 violation_val: 0.03150 time: 0.0474s\n",
      "-------- Epoch 907 --------\n",
      "epoch: 00907 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02776 violation_val: 0.03070 time: 0.0469s\n",
      "-------- Epoch 908 --------\n",
      "epoch: 00908 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02882 violation_val: 0.03254 time: 0.0464s\n",
      "-------- Epoch 909 --------\n",
      "epoch: 00909 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02788 violation_val: 0.03049 time: 0.0466s\n",
      "-------- Epoch 910 --------\n",
      "epoch: 00910 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02888 violation_val: 0.03247 time: 0.0466s\n",
      "-------- Epoch 911 --------\n",
      "epoch: 00911 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02839 violation_val: 0.03184 time: 0.0494s\n",
      "-------- Epoch 912 --------\n",
      "epoch: 00912 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02825 violation_val: 0.03232 time: 0.0471s\n",
      "-------- Epoch 913 --------\n",
      "epoch: 00913 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02870 violation_val: 0.03074 time: 0.0466s\n",
      "-------- Epoch 914 --------\n",
      "epoch: 00914 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02923 violation_val: 0.03041 time: 0.0466s\n",
      "-------- Epoch 915 --------\n",
      "epoch: 00915 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02847 violation_val: 0.03133 time: 0.0485s\n",
      "-------- Epoch 916 --------\n",
      "epoch: 00916 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02848 violation_val: 0.03120 time: 0.0477s\n",
      "-------- Epoch 917 --------\n",
      "epoch: 00917 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02880 violation_val: 0.03108 time: 0.0471s\n",
      "-------- Epoch 918 --------\n",
      "epoch: 00918 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02895 violation_val: 0.03265 time: 0.0480s\n",
      "-------- Epoch 919 --------\n",
      "epoch: 00919 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02868 violation_val: 0.03033 time: 0.0514s\n",
      "-------- Epoch 920 --------\n",
      "epoch: 00920 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02925 violation_val: 0.03064 time: 0.0523s\n",
      "-------- Epoch 921 --------\n",
      "epoch: 00921 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02888 violation_val: 0.03094 time: 0.0522s\n",
      "-------- Epoch 922 --------\n",
      "epoch: 00922 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02849 violation_val: 0.03148 time: 0.0518s\n",
      "-------- Epoch 923 --------\n",
      "epoch: 00923 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02910 violation_val: 0.03249 time: 0.0493s\n",
      "-------- Epoch 924 --------\n",
      "epoch: 00924 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02852 violation_val: 0.03141 time: 0.0481s\n",
      "-------- Epoch 925 --------\n",
      "epoch: 00925 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02855 violation_val: 0.03103 time: 0.0475s\n",
      "-------- Epoch 926 --------\n",
      "epoch: 00926 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.03012 violation_val: 0.03110 time: 0.0476s\n",
      "-------- Epoch 927 --------\n",
      "epoch: 00927 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02792 violation_val: 0.03101 time: 0.0471s\n",
      "-------- Epoch 928 --------\n",
      "epoch: 00928 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02933 violation_val: 0.03450 time: 0.0465s\n",
      "-------- Epoch 929 --------\n",
      "epoch: 00929 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02941 violation_val: 0.03280 time: 0.0464s\n",
      "-------- Epoch 930 --------\n",
      "epoch: 00930 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02920 violation_val: 0.03123 time: 0.0467s\n",
      "-------- Epoch 931 --------\n",
      "epoch: 00931 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02904 violation_val: 0.03263 time: 0.0491s\n",
      "-------- Epoch 932 --------\n",
      "epoch: 00932 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02913 violation_val: 0.03369 time: 0.0516s\n",
      "-------- Epoch 933 --------\n",
      "epoch: 00933 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02982 violation_val: 0.03238 time: 0.0501s\n",
      "-------- Epoch 934 --------\n",
      "epoch: 00934 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02930 violation_val: 0.03081 time: 0.0507s\n",
      "-------- Epoch 935 --------\n",
      "epoch: 00935 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02841 violation_val: 0.03126 time: 0.0516s\n",
      "-------- Epoch 936 --------\n",
      "epoch: 00936 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02914 violation_val: 0.03213 time: 0.0493s\n",
      "-------- Epoch 937 --------\n",
      "epoch: 00937 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02826 violation_val: 0.03150 time: 0.0478s\n",
      "-------- Epoch 938 --------\n",
      "epoch: 00938 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02907 violation_val: 0.03379 time: 0.0471s\n",
      "-------- Epoch 939 --------\n",
      "epoch: 00939 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02921 violation_val: 0.03133 time: 0.0474s\n",
      "-------- Epoch 940 --------\n",
      "epoch: 00940 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02875 violation_val: 0.03319 time: 0.0474s\n",
      "-------- Epoch 941 --------\n",
      "epoch: 00941 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02905 violation_val: 0.03081 time: 0.0469s\n",
      "-------- Epoch 942 --------\n",
      "epoch: 00942 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02861 violation_val: 0.03052 time: 0.0473s\n",
      "-------- Epoch 943 --------\n",
      "epoch: 00943 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02891 violation_val: 0.03140 time: 0.0510s\n",
      "-------- Epoch 944 --------\n",
      "epoch: 00944 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02838 violation_val: 0.03125 time: 0.0508s\n",
      "-------- Epoch 945 --------\n",
      "epoch: 00945 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02918 violation_val: 0.03130 time: 0.0517s\n",
      "-------- Epoch 946 --------\n",
      "epoch: 00946 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02878 violation_val: 0.03122 time: 0.0529s\n",
      "-------- Epoch 947 --------\n",
      "epoch: 00947 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02872 violation_val: 0.03162 time: 0.0509s\n",
      "-------- Epoch 948 --------\n",
      "epoch: 00948 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02864 violation_val: 0.03097 time: 0.0497s\n",
      "-------- Epoch 949 --------\n",
      "epoch: 00949 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02926 violation_val: 0.03061 time: 0.0512s\n",
      "-------- Epoch 950 --------\n",
      "epoch: 00950 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02855 violation_val: 0.03087 time: 0.0514s\n",
      "-------- Epoch 951 --------\n",
      "epoch: 00951 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02842 violation_val: 0.03090 time: 0.0488s\n",
      "-------- Epoch 952 --------\n",
      "epoch: 00952 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02862 violation_val: 0.03035 time: 0.0481s\n",
      "-------- Epoch 953 --------\n",
      "epoch: 00953 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02837 violation_val: 0.03186 time: 0.0472s\n",
      "-------- Epoch 954 --------\n",
      "epoch: 00954 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02868 violation_val: 0.03081 time: 0.0479s\n",
      "-------- Epoch 955 --------\n",
      "epoch: 00955 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02873 violation_val: 0.03063 time: 0.0470s\n",
      "-------- Epoch 956 --------\n",
      "epoch: 00956 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02850 violation_val: 0.03161 time: 0.0469s\n",
      "-------- Epoch 957 --------\n",
      "epoch: 00957 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02966 violation_val: 0.03094 time: 0.0468s\n",
      "-------- Epoch 958 --------\n",
      "epoch: 00958 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02820 violation_val: 0.03318 time: 0.0467s\n",
      "-------- Epoch 959 --------\n",
      "epoch: 00959 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02877 violation_val: 0.03214 time: 0.0474s\n",
      "-------- Epoch 960 --------\n",
      "epoch: 00960 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02875 violation_val: 0.03156 time: 0.0470s\n",
      "-------- Epoch 961 --------\n",
      "epoch: 00961 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02907 violation_val: 0.03069 time: 0.0464s\n",
      "-------- Epoch 962 --------\n",
      "epoch: 00962 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02882 violation_val: 0.03200 time: 0.0465s\n",
      "-------- Epoch 963 --------\n",
      "epoch: 00963 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02917 violation_val: 0.03180 time: 0.0464s\n",
      "-------- Epoch 964 --------\n",
      "epoch: 00964 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02851 violation_val: 0.03099 time: 0.0478s\n",
      "-------- Epoch 965 --------\n",
      "epoch: 00965 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.02940 violation_val: 0.03118 time: 0.0478s\n",
      "-------- Epoch 966 --------\n",
      "epoch: 00966 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02957 violation_val: 0.03149 time: 0.0467s\n",
      "-------- Epoch 967 --------\n",
      "epoch: 00967 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02885 violation_val: 0.03120 time: 0.0470s\n",
      "-------- Epoch 968 --------\n",
      "epoch: 00968 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02918 violation_val: 0.03209 time: 0.0467s\n",
      "-------- Epoch 969 --------\n",
      "epoch: 00969 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02876 violation_val: 0.03085 time: 0.0476s\n",
      "-------- Epoch 970 --------\n",
      "epoch: 00970 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02921 violation_val: 0.03210 time: 0.0496s\n",
      "-------- Epoch 971 --------\n",
      "epoch: 00971 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02901 violation_val: 0.03288 time: 0.0483s\n",
      "-------- Epoch 972 --------\n",
      "epoch: 00972 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.02959 violation_val: 0.03447 time: 0.0490s\n",
      "-------- Epoch 973 --------\n",
      "epoch: 00973 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02943 violation_val: 0.03207 time: 0.0511s\n",
      "-------- Epoch 974 --------\n",
      "epoch: 00974 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02956 violation_val: 0.03230 time: 0.0515s\n",
      "-------- Epoch 975 --------\n",
      "epoch: 00975 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02995 violation_val: 0.03212 time: 0.0508s\n",
      "-------- Epoch 976 --------\n",
      "epoch: 00976 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.02952 violation_val: 0.03353 time: 0.0509s\n",
      "-------- Epoch 977 --------\n",
      "epoch: 00977 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.03033 violation_val: 0.03395 time: 0.0508s\n",
      "-------- Epoch 978 --------\n",
      "epoch: 00978 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.02960 violation_val: 0.03408 time: 0.0518s\n",
      "-------- Epoch 979 --------\n",
      "epoch: 00979 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.03036 violation_val: 0.03240 time: 0.0511s\n",
      "-------- Epoch 980 --------\n",
      "epoch: 00980 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.03055 violation_val: 0.03331 time: 0.0493s\n",
      "-------- Epoch 981 --------\n",
      "epoch: 00981 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.03066 violation_val: 0.03459 time: 0.0500s\n",
      "-------- Epoch 982 --------\n",
      "epoch: 00982 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.03045 violation_val: 0.03461 time: 0.0496s\n",
      "-------- Epoch 983 --------\n",
      "epoch: 00983 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.03082 violation_val: 0.03336 time: 0.0518s\n",
      "-------- Epoch 984 --------\n",
      "epoch: 00984 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.03091 violation_val: 0.03378 time: 0.0506s\n",
      "-------- Epoch 985 --------\n",
      "epoch: 00985 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.03065 violation_val: 0.03341 time: 0.0504s\n",
      "-------- Epoch 986 --------\n",
      "epoch: 00986 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.03049 violation_val: 0.03522 time: 0.0509s\n",
      "-------- Epoch 987 --------\n",
      "epoch: 00987 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.03123 violation_val: 0.03431 time: 0.0511s\n",
      "-------- Epoch 988 --------\n",
      "epoch: 00988 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.03114 violation_val: 0.03368 time: 0.0509s\n",
      "-------- Epoch 989 --------\n",
      "epoch: 00989 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.03132 violation_val: 0.03626 time: 0.0486s\n",
      "-------- Epoch 990 --------\n",
      "epoch: 00990 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.03165 violation_val: 0.03385 time: 0.0498s\n",
      "-------- Epoch 991 --------\n",
      "epoch: 00991 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.03079 violation_val: 0.03556 time: 0.0492s\n",
      "-------- Epoch 992 --------\n",
      "epoch: 00992 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.03146 violation_val: 0.03405 time: 0.0508s\n",
      "-------- Epoch 993 --------\n",
      "epoch: 00993 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.03085 violation_val: 0.03461 time: 0.0493s\n",
      "-------- Epoch 994 --------\n",
      "epoch: 00994 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.03168 violation_val: 0.03368 time: 0.0487s\n",
      "-------- Epoch 995 --------\n",
      "epoch: 00995 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.03131 violation_val: 0.03599 time: 0.0479s\n",
      "-------- Epoch 996 --------\n",
      "epoch: 00996 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.03210 violation_val: 0.03551 time: 0.0474s\n",
      "-------- Epoch 997 --------\n",
      "epoch: 00997 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.03135 violation_val: 0.03503 time: 0.0478s\n",
      "-------- Epoch 998 --------\n",
      "epoch: 00998 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.03231 violation_val: 0.03550 time: 0.0467s\n",
      "-------- Epoch 999 --------\n",
      "epoch: 00999 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.03125 violation_val: 0.03451 time: 0.0466s\n",
      "-------- Epoch 1000 --------\n",
      "epoch: 01000 loss_train: 0.00003 loss_val: 0.00004 violation_train: 0.03189 violation_val: 0.03435 time: 0.0464s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 48.6084s\n",
      "Start Training...\n",
      "-------- Epoch 1 --------\n",
      "epoch: 00001 loss_train: 0.01193 loss_val: 0.01264 violation_train: 2.99494 violation_val: 2.95510 time: 0.0584s\n",
      "-------- Epoch 2 --------\n",
      "epoch: 00002 loss_train: 0.01069 loss_val: 0.01149 violation_train: 2.60570 violation_val: 2.59686 time: 0.0613s\n",
      "-------- Epoch 3 --------\n",
      "epoch: 00003 loss_train: 0.00963 loss_val: 0.01058 violation_train: 2.27612 violation_val: 2.31385 time: 0.0611s\n",
      "-------- Epoch 4 --------\n",
      "epoch: 00004 loss_train: 0.00873 loss_val: 0.00973 violation_train: 2.01351 violation_val: 2.07017 time: 0.0630s\n",
      "-------- Epoch 5 --------\n",
      "epoch: 00005 loss_train: 0.00802 loss_val: 0.00876 violation_train: 1.81486 violation_val: 1.86462 time: 0.0613s\n",
      "-------- Epoch 6 --------\n",
      "epoch: 00006 loss_train: 0.00740 loss_val: 0.00823 violation_train: 1.67429 violation_val: 1.77014 time: 0.0605s\n",
      "-------- Epoch 7 --------\n",
      "epoch: 00007 loss_train: 0.00689 loss_val: 0.00798 violation_train: 1.57188 violation_val: 1.69322 time: 0.0636s\n",
      "-------- Epoch 8 --------\n",
      "epoch: 00008 loss_train: 0.00647 loss_val: 0.00743 violation_train: 1.49201 violation_val: 1.59079 time: 0.0686s\n",
      "-------- Epoch 9 --------\n",
      "epoch: 00009 loss_train: 0.00618 loss_val: 0.00707 violation_train: 1.42606 violation_val: 1.52685 time: 0.0685s\n",
      "-------- Epoch 10 --------\n",
      "epoch: 00010 loss_train: 0.00597 loss_val: 0.00697 violation_train: 1.36536 violation_val: 1.46839 time: 0.0697s\n",
      "-------- Epoch 11 --------\n",
      "epoch: 00011 loss_train: 0.00580 loss_val: 0.00707 violation_train: 1.30872 violation_val: 1.41978 time: 0.0671s\n",
      "-------- Epoch 12 --------\n",
      "epoch: 00012 loss_train: 0.00569 loss_val: 0.00663 violation_train: 1.25245 violation_val: 1.34012 time: 0.0629s\n",
      "-------- Epoch 13 --------\n",
      "epoch: 00013 loss_train: 0.00560 loss_val: 0.00658 violation_train: 1.19801 violation_val: 1.27061 time: 0.0609s\n",
      "-------- Epoch 14 --------\n",
      "epoch: 00014 loss_train: 0.00554 loss_val: 0.00646 violation_train: 1.14234 violation_val: 1.21827 time: 0.0612s\n",
      "-------- Epoch 15 --------\n",
      "epoch: 00015 loss_train: 0.00547 loss_val: 0.00659 violation_train: 1.08650 violation_val: 1.15254 time: 0.0607s\n",
      "-------- Epoch 16 --------\n",
      "epoch: 00016 loss_train: 0.00543 loss_val: 0.00637 violation_train: 1.02955 violation_val: 1.08465 time: 0.0595s\n",
      "-------- Epoch 17 --------\n",
      "epoch: 00017 loss_train: 0.00540 loss_val: 0.00659 violation_train: 0.97444 violation_val: 1.04801 time: 0.0589s\n",
      "-------- Epoch 18 --------\n",
      "epoch: 00018 loss_train: 0.00538 loss_val: 0.00626 violation_train: 0.92050 violation_val: 0.95429 time: 0.0594s\n",
      "-------- Epoch 19 --------\n",
      "epoch: 00019 loss_train: 0.00537 loss_val: 0.00636 violation_train: 0.86890 violation_val: 0.91416 time: 0.0599s\n",
      "-------- Epoch 20 --------\n",
      "epoch: 00020 loss_train: 0.00537 loss_val: 0.00636 violation_train: 0.82097 violation_val: 0.85966 time: 0.0597s\n",
      "-------- Epoch 21 --------\n",
      "epoch: 00021 loss_train: 0.00538 loss_val: 0.00634 violation_train: 0.77671 violation_val: 0.80447 time: 0.0589s\n",
      "-------- Epoch 22 --------\n",
      "epoch: 00022 loss_train: 0.00538 loss_val: 0.00648 violation_train: 0.73497 violation_val: 0.76785 time: 0.0597s\n",
      "-------- Epoch 23 --------\n",
      "epoch: 00023 loss_train: 0.00541 loss_val: 0.00637 violation_train: 0.69796 violation_val: 0.72153 time: 0.0622s\n",
      "-------- Epoch 24 --------\n",
      "epoch: 00024 loss_train: 0.00543 loss_val: 0.00651 violation_train: 0.66527 violation_val: 0.69297 time: 0.0639s\n",
      "-------- Epoch 25 --------\n",
      "epoch: 00025 loss_train: 0.00545 loss_val: 0.00668 violation_train: 0.63588 violation_val: 0.66442 time: 0.0609s\n",
      "-------- Epoch 26 --------\n",
      "epoch: 00026 loss_train: 0.00548 loss_val: 0.00665 violation_train: 0.61046 violation_val: 0.62027 time: 0.0617s\n",
      "-------- Epoch 27 --------\n",
      "epoch: 00027 loss_train: 0.00551 loss_val: 0.00662 violation_train: 0.58694 violation_val: 0.60049 time: 0.0636s\n",
      "-------- Epoch 28 --------\n",
      "epoch: 00028 loss_train: 0.00554 loss_val: 0.00656 violation_train: 0.56681 violation_val: 0.57755 time: 0.0592s\n",
      "-------- Epoch 29 --------\n",
      "epoch: 00029 loss_train: 0.00556 loss_val: 0.00652 violation_train: 0.54852 violation_val: 0.55355 time: 0.0623s\n",
      "-------- Epoch 30 --------\n",
      "epoch: 00030 loss_train: 0.00558 loss_val: 0.00665 violation_train: 0.53209 violation_val: 0.54061 time: 0.0649s\n",
      "-------- Epoch 31 --------\n",
      "epoch: 00031 loss_train: 0.00561 loss_val: 0.00660 violation_train: 0.51657 violation_val: 0.52033 time: 0.0609s\n",
      "-------- Epoch 32 --------\n",
      "epoch: 00032 loss_train: 0.00563 loss_val: 0.00680 violation_train: 0.50271 violation_val: 0.51301 time: 0.0668s\n",
      "-------- Epoch 33 --------\n",
      "epoch: 00033 loss_train: 0.00566 loss_val: 0.00662 violation_train: 0.48945 violation_val: 0.49854 time: 0.0653s\n",
      "-------- Epoch 34 --------\n",
      "epoch: 00034 loss_train: 0.00568 loss_val: 0.00665 violation_train: 0.47709 violation_val: 0.48327 time: 0.0602s\n",
      "-------- Epoch 35 --------\n",
      "epoch: 00035 loss_train: 0.00571 loss_val: 0.00694 violation_train: 0.46449 violation_val: 0.46597 time: 0.0595s\n",
      "-------- Epoch 36 --------\n",
      "epoch: 00036 loss_train: 0.00575 loss_val: 0.00693 violation_train: 0.45269 violation_val: 0.45258 time: 0.0591s\n",
      "-------- Epoch 37 --------\n",
      "epoch: 00037 loss_train: 0.00577 loss_val: 0.00680 violation_train: 0.44014 violation_val: 0.44030 time: 0.0600s\n",
      "-------- Epoch 38 --------\n",
      "epoch: 00038 loss_train: 0.00580 loss_val: 0.00686 violation_train: 0.42808 violation_val: 0.42871 time: 0.0589s\n",
      "-------- Epoch 39 --------\n",
      "epoch: 00039 loss_train: 0.00583 loss_val: 0.00684 violation_train: 0.41572 violation_val: 0.41830 time: 0.0593s\n",
      "-------- Epoch 40 --------\n",
      "epoch: 00040 loss_train: 0.00586 loss_val: 0.00694 violation_train: 0.40365 violation_val: 0.39921 time: 0.0611s\n",
      "-------- Epoch 41 --------\n",
      "epoch: 00041 loss_train: 0.00590 loss_val: 0.00706 violation_train: 0.39132 violation_val: 0.38761 time: 0.0591s\n",
      "-------- Epoch 42 --------\n",
      "epoch: 00042 loss_train: 0.00592 loss_val: 0.00701 violation_train: 0.37930 violation_val: 0.37487 time: 0.0623s\n",
      "-------- Epoch 43 --------\n",
      "epoch: 00043 loss_train: 0.00596 loss_val: 0.00709 violation_train: 0.36705 violation_val: 0.37177 time: 0.0618s\n",
      "-------- Epoch 44 --------\n",
      "epoch: 00044 loss_train: 0.00600 loss_val: 0.00710 violation_train: 0.35483 violation_val: 0.35422 time: 0.0624s\n",
      "-------- Epoch 45 --------\n",
      "epoch: 00045 loss_train: 0.00603 loss_val: 0.00713 violation_train: 0.34265 violation_val: 0.34243 time: 0.0613s\n",
      "-------- Epoch 46 --------\n",
      "epoch: 00046 loss_train: 0.00606 loss_val: 0.00713 violation_train: 0.33062 violation_val: 0.32664 time: 0.0624s\n",
      "-------- Epoch 47 --------\n",
      "epoch: 00047 loss_train: 0.00610 loss_val: 0.00718 violation_train: 0.31839 violation_val: 0.31313 time: 0.0629s\n",
      "-------- Epoch 48 --------\n",
      "epoch: 00048 loss_train: 0.00613 loss_val: 0.00747 violation_train: 0.30667 violation_val: 0.30266 time: 0.0644s\n",
      "-------- Epoch 49 --------\n",
      "epoch: 00049 loss_train: 0.00617 loss_val: 0.00735 violation_train: 0.29430 violation_val: 0.29556 time: 0.0634s\n",
      "-------- Epoch 50 --------\n",
      "epoch: 00050 loss_train: 0.00620 loss_val: 0.00721 violation_train: 0.28244 violation_val: 0.28195 time: 0.0621s\n",
      "-------- Epoch 51 --------\n",
      "epoch: 00051 loss_train: 0.00624 loss_val: 0.00734 violation_train: 0.27071 violation_val: 0.26827 time: 0.0657s\n",
      "-------- Epoch 52 --------\n",
      "epoch: 00052 loss_train: 0.00627 loss_val: 0.00742 violation_train: 0.25924 violation_val: 0.26006 time: 0.0648s\n",
      "-------- Epoch 53 --------\n",
      "epoch: 00053 loss_train: 0.00630 loss_val: 0.00728 violation_train: 0.24813 violation_val: 0.24739 time: 0.0655s\n",
      "-------- Epoch 54 --------\n",
      "epoch: 00054 loss_train: 0.00633 loss_val: 0.00742 violation_train: 0.23657 violation_val: 0.23636 time: 0.0629s\n",
      "-------- Epoch 55 --------\n",
      "epoch: 00055 loss_train: 0.00637 loss_val: 0.00745 violation_train: 0.22584 violation_val: 0.22379 time: 0.0619s\n",
      "-------- Epoch 56 --------\n",
      "epoch: 00056 loss_train: 0.00640 loss_val: 0.00766 violation_train: 0.21602 violation_val: 0.21366 time: 0.0620s\n",
      "-------- Epoch 57 --------\n",
      "epoch: 00057 loss_train: 0.00643 loss_val: 0.00772 violation_train: 0.20581 violation_val: 0.20128 time: 0.0592s\n",
      "-------- Epoch 58 --------\n",
      "epoch: 00058 loss_train: 0.00646 loss_val: 0.00763 violation_train: 0.19620 violation_val: 0.19320 time: 0.0609s\n",
      "-------- Epoch 59 --------\n",
      "epoch: 00059 loss_train: 0.00649 loss_val: 0.00765 violation_train: 0.18691 violation_val: 0.18933 time: 0.0645s\n",
      "-------- Epoch 60 --------\n",
      "epoch: 00060 loss_train: 0.00652 loss_val: 0.00778 violation_train: 0.17844 violation_val: 0.17805 time: 0.0629s\n",
      "-------- Epoch 61 --------\n",
      "epoch: 00061 loss_train: 0.00654 loss_val: 0.00767 violation_train: 0.17026 violation_val: 0.16810 time: 0.0622s\n",
      "-------- Epoch 62 --------\n",
      "epoch: 00062 loss_train: 0.00657 loss_val: 0.00760 violation_train: 0.16272 violation_val: 0.16087 time: 0.0611s\n",
      "-------- Epoch 63 --------\n",
      "epoch: 00063 loss_train: 0.00659 loss_val: 0.00772 violation_train: 0.15569 violation_val: 0.15285 time: 0.0625s\n",
      "-------- Epoch 64 --------\n",
      "epoch: 00064 loss_train: 0.00661 loss_val: 0.00783 violation_train: 0.14915 violation_val: 0.14986 time: 0.0594s\n",
      "-------- Epoch 65 --------\n",
      "epoch: 00065 loss_train: 0.00664 loss_val: 0.00775 violation_train: 0.14322 violation_val: 0.14248 time: 0.0594s\n",
      "-------- Epoch 66 --------\n",
      "epoch: 00066 loss_train: 0.00666 loss_val: 0.00789 violation_train: 0.13828 violation_val: 0.13871 time: 0.0607s\n",
      "-------- Epoch 67 --------\n",
      "epoch: 00067 loss_train: 0.00668 loss_val: 0.00823 violation_train: 0.13310 violation_val: 0.13639 time: 0.0576s\n",
      "-------- Epoch 68 --------\n",
      "epoch: 00068 loss_train: 0.00669 loss_val: 0.00779 violation_train: 0.12924 violation_val: 0.13067 time: 0.0583s\n",
      "-------- Epoch 69 --------\n",
      "epoch: 00069 loss_train: 0.00671 loss_val: 0.00774 violation_train: 0.12555 violation_val: 0.12681 time: 0.0618s\n",
      "-------- Epoch 70 --------\n",
      "epoch: 00070 loss_train: 0.00673 loss_val: 0.00813 violation_train: 0.12180 violation_val: 0.12483 time: 0.0626s\n",
      "-------- Epoch 71 --------\n",
      "epoch: 00071 loss_train: 0.00674 loss_val: 0.00784 violation_train: 0.11898 violation_val: 0.12116 time: 0.0622s\n",
      "-------- Epoch 72 --------\n",
      "epoch: 00072 loss_train: 0.00675 loss_val: 0.00785 violation_train: 0.11587 violation_val: 0.11809 time: 0.0604s\n",
      "-------- Epoch 73 --------\n",
      "epoch: 00073 loss_train: 0.00677 loss_val: 0.00800 violation_train: 0.11351 violation_val: 0.11411 time: 0.0593s\n",
      "-------- Epoch 74 --------\n",
      "epoch: 00074 loss_train: 0.00678 loss_val: 0.00807 violation_train: 0.11057 violation_val: 0.11377 time: 0.0593s\n",
      "-------- Epoch 75 --------\n",
      "epoch: 00075 loss_train: 0.00678 loss_val: 0.00792 violation_train: 0.10854 violation_val: 0.10970 time: 0.0576s\n",
      "-------- Epoch 76 --------\n",
      "epoch: 00076 loss_train: 0.00680 loss_val: 0.00798 violation_train: 0.10624 violation_val: 0.11139 time: 0.0595s\n",
      "-------- Epoch 77 --------\n",
      "epoch: 00077 loss_train: 0.00681 loss_val: 0.00793 violation_train: 0.10420 violation_val: 0.10457 time: 0.0612s\n",
      "-------- Epoch 78 --------\n",
      "epoch: 00078 loss_train: 0.00681 loss_val: 0.00805 violation_train: 0.10202 violation_val: 0.10452 time: 0.0621s\n",
      "-------- Epoch 79 --------\n",
      "epoch: 00079 loss_train: 0.00681 loss_val: 0.00789 violation_train: 0.10007 violation_val: 0.10445 time: 0.0595s\n",
      "-------- Epoch 80 --------\n",
      "epoch: 00080 loss_train: 0.00682 loss_val: 0.00791 violation_train: 0.09793 violation_val: 0.10101 time: 0.0595s\n",
      "-------- Epoch 81 --------\n",
      "epoch: 00081 loss_train: 0.00683 loss_val: 0.00800 violation_train: 0.09588 violation_val: 0.09921 time: 0.0613s\n",
      "-------- Epoch 82 --------\n",
      "epoch: 00082 loss_train: 0.00684 loss_val: 0.00816 violation_train: 0.09404 violation_val: 0.09682 time: 0.0640s\n",
      "-------- Epoch 83 --------\n",
      "epoch: 00083 loss_train: 0.00684 loss_val: 0.00791 violation_train: 0.09229 violation_val: 0.09578 time: 0.0642s\n",
      "-------- Epoch 84 --------\n",
      "epoch: 00084 loss_train: 0.00684 loss_val: 0.00821 violation_train: 0.09036 violation_val: 0.09348 time: 0.0608s\n",
      "-------- Epoch 85 --------\n",
      "epoch: 00085 loss_train: 0.00685 loss_val: 0.00826 violation_train: 0.08841 violation_val: 0.09247 time: 0.0604s\n",
      "-------- Epoch 86 --------\n",
      "epoch: 00086 loss_train: 0.00685 loss_val: 0.00816 violation_train: 0.08675 violation_val: 0.08875 time: 0.0598s\n",
      "-------- Epoch 87 --------\n",
      "epoch: 00087 loss_train: 0.00686 loss_val: 0.00805 violation_train: 0.08523 violation_val: 0.08795 time: 0.0581s\n",
      "-------- Epoch 88 --------\n",
      "epoch: 00088 loss_train: 0.00686 loss_val: 0.00801 violation_train: 0.08287 violation_val: 0.08577 time: 0.0583s\n",
      "-------- Epoch 89 --------\n",
      "epoch: 00089 loss_train: 0.00686 loss_val: 0.00802 violation_train: 0.08160 violation_val: 0.08555 time: 0.0631s\n",
      "-------- Epoch 90 --------\n",
      "epoch: 00090 loss_train: 0.00686 loss_val: 0.00802 violation_train: 0.08016 violation_val: 0.08379 time: 0.0632s\n",
      "-------- Epoch 91 --------\n",
      "epoch: 00091 loss_train: 0.00686 loss_val: 0.00797 violation_train: 0.07769 violation_val: 0.08170 time: 0.0637s\n",
      "-------- Epoch 92 --------\n",
      "epoch: 00092 loss_train: 0.00687 loss_val: 0.00818 violation_train: 0.07657 violation_val: 0.07999 time: 0.0633s\n",
      "-------- Epoch 93 --------\n",
      "epoch: 00093 loss_train: 0.00687 loss_val: 0.00807 violation_train: 0.07465 violation_val: 0.07733 time: 0.0616s\n",
      "-------- Epoch 94 --------\n",
      "epoch: 00094 loss_train: 0.00686 loss_val: 0.00807 violation_train: 0.07329 violation_val: 0.07644 time: 0.0637s\n",
      "-------- Epoch 95 --------\n",
      "epoch: 00095 loss_train: 0.00686 loss_val: 0.00814 violation_train: 0.07155 violation_val: 0.07498 time: 0.0628s\n",
      "-------- Epoch 96 --------\n",
      "epoch: 00096 loss_train: 0.00686 loss_val: 0.00805 violation_train: 0.06999 violation_val: 0.07232 time: 0.0617s\n",
      "-------- Epoch 97 --------\n",
      "epoch: 00097 loss_train: 0.00685 loss_val: 0.00821 violation_train: 0.06777 violation_val: 0.07232 time: 0.0613s\n",
      "-------- Epoch 98 --------\n",
      "epoch: 00098 loss_train: 0.00685 loss_val: 0.00802 violation_train: 0.06655 violation_val: 0.07063 time: 0.0629s\n",
      "-------- Epoch 99 --------\n",
      "epoch: 00099 loss_train: 0.00684 loss_val: 0.00796 violation_train: 0.06469 violation_val: 0.06779 time: 0.0615s\n",
      "-------- Epoch 100 --------\n",
      "epoch: 00100 loss_train: 0.00684 loss_val: 0.00802 violation_train: 0.06350 violation_val: 0.06713 time: 0.0628s\n",
      "-------- Epoch 101 --------\n",
      "epoch: 00101 loss_train: 0.00684 loss_val: 0.00807 violation_train: 0.06205 violation_val: 0.06633 time: 0.0621s\n",
      "-------- Epoch 102 --------\n",
      "epoch: 00102 loss_train: 0.00683 loss_val: 0.00812 violation_train: 0.06061 violation_val: 0.06263 time: 0.0636s\n",
      "-------- Epoch 103 --------\n",
      "epoch: 00103 loss_train: 0.00683 loss_val: 0.00804 violation_train: 0.05814 violation_val: 0.06183 time: 0.0623s\n",
      "-------- Epoch 104 --------\n",
      "epoch: 00104 loss_train: 0.00682 loss_val: 0.00792 violation_train: 0.05709 violation_val: 0.05960 time: 0.0596s\n",
      "-------- Epoch 105 --------\n",
      "epoch: 00105 loss_train: 0.00681 loss_val: 0.00817 violation_train: 0.05608 violation_val: 0.06061 time: 0.0587s\n",
      "-------- Epoch 106 --------\n",
      "epoch: 00106 loss_train: 0.00680 loss_val: 0.00807 violation_train: 0.05394 violation_val: 0.05616 time: 0.0595s\n",
      "-------- Epoch 107 --------\n",
      "epoch: 00107 loss_train: 0.00680 loss_val: 0.00786 violation_train: 0.05205 violation_val: 0.05417 time: 0.0575s\n",
      "-------- Epoch 108 --------\n",
      "epoch: 00108 loss_train: 0.00679 loss_val: 0.00800 violation_train: 0.05052 violation_val: 0.05291 time: 0.0572s\n",
      "-------- Epoch 109 --------\n",
      "epoch: 00109 loss_train: 0.00678 loss_val: 0.00789 violation_train: 0.04886 violation_val: 0.05237 time: 0.0571s\n",
      "-------- Epoch 110 --------\n",
      "epoch: 00110 loss_train: 0.00677 loss_val: 0.00801 violation_train: 0.04736 violation_val: 0.05075 time: 0.0576s\n",
      "-------- Epoch 111 --------\n",
      "epoch: 00111 loss_train: 0.00676 loss_val: 0.00791 violation_train: 0.04671 violation_val: 0.04974 time: 0.0577s\n",
      "-------- Epoch 112 --------\n",
      "epoch: 00112 loss_train: 0.00675 loss_val: 0.00800 violation_train: 0.04387 violation_val: 0.04765 time: 0.0601s\n",
      "-------- Epoch 113 --------\n",
      "epoch: 00113 loss_train: 0.00673 loss_val: 0.00779 violation_train: 0.04310 violation_val: 0.04552 time: 0.0610s\n",
      "-------- Epoch 114 --------\n",
      "epoch: 00114 loss_train: 0.00672 loss_val: 0.00783 violation_train: 0.04096 violation_val: 0.04437 time: 0.0619s\n",
      "-------- Epoch 115 --------\n",
      "epoch: 00115 loss_train: 0.00671 loss_val: 0.00789 violation_train: 0.03955 violation_val: 0.04190 time: 0.0596s\n",
      "-------- Epoch 116 --------\n",
      "epoch: 00116 loss_train: 0.00670 loss_val: 0.00786 violation_train: 0.03805 violation_val: 0.04135 time: 0.0593s\n",
      "-------- Epoch 117 --------\n",
      "epoch: 00117 loss_train: 0.00668 loss_val: 0.00814 violation_train: 0.03678 violation_val: 0.04108 time: 0.0619s\n",
      "-------- Epoch 118 --------\n",
      "epoch: 00118 loss_train: 0.00667 loss_val: 0.00777 violation_train: 0.03528 violation_val: 0.03795 time: 0.0626s\n",
      "-------- Epoch 119 --------\n",
      "epoch: 00119 loss_train: 0.00665 loss_val: 0.00804 violation_train: 0.03418 violation_val: 0.03671 time: 0.0610s\n",
      "-------- Epoch 120 --------\n",
      "epoch: 00120 loss_train: 0.00664 loss_val: 0.00779 violation_train: 0.03244 violation_val: 0.03447 time: 0.0595s\n",
      "-------- Epoch 121 --------\n",
      "epoch: 00121 loss_train: 0.00662 loss_val: 0.00798 violation_train: 0.03089 violation_val: 0.03377 time: 0.0610s\n",
      "-------- Epoch 122 --------\n",
      "epoch: 00122 loss_train: 0.00660 loss_val: 0.00778 violation_train: 0.02987 violation_val: 0.03174 time: 0.0612s\n",
      "-------- Epoch 123 --------\n",
      "epoch: 00123 loss_train: 0.00659 loss_val: 0.00776 violation_train: 0.02859 violation_val: 0.03045 time: 0.0581s\n",
      "-------- Epoch 124 --------\n",
      "epoch: 00124 loss_train: 0.00657 loss_val: 0.00776 violation_train: 0.02720 violation_val: 0.02854 time: 0.0572s\n",
      "-------- Epoch 125 --------\n",
      "epoch: 00125 loss_train: 0.00655 loss_val: 0.00765 violation_train: 0.02578 violation_val: 0.02828 time: 0.0572s\n",
      "-------- Epoch 126 --------\n",
      "epoch: 00126 loss_train: 0.00653 loss_val: 0.00771 violation_train: 0.02525 violation_val: 0.02704 time: 0.0583s\n",
      "-------- Epoch 127 --------\n",
      "epoch: 00127 loss_train: 0.00651 loss_val: 0.00756 violation_train: 0.02383 violation_val: 0.02493 time: 0.0576s\n",
      "-------- Epoch 128 --------\n",
      "epoch: 00128 loss_train: 0.00650 loss_val: 0.00754 violation_train: 0.02243 violation_val: 0.02470 time: 0.0609s\n",
      "-------- Epoch 129 --------\n",
      "epoch: 00129 loss_train: 0.00648 loss_val: 0.00764 violation_train: 0.02121 violation_val: 0.02376 time: 0.0615s\n",
      "-------- Epoch 130 --------\n",
      "epoch: 00130 loss_train: 0.00646 loss_val: 0.00747 violation_train: 0.02094 violation_val: 0.02274 time: 0.0634s\n",
      "-------- Epoch 131 --------\n",
      "epoch: 00131 loss_train: 0.00644 loss_val: 0.00760 violation_train: 0.01892 violation_val: 0.02042 time: 0.0609s\n",
      "-------- Epoch 132 --------\n",
      "epoch: 00132 loss_train: 0.00642 loss_val: 0.00740 violation_train: 0.01821 violation_val: 0.02235 time: 0.0624s\n",
      "-------- Epoch 133 --------\n",
      "epoch: 00133 loss_train: 0.00640 loss_val: 0.00761 violation_train: 0.01755 violation_val: 0.02236 time: 0.0614s\n",
      "-------- Epoch 134 --------\n",
      "epoch: 00134 loss_train: 0.00638 loss_val: 0.00751 violation_train: 0.01693 violation_val: 0.01862 time: 0.0627s\n",
      "-------- Epoch 135 --------\n",
      "epoch: 00135 loss_train: 0.00636 loss_val: 0.00770 violation_train: 0.01588 violation_val: 0.01849 time: 0.0615s\n",
      "-------- Epoch 136 --------\n",
      "epoch: 00136 loss_train: 0.00634 loss_val: 0.00742 violation_train: 0.01530 violation_val: 0.01736 time: 0.0618s\n",
      "-------- Epoch 137 --------\n",
      "epoch: 00137 loss_train: 0.00632 loss_val: 0.00740 violation_train: 0.01459 violation_val: 0.01575 time: 0.0619s\n",
      "-------- Epoch 138 --------\n",
      "epoch: 00138 loss_train: 0.00630 loss_val: 0.00727 violation_train: 0.01298 violation_val: 0.01448 time: 0.0630s\n",
      "-------- Epoch 139 --------\n",
      "epoch: 00139 loss_train: 0.00628 loss_val: 0.00741 violation_train: 0.01235 violation_val: 0.01366 time: 0.0627s\n",
      "-------- Epoch 140 --------\n",
      "epoch: 00140 loss_train: 0.00626 loss_val: 0.00726 violation_train: 0.01160 violation_val: 0.01376 time: 0.0613s\n",
      "-------- Epoch 141 --------\n",
      "epoch: 00141 loss_train: 0.00624 loss_val: 0.00724 violation_train: 0.01131 violation_val: 0.01275 time: 0.0608s\n",
      "-------- Epoch 142 --------\n",
      "epoch: 00142 loss_train: 0.00622 loss_val: 0.00730 violation_train: 0.01055 violation_val: 0.01026 time: 0.0623s\n",
      "-------- Epoch 143 --------\n",
      "epoch: 00143 loss_train: 0.00619 loss_val: 0.00748 violation_train: 0.01033 violation_val: 0.01034 time: 0.0629s\n",
      "-------- Epoch 144 --------\n",
      "epoch: 00144 loss_train: 0.00617 loss_val: 0.00732 violation_train: 0.00912 violation_val: 0.01274 time: 0.0631s\n",
      "-------- Epoch 145 --------\n",
      "epoch: 00145 loss_train: 0.00615 loss_val: 0.00715 violation_train: 0.00917 violation_val: 0.01013 time: 0.0597s\n",
      "-------- Epoch 146 --------\n",
      "epoch: 00146 loss_train: 0.00612 loss_val: 0.00747 violation_train: 0.00814 violation_val: 0.00997 time: 0.0598s\n",
      "-------- Epoch 147 --------\n",
      "epoch: 00147 loss_train: 0.00610 loss_val: 0.00731 violation_train: 0.00797 violation_val: 0.01047 time: 0.0592s\n",
      "-------- Epoch 148 --------\n",
      "epoch: 00148 loss_train: 0.00607 loss_val: 0.00708 violation_train: 0.00797 violation_val: 0.00785 time: 0.0577s\n",
      "-------- Epoch 149 --------\n",
      "epoch: 00149 loss_train: 0.00605 loss_val: 0.00713 violation_train: 0.00681 violation_val: 0.00809 time: 0.0582s\n",
      "-------- Epoch 150 --------\n",
      "epoch: 00150 loss_train: 0.00602 loss_val: 0.00707 violation_train: 0.00674 violation_val: 0.00718 time: 0.0582s\n",
      "-------- Epoch 151 --------\n",
      "epoch: 00151 loss_train: 0.00599 loss_val: 0.00699 violation_train: 0.00683 violation_val: 0.00826 time: 0.0573s\n",
      "-------- Epoch 152 --------\n",
      "epoch: 00152 loss_train: 0.00597 loss_val: 0.00703 violation_train: 0.00553 violation_val: 0.00818 time: 0.0569s\n",
      "-------- Epoch 153 --------\n",
      "epoch: 00153 loss_train: 0.00594 loss_val: 0.00687 violation_train: 0.00598 violation_val: 0.00683 time: 0.0595s\n",
      "-------- Epoch 154 --------\n",
      "epoch: 00154 loss_train: 0.00590 loss_val: 0.00687 violation_train: 0.00609 violation_val: 0.00654 time: 0.0639s\n",
      "-------- Epoch 155 --------\n",
      "epoch: 00155 loss_train: 0.00588 loss_val: 0.00697 violation_train: 0.00519 violation_val: 0.00807 time: 0.0596s\n",
      "-------- Epoch 156 --------\n",
      "epoch: 00156 loss_train: 0.00585 loss_val: 0.00680 violation_train: 0.00549 violation_val: 0.00536 time: 0.0591s\n",
      "-------- Epoch 157 --------\n",
      "epoch: 00157 loss_train: 0.00582 loss_val: 0.00673 violation_train: 0.00459 violation_val: 0.00532 time: 0.0589s\n",
      "-------- Epoch 158 --------\n",
      "epoch: 00158 loss_train: 0.00578 loss_val: 0.00681 violation_train: 0.00467 violation_val: 0.00409 time: 0.0582s\n",
      "-------- Epoch 159 --------\n",
      "epoch: 00159 loss_train: 0.00575 loss_val: 0.00675 violation_train: 0.00489 violation_val: 0.00435 time: 0.0613s\n",
      "-------- Epoch 160 --------\n",
      "epoch: 00160 loss_train: 0.00572 loss_val: 0.00687 violation_train: 0.00392 violation_val: 0.00371 time: 0.0639s\n",
      "-------- Epoch 161 --------\n",
      "epoch: 00161 loss_train: 0.00568 loss_val: 0.00699 violation_train: 0.00393 violation_val: 0.00492 time: 0.0620s\n",
      "-------- Epoch 162 --------\n",
      "epoch: 00162 loss_train: 0.00565 loss_val: 0.00676 violation_train: 0.00372 violation_val: 0.00412 time: 0.0632s\n",
      "-------- Epoch 163 --------\n",
      "epoch: 00163 loss_train: 0.00561 loss_val: 0.00653 violation_train: 0.00348 violation_val: 0.00361 time: 0.0638s\n",
      "-------- Epoch 164 --------\n",
      "epoch: 00164 loss_train: 0.00558 loss_val: 0.00648 violation_train: 0.00307 violation_val: 0.00442 time: 0.0616s\n",
      "-------- Epoch 165 --------\n",
      "epoch: 00165 loss_train: 0.00554 loss_val: 0.00648 violation_train: 0.00335 violation_val: 0.00299 time: 0.0622s\n",
      "-------- Epoch 166 --------\n",
      "epoch: 00166 loss_train: 0.00551 loss_val: 0.00652 violation_train: 0.00306 violation_val: 0.00328 time: 0.0624s\n",
      "-------- Epoch 167 --------\n",
      "epoch: 00167 loss_train: 0.00547 loss_val: 0.00642 violation_train: 0.00356 violation_val: 0.00478 time: 0.0631s\n",
      "-------- Epoch 168 --------\n",
      "epoch: 00168 loss_train: 0.00543 loss_val: 0.00651 violation_train: 0.00287 violation_val: 0.00449 time: 0.0634s\n",
      "-------- Epoch 169 --------\n",
      "epoch: 00169 loss_train: 0.00539 loss_val: 0.00624 violation_train: 0.00286 violation_val: 0.00412 time: 0.0615s\n",
      "-------- Epoch 170 --------\n",
      "epoch: 00170 loss_train: 0.00535 loss_val: 0.00635 violation_train: 0.00313 violation_val: 0.00222 time: 0.0604s\n",
      "-------- Epoch 171 --------\n",
      "epoch: 00171 loss_train: 0.00530 loss_val: 0.00621 violation_train: 0.00276 violation_val: 0.00546 time: 0.0623s\n",
      "-------- Epoch 172 --------\n",
      "epoch: 00172 loss_train: 0.00526 loss_val: 0.00625 violation_train: 0.00294 violation_val: 0.00210 time: 0.0624s\n",
      "-------- Epoch 173 --------\n",
      "epoch: 00173 loss_train: 0.00522 loss_val: 0.00631 violation_train: 0.00229 violation_val: 0.00380 time: 0.0626s\n",
      "-------- Epoch 174 --------\n",
      "epoch: 00174 loss_train: 0.00518 loss_val: 0.00616 violation_train: 0.00271 violation_val: 0.00266 time: 0.0632s\n",
      "-------- Epoch 175 --------\n",
      "epoch: 00175 loss_train: 0.00513 loss_val: 0.00629 violation_train: 0.00229 violation_val: 0.00196 time: 0.0593s\n",
      "-------- Epoch 176 --------\n",
      "epoch: 00176 loss_train: 0.00508 loss_val: 0.00599 violation_train: 0.00243 violation_val: 0.00173 time: 0.0593s\n",
      "-------- Epoch 177 --------\n",
      "epoch: 00177 loss_train: 0.00504 loss_val: 0.00589 violation_train: 0.00266 violation_val: 0.00395 time: 0.0586s\n",
      "-------- Epoch 178 --------\n",
      "epoch: 00178 loss_train: 0.00499 loss_val: 0.00595 violation_train: 0.00273 violation_val: 0.00181 time: 0.0581s\n",
      "-------- Epoch 179 --------\n",
      "epoch: 00179 loss_train: 0.00495 loss_val: 0.00596 violation_train: 0.00199 violation_val: 0.00164 time: 0.0575s\n",
      "-------- Epoch 180 --------\n",
      "epoch: 00180 loss_train: 0.00490 loss_val: 0.00593 violation_train: 0.00218 violation_val: 0.00290 time: 0.0573s\n",
      "-------- Epoch 181 --------\n",
      "epoch: 00181 loss_train: 0.00485 loss_val: 0.00571 violation_train: 0.00270 violation_val: 0.00136 time: 0.0576s\n",
      "-------- Epoch 182 --------\n",
      "epoch: 00182 loss_train: 0.00480 loss_val: 0.00568 violation_train: 0.00184 violation_val: 0.00126 time: 0.0597s\n",
      "-------- Epoch 183 --------\n",
      "epoch: 00183 loss_train: 0.00475 loss_val: 0.00561 violation_train: 0.00211 violation_val: 0.00162 time: 0.0630s\n",
      "-------- Epoch 184 --------\n",
      "epoch: 00184 loss_train: 0.00471 loss_val: 0.00563 violation_train: 0.00174 violation_val: 0.00238 time: 0.0632s\n",
      "-------- Epoch 185 --------\n",
      "epoch: 00185 loss_train: 0.00465 loss_val: 0.00549 violation_train: 0.00156 violation_val: 0.00222 time: 0.0614s\n",
      "-------- Epoch 186 --------\n",
      "epoch: 00186 loss_train: 0.00461 loss_val: 0.00546 violation_train: 0.00219 violation_val: 0.00204 time: 0.0596s\n",
      "-------- Epoch 187 --------\n",
      "epoch: 00187 loss_train: 0.00455 loss_val: 0.00542 violation_train: 0.00164 violation_val: 0.00327 time: 0.0583s\n",
      "-------- Epoch 188 --------\n",
      "epoch: 00188 loss_train: 0.00450 loss_val: 0.00535 violation_train: 0.00168 violation_val: 0.00221 time: 0.0596s\n",
      "-------- Epoch 189 --------\n",
      "epoch: 00189 loss_train: 0.00445 loss_val: 0.00528 violation_train: 0.00158 violation_val: 0.00153 time: 0.0618s\n",
      "-------- Epoch 190 --------\n",
      "epoch: 00190 loss_train: 0.00440 loss_val: 0.00515 violation_train: 0.00158 violation_val: 0.00211 time: 0.0633s\n",
      "-------- Epoch 191 --------\n",
      "epoch: 00191 loss_train: 0.00434 loss_val: 0.00524 violation_train: 0.00158 violation_val: 0.00115 time: 0.0645s\n",
      "-------- Epoch 192 --------\n",
      "epoch: 00192 loss_train: 0.00429 loss_val: 0.00506 violation_train: 0.00142 violation_val: 0.00111 time: 0.0629s\n",
      "-------- Epoch 193 --------\n",
      "epoch: 00193 loss_train: 0.00424 loss_val: 0.00502 violation_train: 0.00160 violation_val: 0.00192 time: 0.0609s\n",
      "-------- Epoch 194 --------\n",
      "epoch: 00194 loss_train: 0.00418 loss_val: 0.00504 violation_train: 0.00135 violation_val: 0.00142 time: 0.0611s\n",
      "-------- Epoch 195 --------\n",
      "epoch: 00195 loss_train: 0.00413 loss_val: 0.00490 violation_train: 0.00171 violation_val: 0.00121 time: 0.0606s\n",
      "-------- Epoch 196 --------\n",
      "epoch: 00196 loss_train: 0.00408 loss_val: 0.00489 violation_train: 0.00123 violation_val: 0.00229 time: 0.0603s\n",
      "-------- Epoch 197 --------\n",
      "epoch: 00197 loss_train: 0.00402 loss_val: 0.00486 violation_train: 0.00138 violation_val: 0.00120 time: 0.0602s\n",
      "-------- Epoch 198 --------\n",
      "epoch: 00198 loss_train: 0.00397 loss_val: 0.00474 violation_train: 0.00142 violation_val: 0.00154 time: 0.0601s\n",
      "-------- Epoch 199 --------\n",
      "epoch: 00199 loss_train: 0.00391 loss_val: 0.00470 violation_train: 0.00106 violation_val: 0.00097 time: 0.0580s\n",
      "-------- Epoch 200 --------\n",
      "epoch: 00200 loss_train: 0.00386 loss_val: 0.00462 violation_train: 0.00119 violation_val: 0.00104 time: 0.0583s\n",
      "-------- Epoch 201 --------\n",
      "epoch: 00201 loss_train: 0.00381 loss_val: 0.00453 violation_train: 0.00135 violation_val: 0.00091 time: 0.0580s\n",
      "-------- Epoch 202 --------\n",
      "epoch: 00202 loss_train: 0.00375 loss_val: 0.00451 violation_train: 0.00109 violation_val: 0.00169 time: 0.0583s\n",
      "-------- Epoch 203 --------\n",
      "epoch: 00203 loss_train: 0.00370 loss_val: 0.00444 violation_train: 0.00154 violation_val: 0.00128 time: 0.0591s\n",
      "-------- Epoch 204 --------\n",
      "epoch: 00204 loss_train: 0.00365 loss_val: 0.00434 violation_train: 0.00141 violation_val: 0.00092 time: 0.0681s\n",
      "-------- Epoch 205 --------\n",
      "epoch: 00205 loss_train: 0.00359 loss_val: 0.00438 violation_train: 0.00144 violation_val: 0.00135 time: 0.0638s\n",
      "-------- Epoch 206 --------\n",
      "epoch: 00206 loss_train: 0.00354 loss_val: 0.00440 violation_train: 0.00142 violation_val: 0.00132 time: 0.0611s\n",
      "-------- Epoch 207 --------\n",
      "epoch: 00207 loss_train: 0.00349 loss_val: 0.00426 violation_train: 0.00123 violation_val: 0.00214 time: 0.0595s\n",
      "-------- Epoch 208 --------\n",
      "epoch: 00208 loss_train: 0.00344 loss_val: 0.00427 violation_train: 0.00127 violation_val: 0.00137 time: 0.0599s\n",
      "-------- Epoch 209 --------\n",
      "epoch: 00209 loss_train: 0.00339 loss_val: 0.00412 violation_train: 0.00112 violation_val: 0.00078 time: 0.0610s\n",
      "-------- Epoch 210 --------\n",
      "epoch: 00210 loss_train: 0.00334 loss_val: 0.00407 violation_train: 0.00089 violation_val: 0.00120 time: 0.0648s\n",
      "-------- Epoch 211 --------\n",
      "epoch: 00211 loss_train: 0.00329 loss_val: 0.00413 violation_train: 0.00094 violation_val: 0.00055 time: 0.0632s\n",
      "-------- Epoch 212 --------\n",
      "epoch: 00212 loss_train: 0.00323 loss_val: 0.00397 violation_train: 0.00125 violation_val: 0.00104 time: 0.0631s\n",
      "-------- Epoch 213 --------\n",
      "epoch: 00213 loss_train: 0.00318 loss_val: 0.00387 violation_train: 0.00131 violation_val: 0.00082 time: 0.0634s\n",
      "-------- Epoch 214 --------\n",
      "epoch: 00214 loss_train: 0.00314 loss_val: 0.00372 violation_train: 0.00095 violation_val: 0.00145 time: 0.0644s\n",
      "-------- Epoch 215 --------\n",
      "epoch: 00215 loss_train: 0.00309 loss_val: 0.00377 violation_train: 0.00119 violation_val: 0.00204 time: 0.0619s\n",
      "-------- Epoch 216 --------\n",
      "epoch: 00216 loss_train: 0.00304 loss_val: 0.00367 violation_train: 0.00081 violation_val: 0.00123 time: 0.0622s\n",
      "-------- Epoch 217 --------\n",
      "epoch: 00217 loss_train: 0.00300 loss_val: 0.00388 violation_train: 0.00093 violation_val: 0.00078 time: 0.0600s\n",
      "-------- Epoch 218 --------\n",
      "epoch: 00218 loss_train: 0.00295 loss_val: 0.00348 violation_train: 0.00100 violation_val: 0.00061 time: 0.0601s\n",
      "-------- Epoch 219 --------\n",
      "epoch: 00219 loss_train: 0.00291 loss_val: 0.00350 violation_train: 0.00085 violation_val: 0.00060 time: 0.0605s\n",
      "-------- Epoch 220 --------\n",
      "epoch: 00220 loss_train: 0.00286 loss_val: 0.00338 violation_train: 0.00077 violation_val: 0.00112 time: 0.0653s\n",
      "-------- Epoch 221 --------\n",
      "epoch: 00221 loss_train: 0.00282 loss_val: 0.00341 violation_train: 0.00100 violation_val: 0.00115 time: 0.0648s\n",
      "-------- Epoch 222 --------\n",
      "epoch: 00222 loss_train: 0.00278 loss_val: 0.00333 violation_train: 0.00107 violation_val: 0.00064 time: 0.0651s\n",
      "-------- Epoch 223 --------\n",
      "epoch: 00223 loss_train: 0.00273 loss_val: 0.00326 violation_train: 0.00080 violation_val: 0.00076 time: 0.0625s\n",
      "-------- Epoch 224 --------\n",
      "epoch: 00224 loss_train: 0.00269 loss_val: 0.00327 violation_train: 0.00071 violation_val: 0.00084 time: 0.0617s\n",
      "-------- Epoch 225 --------\n",
      "epoch: 00225 loss_train: 0.00266 loss_val: 0.00314 violation_train: 0.00081 violation_val: 0.00090 time: 0.0598s\n",
      "-------- Epoch 226 --------\n",
      "epoch: 00226 loss_train: 0.00262 loss_val: 0.00318 violation_train: 0.00069 violation_val: 0.00135 time: 0.0621s\n",
      "-------- Epoch 227 --------\n",
      "epoch: 00227 loss_train: 0.00258 loss_val: 0.00312 violation_train: 0.00099 violation_val: 0.00071 time: 0.0612s\n",
      "-------- Epoch 228 --------\n",
      "epoch: 00228 loss_train: 0.00254 loss_val: 0.00305 violation_train: 0.00084 violation_val: 0.00196 time: 0.0602s\n",
      "-------- Epoch 229 --------\n",
      "epoch: 00229 loss_train: 0.00251 loss_val: 0.00296 violation_train: 0.00104 violation_val: 0.00063 time: 0.0614s\n",
      "-------- Epoch 230 --------\n",
      "epoch: 00230 loss_train: 0.00247 loss_val: 0.00291 violation_train: 0.00066 violation_val: 0.00104 time: 0.0604s\n",
      "-------- Epoch 231 --------\n",
      "epoch: 00231 loss_train: 0.00244 loss_val: 0.00293 violation_train: 0.00093 violation_val: 0.00084 time: 0.0590s\n",
      "-------- Epoch 232 --------\n",
      "epoch: 00232 loss_train: 0.00241 loss_val: 0.00284 violation_train: 0.00074 violation_val: 0.00088 time: 0.0594s\n",
      "-------- Epoch 233 --------\n",
      "epoch: 00233 loss_train: 0.00238 loss_val: 0.00280 violation_train: 0.00078 violation_val: 0.00176 time: 0.0627s\n",
      "-------- Epoch 234 --------\n",
      "epoch: 00234 loss_train: 0.00235 loss_val: 0.00289 violation_train: 0.00083 violation_val: 0.00108 time: 0.0597s\n",
      "-------- Epoch 235 --------\n",
      "epoch: 00235 loss_train: 0.00232 loss_val: 0.00276 violation_train: 0.00082 violation_val: 0.00085 time: 0.0580s\n",
      "-------- Epoch 236 --------\n",
      "epoch: 00236 loss_train: 0.00230 loss_val: 0.00270 violation_train: 0.00077 violation_val: 0.00068 time: 0.0576s\n",
      "-------- Epoch 237 --------\n",
      "epoch: 00237 loss_train: 0.00227 loss_val: 0.00269 violation_train: 0.00095 violation_val: 0.00122 time: 0.0573s\n",
      "-------- Epoch 238 --------\n",
      "epoch: 00238 loss_train: 0.00225 loss_val: 0.00270 violation_train: 0.00086 violation_val: 0.00056 time: 0.0580s\n",
      "-------- Epoch 239 --------\n",
      "epoch: 00239 loss_train: 0.00222 loss_val: 0.00266 violation_train: 0.00072 violation_val: 0.00099 time: 0.0577s\n",
      "-------- Epoch 240 --------\n",
      "epoch: 00240 loss_train: 0.00220 loss_val: 0.00268 violation_train: 0.00106 violation_val: 0.00082 time: 0.0582s\n",
      "-------- Epoch 241 --------\n",
      "epoch: 00241 loss_train: 0.00218 loss_val: 0.00260 violation_train: 0.00073 violation_val: 0.00269 time: 0.0587s\n",
      "-------- Epoch 242 --------\n",
      "epoch: 00242 loss_train: 0.00216 loss_val: 0.00254 violation_train: 0.00082 violation_val: 0.00061 time: 0.0605s\n",
      "-------- Epoch 243 --------\n",
      "epoch: 00243 loss_train: 0.00214 loss_val: 0.00249 violation_train: 0.00069 violation_val: 0.00144 time: 0.0607s\n",
      "-------- Epoch 244 --------\n",
      "epoch: 00244 loss_train: 0.00212 loss_val: 0.00250 violation_train: 0.00105 violation_val: 0.00228 time: 0.0599s\n",
      "-------- Epoch 245 --------\n",
      "epoch: 00245 loss_train: 0.00210 loss_val: 0.00250 violation_train: 0.00111 violation_val: 0.00135 time: 0.0587s\n",
      "-------- Epoch 246 --------\n",
      "epoch: 00246 loss_train: 0.00209 loss_val: 0.00245 violation_train: 0.00097 violation_val: 0.00073 time: 0.0589s\n",
      "-------- Epoch 247 --------\n",
      "epoch: 00247 loss_train: 0.00207 loss_val: 0.00241 violation_train: 0.00078 violation_val: 0.00074 time: 0.0601s\n",
      "-------- Epoch 248 --------\n",
      "epoch: 00248 loss_train: 0.00205 loss_val: 0.00243 violation_train: 0.00070 violation_val: 0.00073 time: 0.0629s\n",
      "-------- Epoch 249 --------\n",
      "epoch: 00249 loss_train: 0.00204 loss_val: 0.00247 violation_train: 0.00087 violation_val: 0.00063 time: 0.0619s\n",
      "-------- Epoch 250 --------\n",
      "epoch: 00250 loss_train: 0.00203 loss_val: 0.00243 violation_train: 0.00077 violation_val: 0.00063 time: 0.0621s\n",
      "-------- Epoch 251 --------\n",
      "epoch: 00251 loss_train: 0.00201 loss_val: 0.00237 violation_train: 0.00078 violation_val: 0.00182 time: 0.0609s\n",
      "-------- Epoch 252 --------\n",
      "epoch: 00252 loss_train: 0.00200 loss_val: 0.00251 violation_train: 0.00061 violation_val: 0.00075 time: 0.0585s\n",
      "-------- Epoch 253 --------\n",
      "epoch: 00253 loss_train: 0.00199 loss_val: 0.00235 violation_train: 0.00080 violation_val: 0.00091 time: 0.0576s\n",
      "-------- Epoch 254 --------\n",
      "epoch: 00254 loss_train: 0.00198 loss_val: 0.00229 violation_train: 0.00068 violation_val: 0.00051 time: 0.0637s\n",
      "-------- Epoch 255 --------\n",
      "epoch: 00255 loss_train: 0.00197 loss_val: 0.00237 violation_train: 0.00059 violation_val: 0.00046 time: 0.0632s\n",
      "-------- Epoch 256 --------\n",
      "epoch: 00256 loss_train: 0.00196 loss_val: 0.00231 violation_train: 0.00088 violation_val: 0.00099 time: 0.0646s\n",
      "-------- Epoch 257 --------\n",
      "epoch: 00257 loss_train: 0.00195 loss_val: 0.00225 violation_train: 0.00064 violation_val: 0.00127 time: 0.0628s\n",
      "-------- Epoch 258 --------\n",
      "epoch: 00258 loss_train: 0.00194 loss_val: 0.00228 violation_train: 0.00068 violation_val: 0.00169 time: 0.0650s\n",
      "-------- Epoch 259 --------\n",
      "epoch: 00259 loss_train: 0.00193 loss_val: 0.00223 violation_train: 0.00064 violation_val: 0.00076 time: 0.0642s\n",
      "-------- Epoch 260 --------\n",
      "epoch: 00260 loss_train: 0.00192 loss_val: 0.00228 violation_train: 0.00058 violation_val: 0.00047 time: 0.0611s\n",
      "-------- Epoch 261 --------\n",
      "epoch: 00261 loss_train: 0.00192 loss_val: 0.00225 violation_train: 0.00105 violation_val: 0.00092 time: 0.0593s\n",
      "-------- Epoch 262 --------\n",
      "epoch: 00262 loss_train: 0.00191 loss_val: 0.00222 violation_train: 0.00124 violation_val: 0.00097 time: 0.0624s\n",
      "-------- Epoch 263 --------\n",
      "epoch: 00263 loss_train: 0.00190 loss_val: 0.00218 violation_train: 0.00066 violation_val: 0.00059 time: 0.0599s\n",
      "-------- Epoch 264 --------\n",
      "epoch: 00264 loss_train: 0.00190 loss_val: 0.00222 violation_train: 0.00050 violation_val: 0.00030 time: 0.0659s\n",
      "-------- Epoch 265 --------\n",
      "epoch: 00265 loss_train: 0.00189 loss_val: 0.00214 violation_train: 0.00049 violation_val: 0.00107 time: 0.0689s\n",
      "-------- Epoch 266 --------\n",
      "epoch: 00266 loss_train: 0.00188 loss_val: 0.00218 violation_train: 0.00091 violation_val: 0.00074 time: 0.0668s\n",
      "-------- Epoch 267 --------\n",
      "epoch: 00267 loss_train: 0.00188 loss_val: 0.00224 violation_train: 0.00047 violation_val: 0.00042 time: 0.0653s\n",
      "-------- Epoch 268 --------\n",
      "epoch: 00268 loss_train: 0.00187 loss_val: 0.00214 violation_train: 0.00098 violation_val: 0.00078 time: 0.0604s\n",
      "-------- Epoch 269 --------\n",
      "epoch: 00269 loss_train: 0.00187 loss_val: 0.00221 violation_train: 0.00072 violation_val: 0.00098 time: 0.0613s\n",
      "-------- Epoch 270 --------\n",
      "epoch: 00270 loss_train: 0.00186 loss_val: 0.00216 violation_train: 0.00081 violation_val: 0.00038 time: 0.0613s\n",
      "-------- Epoch 271 --------\n",
      "epoch: 00271 loss_train: 0.00186 loss_val: 0.00210 violation_train: 0.00064 violation_val: 0.00098 time: 0.0623s\n",
      "-------- Epoch 272 --------\n",
      "epoch: 00272 loss_train: 0.00186 loss_val: 0.00214 violation_train: 0.00055 violation_val: 0.00032 time: 0.0605s\n",
      "-------- Epoch 273 --------\n",
      "epoch: 00273 loss_train: 0.00185 loss_val: 0.00213 violation_train: 0.00048 violation_val: 0.00060 time: 0.0607s\n",
      "-------- Epoch 274 --------\n",
      "epoch: 00274 loss_train: 0.00185 loss_val: 0.00211 violation_train: 0.00048 violation_val: 0.00036 time: 0.0599s\n",
      "-------- Epoch 275 --------\n",
      "epoch: 00275 loss_train: 0.00185 loss_val: 0.00208 violation_train: 0.00056 violation_val: 0.00070 time: 0.0595s\n",
      "-------- Epoch 276 --------\n",
      "epoch: 00276 loss_train: 0.00184 loss_val: 0.00209 violation_train: 0.00046 violation_val: 0.00123 time: 0.0580s\n",
      "-------- Epoch 277 --------\n",
      "epoch: 00277 loss_train: 0.00184 loss_val: 0.00209 violation_train: 0.00088 violation_val: 0.00097 time: 0.0577s\n",
      "-------- Epoch 278 --------\n",
      "epoch: 00278 loss_train: 0.00184 loss_val: 0.00208 violation_train: 0.00153 violation_val: 0.00045 time: 0.0595s\n",
      "-------- Epoch 279 --------\n",
      "epoch: 00279 loss_train: 0.00183 loss_val: 0.00209 violation_train: 0.00044 violation_val: 0.00046 time: 0.0593s\n",
      "-------- Epoch 280 --------\n",
      "epoch: 00280 loss_train: 0.00183 loss_val: 0.00206 violation_train: 0.00079 violation_val: 0.00033 time: 0.0586s\n",
      "-------- Epoch 281 --------\n",
      "epoch: 00281 loss_train: 0.00183 loss_val: 0.00213 violation_train: 0.00067 violation_val: 0.00072 time: 0.0581s\n",
      "-------- Epoch 282 --------\n",
      "epoch: 00282 loss_train: 0.00183 loss_val: 0.00213 violation_train: 0.00045 violation_val: 0.00033 time: 0.0597s\n",
      "-------- Epoch 283 --------\n",
      "epoch: 00283 loss_train: 0.00183 loss_val: 0.00216 violation_train: 0.00033 violation_val: 0.00052 time: 0.0580s\n",
      "-------- Epoch 284 --------\n",
      "epoch: 00284 loss_train: 0.00182 loss_val: 0.00207 violation_train: 0.00064 violation_val: 0.00064 time: 0.0574s\n",
      "-------- Epoch 285 --------\n",
      "epoch: 00285 loss_train: 0.00182 loss_val: 0.00206 violation_train: 0.00053 violation_val: 0.00052 time: 0.0586s\n",
      "-------- Epoch 286 --------\n",
      "epoch: 00286 loss_train: 0.00182 loss_val: 0.00207 violation_train: 0.00064 violation_val: 0.00028 time: 0.0586s\n",
      "-------- Epoch 287 --------\n",
      "epoch: 00287 loss_train: 0.00182 loss_val: 0.00207 violation_train: 0.00030 violation_val: 0.00084 time: 0.0579s\n",
      "-------- Epoch 288 --------\n",
      "epoch: 00288 loss_train: 0.00182 loss_val: 0.00206 violation_train: 0.00048 violation_val: 0.00039 time: 0.0571s\n",
      "-------- Epoch 289 --------\n",
      "epoch: 00289 loss_train: 0.00182 loss_val: 0.00205 violation_train: 0.00052 violation_val: 0.00052 time: 0.0574s\n",
      "-------- Epoch 290 --------\n",
      "epoch: 00290 loss_train: 0.00182 loss_val: 0.00202 violation_train: 0.00058 violation_val: 0.00088 time: 0.0582s\n",
      "-------- Epoch 291 --------\n",
      "epoch: 00291 loss_train: 0.00181 loss_val: 0.00204 violation_train: 0.00047 violation_val: 0.00048 time: 0.0574s\n",
      "-------- Epoch 292 --------\n",
      "epoch: 00292 loss_train: 0.00181 loss_val: 0.00205 violation_train: 0.00043 violation_val: 0.00025 time: 0.0613s\n",
      "-------- Epoch 293 --------\n",
      "epoch: 00293 loss_train: 0.00181 loss_val: 0.00207 violation_train: 0.00039 violation_val: 0.00027 time: 0.0604s\n",
      "-------- Epoch 294 --------\n",
      "epoch: 00294 loss_train: 0.00181 loss_val: 0.00206 violation_train: 0.00024 violation_val: 0.00022 time: 0.0588s\n",
      "-------- Epoch 295 --------\n",
      "epoch: 00295 loss_train: 0.00181 loss_val: 0.00202 violation_train: 0.00037 violation_val: 0.00024 time: 0.0582s\n",
      "-------- Epoch 296 --------\n",
      "epoch: 00296 loss_train: 0.00181 loss_val: 0.00202 violation_train: 0.00037 violation_val: 0.00041 time: 0.0608s\n",
      "-------- Epoch 297 --------\n",
      "epoch: 00297 loss_train: 0.00181 loss_val: 0.00199 violation_train: 0.00069 violation_val: 0.00080 time: 0.0659s\n",
      "-------- Epoch 298 --------\n",
      "epoch: 00298 loss_train: 0.00181 loss_val: 0.00204 violation_train: 0.00049 violation_val: 0.00105 time: 0.0658s\n",
      "-------- Epoch 299 --------\n",
      "epoch: 00299 loss_train: 0.00181 loss_val: 0.00199 violation_train: 0.00050 violation_val: 0.00036 time: 0.0635s\n",
      "-------- Epoch 300 --------\n",
      "epoch: 00300 loss_train: 0.00181 loss_val: 0.00202 violation_train: 0.00051 violation_val: 0.00031 time: 0.0626s\n",
      "-------- Epoch 301 --------\n",
      "epoch: 00301 loss_train: 0.00181 loss_val: 0.00201 violation_train: 0.00038 violation_val: 0.00041 time: 0.0653s\n",
      "-------- Epoch 302 --------\n",
      "epoch: 00302 loss_train: 0.00180 loss_val: 0.00209 violation_train: 0.00047 violation_val: 0.00073 time: 0.0862s\n",
      "-------- Epoch 303 --------\n",
      "epoch: 00303 loss_train: 0.00180 loss_val: 0.00203 violation_train: 0.00082 violation_val: 0.00313 time: 0.0716s\n",
      "-------- Epoch 304 --------\n",
      "epoch: 00304 loss_train: 0.00180 loss_val: 0.00207 violation_train: 0.00066 violation_val: 0.00048 time: 0.0641s\n",
      "-------- Epoch 305 --------\n",
      "epoch: 00305 loss_train: 0.00180 loss_val: 0.00200 violation_train: 0.00033 violation_val: 0.00036 time: 0.0697s\n",
      "-------- Epoch 306 --------\n",
      "epoch: 00306 loss_train: 0.00180 loss_val: 0.00205 violation_train: 0.00039 violation_val: 0.00052 time: 0.0667s\n",
      "-------- Epoch 307 --------\n",
      "epoch: 00307 loss_train: 0.00180 loss_val: 0.00210 violation_train: 0.00035 violation_val: 0.00053 time: 0.0632s\n",
      "-------- Epoch 308 --------\n",
      "epoch: 00308 loss_train: 0.00180 loss_val: 0.00201 violation_train: 0.00034 violation_val: 0.00024 time: 0.0627s\n",
      "-------- Epoch 309 --------\n",
      "epoch: 00309 loss_train: 0.00180 loss_val: 0.00200 violation_train: 0.00031 violation_val: 0.00253 time: 0.0670s\n",
      "-------- Epoch 310 --------\n",
      "epoch: 00310 loss_train: 0.00180 loss_val: 0.00207 violation_train: 0.00038 violation_val: 0.00095 time: 0.0639s\n",
      "-------- Epoch 311 --------\n",
      "epoch: 00311 loss_train: 0.00180 loss_val: 0.00199 violation_train: 0.00087 violation_val: 0.00057 time: 0.0621s\n",
      "-------- Epoch 312 --------\n",
      "epoch: 00312 loss_train: 0.00180 loss_val: 0.00198 violation_train: 0.00041 violation_val: 0.00047 time: 0.0615s\n",
      "-------- Epoch 313 --------\n",
      "epoch: 00313 loss_train: 0.00180 loss_val: 0.00202 violation_train: 0.00063 violation_val: 0.00050 time: 0.0598s\n",
      "-------- Epoch 314 --------\n",
      "epoch: 00314 loss_train: 0.00180 loss_val: 0.00209 violation_train: 0.00042 violation_val: 0.00100 time: 0.0611s\n",
      "-------- Epoch 315 --------\n",
      "epoch: 00315 loss_train: 0.00180 loss_val: 0.00202 violation_train: 0.00048 violation_val: 0.00025 time: 0.0609s\n",
      "-------- Epoch 316 --------\n",
      "epoch: 00316 loss_train: 0.00180 loss_val: 0.00197 violation_train: 0.00063 violation_val: 0.00025 time: 0.0599s\n",
      "-------- Epoch 317 --------\n",
      "epoch: 00317 loss_train: 0.00180 loss_val: 0.00202 violation_train: 0.00017 violation_val: 0.00067 time: 0.0595s\n",
      "-------- Epoch 318 --------\n",
      "epoch: 00318 loss_train: 0.00179 loss_val: 0.00204 violation_train: 0.00044 violation_val: 0.00034 time: 0.0587s\n",
      "-------- Epoch 319 --------\n",
      "epoch: 00319 loss_train: 0.00179 loss_val: 0.00196 violation_train: 0.00028 violation_val: 0.00033 time: 0.0589s\n",
      "-------- Epoch 320 --------\n",
      "epoch: 00320 loss_train: 0.00179 loss_val: 0.00198 violation_train: 0.00034 violation_val: 0.00043 time: 0.0577s\n",
      "-------- Epoch 321 --------\n",
      "epoch: 00321 loss_train: 0.00179 loss_val: 0.00196 violation_train: 0.00026 violation_val: 0.00025 time: 0.0585s\n",
      "-------- Epoch 322 --------\n",
      "epoch: 00322 loss_train: 0.00179 loss_val: 0.00196 violation_train: 0.00040 violation_val: 0.00150 time: 0.0578s\n",
      "-------- Epoch 323 --------\n",
      "epoch: 00323 loss_train: 0.00179 loss_val: 0.00203 violation_train: 0.00108 violation_val: 0.00032 time: 0.0604s\n",
      "-------- Epoch 324 --------\n",
      "epoch: 00324 loss_train: 0.00179 loss_val: 0.00198 violation_train: 0.00059 violation_val: 0.00055 time: 0.0619s\n",
      "-------- Epoch 325 --------\n",
      "epoch: 00325 loss_train: 0.00179 loss_val: 0.00198 violation_train: 0.00024 violation_val: 0.00033 time: 0.0655s\n",
      "-------- Epoch 326 --------\n",
      "epoch: 00326 loss_train: 0.00179 loss_val: 0.00199 violation_train: 0.00022 violation_val: 0.00076 time: 0.0640s\n",
      "-------- Epoch 327 --------\n",
      "epoch: 00327 loss_train: 0.00179 loss_val: 0.00199 violation_train: 0.00051 violation_val: 0.00072 time: 0.0641s\n",
      "-------- Epoch 328 --------\n",
      "epoch: 00328 loss_train: 0.00179 loss_val: 0.00201 violation_train: 0.00059 violation_val: 0.00031 time: 0.0629s\n",
      "-------- Epoch 329 --------\n",
      "epoch: 00329 loss_train: 0.00179 loss_val: 0.00203 violation_train: 0.00027 violation_val: 0.00015 time: 0.0633s\n",
      "-------- Epoch 330 --------\n",
      "epoch: 00330 loss_train: 0.00179 loss_val: 0.00198 violation_train: 0.00023 violation_val: 0.00068 time: 0.0639s\n",
      "-------- Epoch 331 --------\n",
      "epoch: 00331 loss_train: 0.00179 loss_val: 0.00194 violation_train: 0.00025 violation_val: 0.00027 time: 0.0609s\n",
      "-------- Epoch 332 --------\n",
      "epoch: 00332 loss_train: 0.00179 loss_val: 0.00203 violation_train: 0.00054 violation_val: 0.00061 time: 0.0607s\n",
      "-------- Epoch 333 --------\n",
      "epoch: 00333 loss_train: 0.00179 loss_val: 0.00205 violation_train: 0.00092 violation_val: 0.00119 time: 0.0599s\n",
      "-------- Epoch 334 --------\n",
      "epoch: 00334 loss_train: 0.00179 loss_val: 0.00197 violation_train: 0.00061 violation_val: 0.00037 time: 0.0641s\n",
      "-------- Epoch 335 --------\n",
      "epoch: 00335 loss_train: 0.00179 loss_val: 0.00197 violation_train: 0.00032 violation_val: 0.00023 time: 0.0641s\n",
      "-------- Epoch 336 --------\n",
      "epoch: 00336 loss_train: 0.00179 loss_val: 0.00202 violation_train: 0.00027 violation_val: 0.00044 time: 0.0625s\n",
      "-------- Epoch 337 --------\n",
      "epoch: 00337 loss_train: 0.00179 loss_val: 0.00210 violation_train: 0.00019 violation_val: 0.00024 time: 0.0634s\n",
      "-------- Epoch 338 --------\n",
      "epoch: 00338 loss_train: 0.00179 loss_val: 0.00197 violation_train: 0.00023 violation_val: 0.00048 time: 0.0621s\n",
      "-------- Epoch 339 --------\n",
      "epoch: 00339 loss_train: 0.00179 loss_val: 0.00197 violation_train: 0.00081 violation_val: 0.00086 time: 0.0640s\n",
      "-------- Epoch 340 --------\n",
      "epoch: 00340 loss_train: 0.00178 loss_val: 0.00207 violation_train: 0.00052 violation_val: 0.00022 time: 0.0624s\n",
      "-------- Epoch 341 --------\n",
      "epoch: 00341 loss_train: 0.00178 loss_val: 0.00197 violation_train: 0.00103 violation_val: 0.00073 time: 0.0642s\n",
      "-------- Epoch 342 --------\n",
      "epoch: 00342 loss_train: 0.00178 loss_val: 0.00197 violation_train: 0.00014 violation_val: 0.00016 time: 0.0601s\n",
      "-------- Epoch 343 --------\n",
      "epoch: 00343 loss_train: 0.00178 loss_val: 0.00203 violation_train: 0.00011 violation_val: 0.00024 time: 0.0603s\n",
      "-------- Epoch 344 --------\n",
      "epoch: 00344 loss_train: 0.00178 loss_val: 0.00196 violation_train: 0.00011 violation_val: 0.00032 time: 0.0594s\n",
      "-------- Epoch 345 --------\n",
      "epoch: 00345 loss_train: 0.00178 loss_val: 0.00196 violation_train: 0.00012 violation_val: 0.00014 time: 0.0629s\n",
      "-------- Epoch 346 --------\n",
      "epoch: 00346 loss_train: 0.00178 loss_val: 0.00196 violation_train: 0.00009 violation_val: 0.00016 time: 0.0605s\n",
      "-------- Epoch 347 --------\n",
      "epoch: 00347 loss_train: 0.00178 loss_val: 0.00197 violation_train: 0.00007 violation_val: 0.00068 time: 0.0590s\n",
      "-------- Epoch 348 --------\n",
      "epoch: 00348 loss_train: 0.00178 loss_val: 0.00199 violation_train: 0.00063 violation_val: 0.00355 time: 0.0584s\n",
      "-------- Epoch 349 --------\n",
      "epoch: 00349 loss_train: 0.00178 loss_val: 0.00195 violation_train: 0.00096 violation_val: 0.00021 time: 0.0592s\n",
      "-------- Epoch 350 --------\n",
      "epoch: 00350 loss_train: 0.00178 loss_val: 0.00197 violation_train: 0.00013 violation_val: 0.00023 time: 0.0581s\n",
      "-------- Epoch 351 --------\n",
      "epoch: 00351 loss_train: 0.00178 loss_val: 0.00198 violation_train: 0.00010 violation_val: 0.00014 time: 0.0575s\n",
      "-------- Epoch 352 --------\n",
      "epoch: 00352 loss_train: 0.00178 loss_val: 0.00199 violation_train: 0.00009 violation_val: 0.00014 time: 0.0578s\n",
      "-------- Epoch 353 --------\n",
      "epoch: 00353 loss_train: 0.00178 loss_val: 0.00196 violation_train: 0.00010 violation_val: 0.00023 time: 0.0622s\n",
      "-------- Epoch 354 --------\n",
      "epoch: 00354 loss_train: 0.00178 loss_val: 0.00202 violation_train: 0.00014 violation_val: 0.00029 time: 0.0605s\n",
      "-------- Epoch 355 --------\n",
      "epoch: 00355 loss_train: 0.00178 loss_val: 0.00193 violation_train: 0.00041 violation_val: 0.00045 time: 0.0596s\n",
      "-------- Epoch 356 --------\n",
      "epoch: 00356 loss_train: 0.00178 loss_val: 0.00200 violation_train: 0.00031 violation_val: 0.00029 time: 0.0619s\n",
      "-------- Epoch 357 --------\n",
      "epoch: 00357 loss_train: 0.00178 loss_val: 0.00196 violation_train: 0.00038 violation_val: 0.00062 time: 0.0618s\n",
      "-------- Epoch 358 --------\n",
      "epoch: 00358 loss_train: 0.00178 loss_val: 0.00195 violation_train: 0.00025 violation_val: 0.00041 time: 0.0604s\n",
      "-------- Epoch 359 --------\n",
      "epoch: 00359 loss_train: 0.00178 loss_val: 0.00199 violation_train: 0.00065 violation_val: 0.00192 time: 0.0582s\n",
      "-------- Epoch 360 --------\n",
      "epoch: 00360 loss_train: 0.00178 loss_val: 0.00199 violation_train: 0.00052 violation_val: 0.00030 time: 0.0576s\n",
      "-------- Epoch 361 --------\n",
      "epoch: 00361 loss_train: 0.00177 loss_val: 0.00200 violation_train: 0.00019 violation_val: 0.00026 time: 0.0580s\n",
      "-------- Epoch 362 --------\n",
      "epoch: 00362 loss_train: 0.00178 loss_val: 0.00200 violation_train: 0.00021 violation_val: 0.00037 time: 0.0578s\n",
      "-------- Epoch 363 --------\n",
      "epoch: 00363 loss_train: 0.00177 loss_val: 0.00202 violation_train: 0.00060 violation_val: 0.00096 time: 0.0582s\n",
      "-------- Epoch 364 --------\n",
      "epoch: 00364 loss_train: 0.00177 loss_val: 0.00197 violation_train: 0.00104 violation_val: 0.00108 time: 0.0572s\n",
      "-------- Epoch 365 --------\n",
      "epoch: 00365 loss_train: 0.00177 loss_val: 0.00195 violation_train: 0.00053 violation_val: 0.00014 time: 0.0583s\n",
      "-------- Epoch 366 --------\n",
      "epoch: 00366 loss_train: 0.00177 loss_val: 0.00201 violation_train: 0.00012 violation_val: 0.00018 time: 0.0578s\n",
      "-------- Epoch 367 --------\n",
      "epoch: 00367 loss_train: 0.00177 loss_val: 0.00198 violation_train: 0.00013 violation_val: 0.00022 time: 0.0572s\n",
      "-------- Epoch 368 --------\n",
      "epoch: 00368 loss_train: 0.00177 loss_val: 0.00198 violation_train: 0.00018 violation_val: 0.00113 time: 0.0572s\n",
      "-------- Epoch 369 --------\n",
      "epoch: 00369 loss_train: 0.00177 loss_val: 0.00201 violation_train: 0.00044 violation_val: 0.00024 time: 0.0580s\n",
      "-------- Epoch 370 --------\n",
      "epoch: 00370 loss_train: 0.00177 loss_val: 0.00197 violation_train: 0.00063 violation_val: 0.00035 time: 0.0577s\n",
      "-------- Epoch 371 --------\n",
      "epoch: 00371 loss_train: 0.00177 loss_val: 0.00192 violation_train: 0.00012 violation_val: 0.00039 time: 0.0576s\n",
      "-------- Epoch 372 --------\n",
      "epoch: 00372 loss_train: 0.00177 loss_val: 0.00194 violation_train: 0.00057 violation_val: 0.00088 time: 0.0573s\n",
      "-------- Epoch 373 --------\n",
      "epoch: 00373 loss_train: 0.00177 loss_val: 0.00195 violation_train: 0.00052 violation_val: 0.00024 time: 0.0578s\n",
      "-------- Epoch 374 --------\n",
      "epoch: 00374 loss_train: 0.00177 loss_val: 0.00194 violation_train: 0.00025 violation_val: 0.00016 time: 0.0575s\n",
      "-------- Epoch 375 --------\n",
      "epoch: 00375 loss_train: 0.00177 loss_val: 0.00194 violation_train: 0.00018 violation_val: 0.00021 time: 0.0572s\n",
      "-------- Epoch 376 --------\n",
      "epoch: 00376 loss_train: 0.00177 loss_val: 0.00194 violation_train: 0.00098 violation_val: 0.00175 time: 0.0569s\n",
      "-------- Epoch 377 --------\n",
      "epoch: 00377 loss_train: 0.00177 loss_val: 0.00193 violation_train: 0.00091 violation_val: 0.00059 time: 0.0589s\n",
      "-------- Epoch 378 --------\n",
      "epoch: 00378 loss_train: 0.00177 loss_val: 0.00195 violation_train: 0.00034 violation_val: 0.00036 time: 0.0576s\n",
      "-------- Epoch 379 --------\n",
      "epoch: 00379 loss_train: 0.00177 loss_val: 0.00199 violation_train: 0.00007 violation_val: 0.00018 time: 0.0573s\n",
      "-------- Epoch 380 --------\n",
      "epoch: 00380 loss_train: 0.00177 loss_val: 0.00206 violation_train: 0.00007 violation_val: 0.00015 time: 0.0573s\n",
      "-------- Epoch 381 --------\n",
      "epoch: 00381 loss_train: 0.00177 loss_val: 0.00199 violation_train: 0.00006 violation_val: 0.00013 time: 0.0582s\n",
      "-------- Epoch 382 --------\n",
      "epoch: 00382 loss_train: 0.00177 loss_val: 0.00202 violation_train: 0.00012 violation_val: 0.00022 time: 0.0575s\n",
      "-------- Epoch 383 --------\n",
      "epoch: 00383 loss_train: 0.00177 loss_val: 0.00198 violation_train: 0.00032 violation_val: 0.00027 time: 0.0571s\n",
      "-------- Epoch 384 --------\n",
      "epoch: 00384 loss_train: 0.00176 loss_val: 0.00195 violation_train: 0.00038 violation_val: 0.00038 time: 0.0572s\n",
      "-------- Epoch 385 --------\n",
      "epoch: 00385 loss_train: 0.00176 loss_val: 0.00197 violation_train: 0.00061 violation_val: 0.00021 time: 0.0578s\n",
      "-------- Epoch 386 --------\n",
      "epoch: 00386 loss_train: 0.00176 loss_val: 0.00197 violation_train: 0.00035 violation_val: 0.00024 time: 0.0577s\n",
      "-------- Epoch 387 --------\n",
      "epoch: 00387 loss_train: 0.00176 loss_val: 0.00195 violation_train: 0.00019 violation_val: 0.00030 time: 0.0571s\n",
      "-------- Epoch 388 --------\n",
      "epoch: 00388 loss_train: 0.00176 loss_val: 0.00212 violation_train: 0.00034 violation_val: 0.00026 time: 0.0572s\n",
      "-------- Epoch 389 --------\n",
      "epoch: 00389 loss_train: 0.00176 loss_val: 0.00202 violation_train: 0.00060 violation_val: 0.00030 time: 0.0582s\n",
      "-------- Epoch 390 --------\n",
      "epoch: 00390 loss_train: 0.00176 loss_val: 0.00196 violation_train: 0.00019 violation_val: 0.00046 time: 0.0575s\n",
      "-------- Epoch 391 --------\n",
      "epoch: 00391 loss_train: 0.00176 loss_val: 0.00197 violation_train: 0.00053 violation_val: 0.00066 time: 0.0570s\n",
      "-------- Epoch 392 --------\n",
      "epoch: 00392 loss_train: 0.00176 loss_val: 0.00194 violation_train: 0.00022 violation_val: 0.00030 time: 0.0571s\n",
      "-------- Epoch 393 --------\n",
      "epoch: 00393 loss_train: 0.00176 loss_val: 0.00194 violation_train: 0.00062 violation_val: 0.00079 time: 0.0577s\n",
      "-------- Epoch 394 --------\n",
      "epoch: 00394 loss_train: 0.00176 loss_val: 0.00198 violation_train: 0.00051 violation_val: 0.00079 time: 0.0575s\n",
      "-------- Epoch 395 --------\n",
      "epoch: 00395 loss_train: 0.00176 loss_val: 0.00197 violation_train: 0.00075 violation_val: 0.00040 time: 0.0573s\n",
      "-------- Epoch 396 --------\n",
      "epoch: 00396 loss_train: 0.00176 loss_val: 0.00202 violation_train: 0.00023 violation_val: 0.00017 time: 0.0571s\n",
      "-------- Epoch 397 --------\n",
      "epoch: 00397 loss_train: 0.00176 loss_val: 0.00196 violation_train: 0.00025 violation_val: 0.00085 time: 0.0579s\n",
      "-------- Epoch 398 --------\n",
      "epoch: 00398 loss_train: 0.00176 loss_val: 0.00196 violation_train: 0.00080 violation_val: 0.00027 time: 0.0573s\n",
      "-------- Epoch 399 --------\n",
      "epoch: 00399 loss_train: 0.00176 loss_val: 0.00194 violation_train: 0.00033 violation_val: 0.00023 time: 0.0576s\n",
      "-------- Epoch 400 --------\n",
      "epoch: 00400 loss_train: 0.00176 loss_val: 0.00194 violation_train: 0.00012 violation_val: 0.00021 time: 0.0617s\n",
      "-------- Epoch 401 --------\n",
      "epoch: 00401 loss_train: 0.00176 loss_val: 0.00194 violation_train: 0.00091 violation_val: 0.00037 time: 0.0600s\n",
      "-------- Epoch 402 --------\n",
      "epoch: 00402 loss_train: 0.00176 loss_val: 0.00195 violation_train: 0.00028 violation_val: 0.00027 time: 0.0591s\n",
      "-------- Epoch 403 --------\n",
      "epoch: 00403 loss_train: 0.00176 loss_val: 0.00193 violation_train: 0.00043 violation_val: 0.00028 time: 0.0583s\n",
      "-------- Epoch 404 --------\n",
      "epoch: 00404 loss_train: 0.00176 loss_val: 0.00197 violation_train: 0.00021 violation_val: 0.00020 time: 0.0574s\n",
      "-------- Epoch 405 --------\n",
      "epoch: 00405 loss_train: 0.00176 loss_val: 0.00195 violation_train: 0.00026 violation_val: 0.00107 time: 0.0584s\n",
      "-------- Epoch 406 --------\n",
      "epoch: 00406 loss_train: 0.00176 loss_val: 0.00198 violation_train: 0.00051 violation_val: 0.00023 time: 0.0580s\n",
      "-------- Epoch 407 --------\n",
      "epoch: 00407 loss_train: 0.00176 loss_val: 0.00194 violation_train: 0.00070 violation_val: 0.00098 time: 0.0579s\n",
      "-------- Epoch 408 --------\n",
      "epoch: 00408 loss_train: 0.00176 loss_val: 0.00191 violation_train: 0.00095 violation_val: 0.00048 time: 0.0579s\n",
      "-------- Epoch 409 --------\n",
      "epoch: 00409 loss_train: 0.00175 loss_val: 0.00193 violation_train: 0.00013 violation_val: 0.00018 time: 0.0589s\n",
      "-------- Epoch 410 --------\n",
      "epoch: 00410 loss_train: 0.00175 loss_val: 0.00200 violation_train: 0.00009 violation_val: 0.00016 time: 0.0578s\n",
      "-------- Epoch 411 --------\n",
      "epoch: 00411 loss_train: 0.00175 loss_val: 0.00193 violation_train: 0.00007 violation_val: 0.00013 time: 0.0580s\n",
      "-------- Epoch 412 --------\n",
      "epoch: 00412 loss_train: 0.00175 loss_val: 0.00195 violation_train: 0.00013 violation_val: 0.00030 time: 0.0576s\n",
      "-------- Epoch 413 --------\n",
      "epoch: 00413 loss_train: 0.00175 loss_val: 0.00198 violation_train: 0.00111 violation_val: 0.00142 time: 0.0581s\n",
      "-------- Epoch 414 --------\n",
      "epoch: 00414 loss_train: 0.00175 loss_val: 0.00193 violation_train: 0.00091 violation_val: 0.00065 time: 0.0576s\n",
      "-------- Epoch 415 --------\n",
      "epoch: 00415 loss_train: 0.00175 loss_val: 0.00195 violation_train: 0.00043 violation_val: 0.00038 time: 0.0571s\n",
      "-------- Epoch 416 --------\n",
      "epoch: 00416 loss_train: 0.00175 loss_val: 0.00195 violation_train: 0.00015 violation_val: 0.00047 time: 0.0571s\n",
      "-------- Epoch 417 --------\n",
      "epoch: 00417 loss_train: 0.00175 loss_val: 0.00202 violation_train: 0.00012 violation_val: 0.00013 time: 0.0584s\n",
      "-------- Epoch 418 --------\n",
      "epoch: 00418 loss_train: 0.00175 loss_val: 0.00195 violation_train: 0.00006 violation_val: 0.00028 time: 0.0585s\n",
      "-------- Epoch 419 --------\n",
      "epoch: 00419 loss_train: 0.00175 loss_val: 0.00196 violation_train: 0.00014 violation_val: 0.00035 time: 0.0581s\n",
      "-------- Epoch 420 --------\n",
      "epoch: 00420 loss_train: 0.00175 loss_val: 0.00197 violation_train: 0.00013 violation_val: 0.00018 time: 0.0577s\n",
      "-------- Epoch 421 --------\n",
      "epoch: 00421 loss_train: 0.00175 loss_val: 0.00199 violation_train: 0.00030 violation_val: 0.00038 time: 0.0600s\n",
      "-------- Epoch 422 --------\n",
      "epoch: 00422 loss_train: 0.00175 loss_val: 0.00193 violation_train: 0.00041 violation_val: 0.00039 time: 0.0600s\n",
      "-------- Epoch 423 --------\n",
      "epoch: 00423 loss_train: 0.00175 loss_val: 0.00198 violation_train: 0.00082 violation_val: 0.00188 time: 0.0575s\n",
      "-------- Epoch 424 --------\n",
      "epoch: 00424 loss_train: 0.00175 loss_val: 0.00199 violation_train: 0.00041 violation_val: 0.00027 time: 0.0573s\n",
      "-------- Epoch 425 --------\n",
      "epoch: 00425 loss_train: 0.00175 loss_val: 0.00196 violation_train: 0.00029 violation_val: 0.00082 time: 0.0582s\n",
      "-------- Epoch 426 --------\n",
      "epoch: 00426 loss_train: 0.00175 loss_val: 0.00195 violation_train: 0.00032 violation_val: 0.00016 time: 0.0578s\n",
      "-------- Epoch 427 --------\n",
      "epoch: 00427 loss_train: 0.00175 loss_val: 0.00190 violation_train: 0.00012 violation_val: 0.00047 time: 0.0582s\n",
      "-------- Epoch 428 --------\n",
      "epoch: 00428 loss_train: 0.00175 loss_val: 0.00193 violation_train: 0.00042 violation_val: 0.00135 time: 0.0575s\n",
      "-------- Epoch 429 --------\n",
      "epoch: 00429 loss_train: 0.00175 loss_val: 0.00191 violation_train: 0.00113 violation_val: 0.00035 time: 0.0587s\n",
      "-------- Epoch 430 --------\n",
      "epoch: 00430 loss_train: 0.00175 loss_val: 0.00199 violation_train: 0.00026 violation_val: 0.00040 time: 0.0578s\n",
      "-------- Epoch 431 --------\n",
      "epoch: 00431 loss_train: 0.00175 loss_val: 0.00192 violation_train: 0.00021 violation_val: 0.00022 time: 0.0612s\n",
      "-------- Epoch 432 --------\n",
      "epoch: 00432 loss_train: 0.00175 loss_val: 0.00193 violation_train: 0.00008 violation_val: 0.00014 time: 0.0575s\n",
      "-------- Epoch 433 --------\n",
      "epoch: 00433 loss_train: 0.00175 loss_val: 0.00192 violation_train: 0.00015 violation_val: 0.00055 time: 0.0591s\n",
      "-------- Epoch 434 --------\n",
      "epoch: 00434 loss_train: 0.00174 loss_val: 0.00200 violation_train: 0.00019 violation_val: 0.00021 time: 0.0578s\n",
      "-------- Epoch 435 --------\n",
      "epoch: 00435 loss_train: 0.00174 loss_val: 0.00195 violation_train: 0.00077 violation_val: 0.00031 time: 0.0574s\n",
      "-------- Epoch 436 --------\n",
      "epoch: 00436 loss_train: 0.00174 loss_val: 0.00197 violation_train: 0.00011 violation_val: 0.00018 time: 0.0573s\n",
      "-------- Epoch 437 --------\n",
      "epoch: 00437 loss_train: 0.00174 loss_val: 0.00194 violation_train: 0.00010 violation_val: 0.00028 time: 0.0581s\n",
      "-------- Epoch 438 --------\n",
      "epoch: 00438 loss_train: 0.00174 loss_val: 0.00200 violation_train: 0.00014 violation_val: 0.00046 time: 0.0575s\n",
      "-------- Epoch 439 --------\n",
      "epoch: 00439 loss_train: 0.00174 loss_val: 0.00196 violation_train: 0.00015 violation_val: 0.00123 time: 0.0573s\n",
      "-------- Epoch 440 --------\n",
      "epoch: 00440 loss_train: 0.00174 loss_val: 0.00196 violation_train: 0.00050 violation_val: 0.00024 time: 0.0571s\n",
      "-------- Epoch 441 --------\n",
      "epoch: 00441 loss_train: 0.00174 loss_val: 0.00197 violation_train: 0.00037 violation_val: 0.00141 time: 0.0584s\n",
      "-------- Epoch 442 --------\n",
      "epoch: 00442 loss_train: 0.00174 loss_val: 0.00191 violation_train: 0.00098 violation_val: 0.00077 time: 0.0584s\n",
      "-------- Epoch 443 --------\n",
      "epoch: 00443 loss_train: 0.00174 loss_val: 0.00198 violation_train: 0.00022 violation_val: 0.00022 time: 0.0578s\n",
      "-------- Epoch 444 --------\n",
      "epoch: 00444 loss_train: 0.00174 loss_val: 0.00199 violation_train: 0.00016 violation_val: 0.00035 time: 0.0575s\n",
      "-------- Epoch 445 --------\n",
      "epoch: 00445 loss_train: 0.00174 loss_val: 0.00197 violation_train: 0.00021 violation_val: 0.00017 time: 0.0583s\n",
      "-------- Epoch 446 --------\n",
      "epoch: 00446 loss_train: 0.00174 loss_val: 0.00196 violation_train: 0.00042 violation_val: 0.00022 time: 0.0583s\n",
      "-------- Epoch 447 --------\n",
      "epoch: 00447 loss_train: 0.00174 loss_val: 0.00207 violation_train: 0.00045 violation_val: 0.00036 time: 0.0574s\n",
      "-------- Epoch 448 --------\n",
      "epoch: 00448 loss_train: 0.00174 loss_val: 0.00199 violation_train: 0.00079 violation_val: 0.00105 time: 0.0574s\n",
      "-------- Epoch 449 --------\n",
      "epoch: 00449 loss_train: 0.00174 loss_val: 0.00191 violation_train: 0.00064 violation_val: 0.00014 time: 0.0610s\n",
      "-------- Epoch 450 --------\n",
      "epoch: 00450 loss_train: 0.00174 loss_val: 0.00190 violation_train: 0.00006 violation_val: 0.00021 time: 0.0596s\n",
      "-------- Epoch 451 --------\n",
      "epoch: 00451 loss_train: 0.00174 loss_val: 0.00193 violation_train: 0.00009 violation_val: 0.00011 time: 0.0629s\n",
      "-------- Epoch 452 --------\n",
      "epoch: 00452 loss_train: 0.00174 loss_val: 0.00194 violation_train: 0.00014 violation_val: 0.00046 time: 0.0641s\n",
      "-------- Epoch 453 --------\n",
      "epoch: 00453 loss_train: 0.00174 loss_val: 0.00190 violation_train: 0.00039 violation_val: 0.00224 time: 0.0668s\n",
      "-------- Epoch 454 --------\n",
      "epoch: 00454 loss_train: 0.00174 loss_val: 0.00192 violation_train: 0.00055 violation_val: 0.00062 time: 0.0675s\n",
      "-------- Epoch 455 --------\n",
      "epoch: 00455 loss_train: 0.00174 loss_val: 0.00200 violation_train: 0.00032 violation_val: 0.00039 time: 0.0659s\n",
      "-------- Epoch 456 --------\n",
      "epoch: 00456 loss_train: 0.00174 loss_val: 0.00195 violation_train: 0.00116 violation_val: 0.00203 time: 0.0634s\n",
      "-------- Epoch 457 --------\n",
      "epoch: 00457 loss_train: 0.00174 loss_val: 0.00194 violation_train: 0.00093 violation_val: 0.00031 time: 0.0619s\n",
      "-------- Epoch 458 --------\n",
      "epoch: 00458 loss_train: 0.00174 loss_val: 0.00192 violation_train: 0.00011 violation_val: 0.00020 time: 0.0602s\n",
      "-------- Epoch 459 --------\n",
      "epoch: 00459 loss_train: 0.00174 loss_val: 0.00192 violation_train: 0.00007 violation_val: 0.00015 time: 0.0606s\n",
      "-------- Epoch 460 --------\n",
      "epoch: 00460 loss_train: 0.00173 loss_val: 0.00201 violation_train: 0.00022 violation_val: 0.00031 time: 0.0635s\n",
      "-------- Epoch 461 --------\n",
      "epoch: 00461 loss_train: 0.00173 loss_val: 0.00192 violation_train: 0.00017 violation_val: 0.00019 time: 0.0680s\n",
      "-------- Epoch 462 --------\n",
      "epoch: 00462 loss_train: 0.00173 loss_val: 0.00206 violation_train: 0.00013 violation_val: 0.00017 time: 0.0678s\n",
      "-------- Epoch 463 --------\n",
      "epoch: 00463 loss_train: 0.00173 loss_val: 0.00199 violation_train: 0.00010 violation_val: 0.00026 time: 0.0672s\n",
      "-------- Epoch 464 --------\n",
      "epoch: 00464 loss_train: 0.00173 loss_val: 0.00195 violation_train: 0.00019 violation_val: 0.00172 time: 0.0610s\n",
      "-------- Epoch 465 --------\n",
      "epoch: 00465 loss_train: 0.00173 loss_val: 0.00191 violation_train: 0.00271 violation_val: 0.00146 time: 0.0601s\n",
      "-------- Epoch 466 --------\n",
      "epoch: 00466 loss_train: 0.00173 loss_val: 0.00200 violation_train: 0.00059 violation_val: 0.00016 time: 0.0594s\n",
      "-------- Epoch 467 --------\n",
      "epoch: 00467 loss_train: 0.00173 loss_val: 0.00201 violation_train: 0.00007 violation_val: 0.00012 time: 0.0597s\n",
      "-------- Epoch 468 --------\n",
      "epoch: 00468 loss_train: 0.00173 loss_val: 0.00193 violation_train: 0.00003 violation_val: 0.00013 time: 0.0624s\n",
      "-------- Epoch 469 --------\n",
      "epoch: 00469 loss_train: 0.00173 loss_val: 0.00197 violation_train: 0.00004 violation_val: 0.00011 time: 0.0621s\n",
      "-------- Epoch 470 --------\n",
      "epoch: 00470 loss_train: 0.00173 loss_val: 0.00193 violation_train: 0.00004 violation_val: 0.00012 time: 0.0604s\n",
      "-------- Epoch 471 --------\n",
      "epoch: 00471 loss_train: 0.00173 loss_val: 0.00206 violation_train: 0.00004 violation_val: 0.00011 time: 0.0589s\n",
      "-------- Epoch 472 --------\n",
      "epoch: 00472 loss_train: 0.00173 loss_val: 0.00191 violation_train: 0.00004 violation_val: 0.00011 time: 0.0580s\n",
      "-------- Epoch 473 --------\n",
      "epoch: 00473 loss_train: 0.00173 loss_val: 0.00197 violation_train: 0.00004 violation_val: 0.00011 time: 0.0580s\n",
      "-------- Epoch 474 --------\n",
      "epoch: 00474 loss_train: 0.00173 loss_val: 0.00191 violation_train: 0.00004 violation_val: 0.00013 time: 0.0579s\n",
      "-------- Epoch 475 --------\n",
      "epoch: 00475 loss_train: 0.00173 loss_val: 0.00193 violation_train: 0.00004 violation_val: 0.00012 time: 0.0573s\n",
      "-------- Epoch 476 --------\n",
      "epoch: 00476 loss_train: 0.00173 loss_val: 0.00188 violation_train: 0.00005 violation_val: 0.00016 time: 0.0576s\n",
      "-------- Epoch 477 --------\n",
      "epoch: 00477 loss_train: 0.00173 loss_val: 0.00194 violation_train: 0.00005 violation_val: 0.00013 time: 0.0578s\n",
      "-------- Epoch 478 --------\n",
      "epoch: 00478 loss_train: 0.00173 loss_val: 0.00192 violation_train: 0.00006 violation_val: 0.00014 time: 0.0575s\n",
      "-------- Epoch 479 --------\n",
      "epoch: 00479 loss_train: 0.00173 loss_val: 0.00191 violation_train: 0.00007 violation_val: 0.00022 time: 0.0573s\n",
      "-------- Epoch 480 --------\n",
      "epoch: 00480 loss_train: 0.00173 loss_val: 0.00193 violation_train: 0.00012 violation_val: 0.00017 time: 0.0577s\n",
      "-------- Epoch 481 --------\n",
      "epoch: 00481 loss_train: 0.00173 loss_val: 0.00193 violation_train: 0.00009 violation_val: 0.00017 time: 0.0599s\n",
      "-------- Epoch 482 --------\n",
      "epoch: 00482 loss_train: 0.00173 loss_val: 0.00193 violation_train: 0.00009 violation_val: 0.00022 time: 0.0578s\n",
      "-------- Epoch 483 --------\n",
      "epoch: 00483 loss_train: 0.00173 loss_val: 0.00191 violation_train: 0.00014 violation_val: 0.00025 time: 0.0574s\n",
      "-------- Epoch 484 --------\n",
      "epoch: 00484 loss_train: 0.00173 loss_val: 0.00193 violation_train: 0.00016 violation_val: 0.00045 time: 0.0573s\n",
      "-------- Epoch 485 --------\n",
      "epoch: 00485 loss_train: 0.00173 loss_val: 0.00201 violation_train: 0.00048 violation_val: 0.00158 time: 0.0579s\n",
      "-------- Epoch 486 --------\n",
      "epoch: 00486 loss_train: 0.00173 loss_val: 0.00188 violation_train: 0.00165 violation_val: 0.00052 time: 0.0580s\n",
      "-------- Epoch 487 --------\n",
      "epoch: 00487 loss_train: 0.00173 loss_val: 0.00196 violation_train: 0.00015 violation_val: 0.00014 time: 0.0579s\n",
      "-------- Epoch 488 --------\n",
      "epoch: 00488 loss_train: 0.00173 loss_val: 0.00191 violation_train: 0.00006 violation_val: 0.00017 time: 0.0586s\n",
      "-------- Epoch 489 --------\n",
      "epoch: 00489 loss_train: 0.00173 loss_val: 0.00189 violation_train: 0.00007 violation_val: 0.00029 time: 0.0583s\n",
      "-------- Epoch 490 --------\n",
      "epoch: 00490 loss_train: 0.00172 loss_val: 0.00192 violation_train: 0.00008 violation_val: 0.00019 time: 0.0586s\n",
      "-------- Epoch 491 --------\n",
      "epoch: 00491 loss_train: 0.00173 loss_val: 0.00198 violation_train: 0.00007 violation_val: 0.00024 time: 0.0575s\n",
      "-------- Epoch 492 --------\n",
      "epoch: 00492 loss_train: 0.00172 loss_val: 0.00196 violation_train: 0.00007 violation_val: 0.00016 time: 0.0575s\n",
      "-------- Epoch 493 --------\n",
      "epoch: 00493 loss_train: 0.00172 loss_val: 0.00189 violation_train: 0.00007 violation_val: 0.00019 time: 0.0619s\n",
      "-------- Epoch 494 --------\n",
      "epoch: 00494 loss_train: 0.00172 loss_val: 0.00191 violation_train: 0.00010 violation_val: 0.00017 time: 0.0596s\n",
      "-------- Epoch 495 --------\n",
      "epoch: 00495 loss_train: 0.00172 loss_val: 0.00191 violation_train: 0.00017 violation_val: 0.00048 time: 0.0587s\n",
      "-------- Epoch 496 --------\n",
      "epoch: 00496 loss_train: 0.00172 loss_val: 0.00194 violation_train: 0.00022 violation_val: 0.00056 time: 0.0578s\n",
      "-------- Epoch 497 --------\n",
      "epoch: 00497 loss_train: 0.00172 loss_val: 0.00188 violation_train: 0.00080 violation_val: 0.00027 time: 0.0596s\n",
      "-------- Epoch 498 --------\n",
      "epoch: 00498 loss_train: 0.00172 loss_val: 0.00198 violation_train: 0.00013 violation_val: 0.00016 time: 0.0588s\n",
      "-------- Epoch 499 --------\n",
      "epoch: 00499 loss_train: 0.00172 loss_val: 0.00196 violation_train: 0.00011 violation_val: 0.00022 time: 0.0573s\n",
      "-------- Epoch 500 --------\n",
      "epoch: 00500 loss_train: 0.00172 loss_val: 0.00192 violation_train: 0.00045 violation_val: 0.00042 time: 0.0572s\n",
      "-------- Epoch 501 --------\n",
      "epoch: 00501 loss_train: 0.00172 loss_val: 0.00189 violation_train: 0.00038 violation_val: 0.00020 time: 0.0585s\n",
      "-------- Epoch 502 --------\n",
      "epoch: 00502 loss_train: 0.00172 loss_val: 0.00200 violation_train: 0.00045 violation_val: 0.00077 time: 0.0573s\n",
      "-------- Epoch 503 --------\n",
      "epoch: 00503 loss_train: 0.00172 loss_val: 0.00194 violation_train: 0.00083 violation_val: 0.00066 time: 0.0572s\n",
      "-------- Epoch 504 --------\n",
      "epoch: 00504 loss_train: 0.00172 loss_val: 0.00192 violation_train: 0.00089 violation_val: 0.00034 time: 0.0571s\n",
      "-------- Epoch 505 --------\n",
      "epoch: 00505 loss_train: 0.00172 loss_val: 0.00190 violation_train: 0.00013 violation_val: 0.00018 time: 0.0579s\n",
      "-------- Epoch 506 --------\n",
      "epoch: 00506 loss_train: 0.00172 loss_val: 0.00194 violation_train: 0.00011 violation_val: 0.00016 time: 0.0581s\n",
      "-------- Epoch 507 --------\n",
      "epoch: 00507 loss_train: 0.00172 loss_val: 0.00190 violation_train: 0.00012 violation_val: 0.00017 time: 0.0574s\n",
      "-------- Epoch 508 --------\n",
      "epoch: 00508 loss_train: 0.00172 loss_val: 0.00189 violation_train: 0.00011 violation_val: 0.00024 time: 0.0571s\n",
      "-------- Epoch 509 --------\n",
      "epoch: 00509 loss_train: 0.00172 loss_val: 0.00201 violation_train: 0.00123 violation_val: 0.00065 time: 0.0579s\n",
      "-------- Epoch 510 --------\n",
      "epoch: 00510 loss_train: 0.00172 loss_val: 0.00191 violation_train: 0.00032 violation_val: 0.00019 time: 0.0573s\n",
      "-------- Epoch 511 --------\n",
      "epoch: 00511 loss_train: 0.00172 loss_val: 0.00197 violation_train: 0.00009 violation_val: 0.00018 time: 0.0576s\n",
      "-------- Epoch 512 --------\n",
      "epoch: 00512 loss_train: 0.00172 loss_val: 0.00190 violation_train: 0.00011 violation_val: 0.00014 time: 0.0574s\n",
      "-------- Epoch 513 --------\n",
      "epoch: 00513 loss_train: 0.00172 loss_val: 0.00193 violation_train: 0.00009 violation_val: 0.00027 time: 0.0584s\n",
      "-------- Epoch 514 --------\n",
      "epoch: 00514 loss_train: 0.00172 loss_val: 0.00192 violation_train: 0.00024 violation_val: 0.00044 time: 0.0574s\n",
      "-------- Epoch 515 --------\n",
      "epoch: 00515 loss_train: 0.00172 loss_val: 0.00192 violation_train: 0.00020 violation_val: 0.00028 time: 0.0572s\n",
      "-------- Epoch 516 --------\n",
      "epoch: 00516 loss_train: 0.00172 loss_val: 0.00191 violation_train: 0.00014 violation_val: 0.00018 time: 0.0572s\n",
      "-------- Epoch 517 --------\n",
      "epoch: 00517 loss_train: 0.00172 loss_val: 0.00194 violation_train: 0.00038 violation_val: 0.00057 time: 0.0579s\n",
      "-------- Epoch 518 --------\n",
      "epoch: 00518 loss_train: 0.00172 loss_val: 0.00190 violation_train: 0.00077 violation_val: 0.00129 time: 0.0574s\n",
      "-------- Epoch 519 --------\n",
      "epoch: 00519 loss_train: 0.00172 loss_val: 0.00189 violation_train: 0.00069 violation_val: 0.00017 time: 0.0572s\n",
      "-------- Epoch 520 --------\n",
      "epoch: 00520 loss_train: 0.00172 loss_val: 0.00194 violation_train: 0.00013 violation_val: 0.00023 time: 0.0572s\n",
      "-------- Epoch 521 --------\n",
      "epoch: 00521 loss_train: 0.00171 loss_val: 0.00190 violation_train: 0.00031 violation_val: 0.00032 time: 0.0580s\n",
      "-------- Epoch 522 --------\n",
      "epoch: 00522 loss_train: 0.00171 loss_val: 0.00195 violation_train: 0.00019 violation_val: 0.00049 time: 0.0574s\n",
      "-------- Epoch 523 --------\n",
      "epoch: 00523 loss_train: 0.00171 loss_val: 0.00192 violation_train: 0.00097 violation_val: 0.00146 time: 0.0572s\n",
      "-------- Epoch 524 --------\n",
      "epoch: 00524 loss_train: 0.00171 loss_val: 0.00190 violation_train: 0.00125 violation_val: 0.00125 time: 0.0572s\n",
      "-------- Epoch 525 --------\n",
      "epoch: 00525 loss_train: 0.00171 loss_val: 0.00192 violation_train: 0.00021 violation_val: 0.00017 time: 0.0578s\n",
      "-------- Epoch 526 --------\n",
      "epoch: 00526 loss_train: 0.00171 loss_val: 0.00194 violation_train: 0.00005 violation_val: 0.00013 time: 0.0575s\n",
      "-------- Epoch 527 --------\n",
      "epoch: 00527 loss_train: 0.00171 loss_val: 0.00187 violation_train: 0.00007 violation_val: 0.00025 time: 0.0576s\n",
      "-------- Epoch 528 --------\n",
      "epoch: 00528 loss_train: 0.00171 loss_val: 0.00189 violation_train: 0.00006 violation_val: 0.00013 time: 0.0574s\n",
      "-------- Epoch 529 --------\n",
      "epoch: 00529 loss_train: 0.00171 loss_val: 0.00191 violation_train: 0.00010 violation_val: 0.00021 time: 0.0579s\n",
      "-------- Epoch 530 --------\n",
      "epoch: 00530 loss_train: 0.00171 loss_val: 0.00192 violation_train: 0.00018 violation_val: 0.00033 time: 0.0574s\n",
      "-------- Epoch 531 --------\n",
      "epoch: 00531 loss_train: 0.00171 loss_val: 0.00191 violation_train: 0.00011 violation_val: 0.00015 time: 0.0572s\n",
      "-------- Epoch 532 --------\n",
      "epoch: 00532 loss_train: 0.00171 loss_val: 0.00196 violation_train: 0.00009 violation_val: 0.00017 time: 0.0572s\n",
      "-------- Epoch 533 --------\n",
      "epoch: 00533 loss_train: 0.00171 loss_val: 0.00193 violation_train: 0.00073 violation_val: 0.00096 time: 0.0580s\n",
      "-------- Epoch 534 --------\n",
      "epoch: 00534 loss_train: 0.00171 loss_val: 0.00191 violation_train: 0.00080 violation_val: 0.00103 time: 0.0574s\n",
      "-------- Epoch 535 --------\n",
      "epoch: 00535 loss_train: 0.00171 loss_val: 0.00194 violation_train: 0.00039 violation_val: 0.00012 time: 0.0571s\n",
      "-------- Epoch 536 --------\n",
      "epoch: 00536 loss_train: 0.00171 loss_val: 0.00199 violation_train: 0.00006 violation_val: 0.00017 time: 0.0571s\n",
      "-------- Epoch 537 --------\n",
      "epoch: 00537 loss_train: 0.00171 loss_val: 0.00188 violation_train: 0.00014 violation_val: 0.00013 time: 0.0575s\n",
      "-------- Epoch 538 --------\n",
      "epoch: 00538 loss_train: 0.00171 loss_val: 0.00190 violation_train: 0.00006 violation_val: 0.00012 time: 0.0573s\n",
      "-------- Epoch 539 --------\n",
      "epoch: 00539 loss_train: 0.00171 loss_val: 0.00200 violation_train: 0.00120 violation_val: 0.00293 time: 0.0579s\n",
      "-------- Epoch 540 --------\n",
      "epoch: 00540 loss_train: 0.00171 loss_val: 0.00195 violation_train: 0.00111 violation_val: 0.00024 time: 0.0607s\n",
      "-------- Epoch 541 --------\n",
      "epoch: 00541 loss_train: 0.00171 loss_val: 0.00192 violation_train: 0.00008 violation_val: 0.00019 time: 0.0595s\n",
      "-------- Epoch 542 --------\n",
      "epoch: 00542 loss_train: 0.00171 loss_val: 0.00197 violation_train: 0.00005 violation_val: 0.00016 time: 0.0601s\n",
      "-------- Epoch 543 --------\n",
      "epoch: 00543 loss_train: 0.00171 loss_val: 0.00194 violation_train: 0.00006 violation_val: 0.00014 time: 0.0590s\n",
      "-------- Epoch 544 --------\n",
      "epoch: 00544 loss_train: 0.00171 loss_val: 0.00193 violation_train: 0.00005 violation_val: 0.00031 time: 0.0598s\n",
      "-------- Epoch 545 --------\n",
      "epoch: 00545 loss_train: 0.00171 loss_val: 0.00192 violation_train: 0.00005 violation_val: 0.00016 time: 0.0597s\n",
      "-------- Epoch 546 --------\n",
      "epoch: 00546 loss_train: 0.00171 loss_val: 0.00193 violation_train: 0.00004 violation_val: 0.00012 time: 0.0577s\n",
      "-------- Epoch 547 --------\n",
      "epoch: 00547 loss_train: 0.00171 loss_val: 0.00189 violation_train: 0.00005 violation_val: 0.00029 time: 0.0605s\n",
      "-------- Epoch 548 --------\n",
      "epoch: 00548 loss_train: 0.00171 loss_val: 0.00190 violation_train: 0.00008 violation_val: 0.00011 time: 0.0601s\n",
      "-------- Epoch 549 --------\n",
      "epoch: 00549 loss_train: 0.00171 loss_val: 0.00197 violation_train: 0.00007 violation_val: 0.00024 time: 0.0601s\n",
      "-------- Epoch 550 --------\n",
      "epoch: 00550 loss_train: 0.00170 loss_val: 0.00197 violation_train: 0.00013 violation_val: 0.00015 time: 0.0593s\n",
      "-------- Epoch 551 --------\n",
      "epoch: 00551 loss_train: 0.00170 loss_val: 0.00192 violation_train: 0.00027 violation_val: 0.00058 time: 0.0580s\n",
      "-------- Epoch 552 --------\n",
      "epoch: 00552 loss_train: 0.00170 loss_val: 0.00197 violation_train: 0.00020 violation_val: 0.00053 time: 0.0588s\n",
      "-------- Epoch 553 --------\n",
      "epoch: 00553 loss_train: 0.00170 loss_val: 0.00189 violation_train: 0.00149 violation_val: 0.00068 time: 0.0592s\n",
      "-------- Epoch 554 --------\n",
      "epoch: 00554 loss_train: 0.00170 loss_val: 0.00187 violation_train: 0.00047 violation_val: 0.00022 time: 0.0581s\n",
      "-------- Epoch 555 --------\n",
      "epoch: 00555 loss_train: 0.00170 loss_val: 0.00190 violation_train: 0.00009 violation_val: 0.00011 time: 0.0574s\n",
      "-------- Epoch 556 --------\n",
      "epoch: 00556 loss_train: 0.00170 loss_val: 0.00193 violation_train: 0.00005 violation_val: 0.00013 time: 0.0595s\n",
      "-------- Epoch 557 --------\n",
      "epoch: 00557 loss_train: 0.00170 loss_val: 0.00191 violation_train: 0.00007 violation_val: 0.00012 time: 0.0596s\n",
      "-------- Epoch 558 --------\n",
      "epoch: 00558 loss_train: 0.00170 loss_val: 0.00199 violation_train: 0.00005 violation_val: 0.00013 time: 0.0588s\n",
      "-------- Epoch 559 --------\n",
      "epoch: 00559 loss_train: 0.00170 loss_val: 0.00189 violation_train: 0.00007 violation_val: 0.00014 time: 0.0595s\n",
      "-------- Epoch 560 --------\n",
      "epoch: 00560 loss_train: 0.00170 loss_val: 0.00188 violation_train: 0.00006 violation_val: 0.00012 time: 0.0577s\n",
      "-------- Epoch 561 --------\n",
      "epoch: 00561 loss_train: 0.00170 loss_val: 0.00197 violation_train: 0.00029 violation_val: 0.00078 time: 0.0596s\n",
      "-------- Epoch 562 --------\n",
      "epoch: 00562 loss_train: 0.00170 loss_val: 0.00190 violation_train: 0.00052 violation_val: 0.00014 time: 0.0581s\n",
      "-------- Epoch 563 --------\n",
      "epoch: 00563 loss_train: 0.00170 loss_val: 0.00187 violation_train: 0.00012 violation_val: 0.00019 time: 0.0572s\n",
      "-------- Epoch 564 --------\n",
      "epoch: 00564 loss_train: 0.00170 loss_val: 0.00193 violation_train: 0.00023 violation_val: 0.00100 time: 0.0586s\n",
      "-------- Epoch 565 --------\n",
      "epoch: 00565 loss_train: 0.00170 loss_val: 0.00191 violation_train: 0.00088 violation_val: 0.00019 time: 0.0594s\n",
      "-------- Epoch 566 --------\n",
      "epoch: 00566 loss_train: 0.00170 loss_val: 0.00189 violation_train: 0.00011 violation_val: 0.00013 time: 0.0588s\n",
      "-------- Epoch 567 --------\n",
      "epoch: 00567 loss_train: 0.00170 loss_val: 0.00190 violation_train: 0.00030 violation_val: 0.00050 time: 0.0638s\n",
      "-------- Epoch 568 --------\n",
      "epoch: 00568 loss_train: 0.00170 loss_val: 0.00187 violation_train: 0.00024 violation_val: 0.00173 time: 0.0597s\n",
      "-------- Epoch 569 --------\n",
      "epoch: 00569 loss_train: 0.00170 loss_val: 0.00188 violation_train: 0.00025 violation_val: 0.00025 time: 0.0598s\n",
      "-------- Epoch 570 --------\n",
      "epoch: 00570 loss_train: 0.00170 loss_val: 0.00193 violation_train: 0.00053 violation_val: 0.00032 time: 0.0593s\n",
      "-------- Epoch 571 --------\n",
      "epoch: 00571 loss_train: 0.00170 loss_val: 0.00200 violation_train: 0.00048 violation_val: 0.00039 time: 0.0585s\n",
      "-------- Epoch 572 --------\n",
      "epoch: 00572 loss_train: 0.00170 loss_val: 0.00192 violation_train: 0.00103 violation_val: 0.00066 time: 0.0585s\n",
      "-------- Epoch 573 --------\n",
      "epoch: 00573 loss_train: 0.00170 loss_val: 0.00193 violation_train: 0.00029 violation_val: 0.00031 time: 0.0591s\n",
      "-------- Epoch 574 --------\n",
      "epoch: 00574 loss_train: 0.00170 loss_val: 0.00188 violation_train: 0.00008 violation_val: 0.00014 time: 0.0587s\n",
      "-------- Epoch 575 --------\n",
      "epoch: 00575 loss_train: 0.00170 loss_val: 0.00197 violation_train: 0.00007 violation_val: 0.00013 time: 0.0585s\n",
      "-------- Epoch 576 --------\n",
      "epoch: 00576 loss_train: 0.00170 loss_val: 0.00201 violation_train: 0.00027 violation_val: 0.00049 time: 0.0577s\n",
      "-------- Epoch 577 --------\n",
      "epoch: 00577 loss_train: 0.00170 loss_val: 0.00189 violation_train: 0.00058 violation_val: 0.00034 time: 0.0587s\n",
      "-------- Epoch 578 --------\n",
      "epoch: 00578 loss_train: 0.00170 loss_val: 0.00191 violation_train: 0.00027 violation_val: 0.00018 time: 0.0649s\n",
      "-------- Epoch 579 --------\n",
      "epoch: 00579 loss_train: 0.00170 loss_val: 0.00190 violation_train: 0.00031 violation_val: 0.00015 time: 0.0652s\n",
      "-------- Epoch 580 --------\n",
      "epoch: 00580 loss_train: 0.00169 loss_val: 0.00190 violation_train: 0.00100 violation_val: 0.00359 time: 0.0635s\n",
      "-------- Epoch 581 --------\n",
      "epoch: 00581 loss_train: 0.00169 loss_val: 0.00192 violation_train: 0.00084 violation_val: 0.00033 time: 0.0607s\n",
      "-------- Epoch 582 --------\n",
      "epoch: 00582 loss_train: 0.00169 loss_val: 0.00195 violation_train: 0.00022 violation_val: 0.00021 time: 0.0586s\n",
      "-------- Epoch 583 --------\n",
      "epoch: 00583 loss_train: 0.00170 loss_val: 0.00192 violation_train: 0.00007 violation_val: 0.00012 time: 0.0605s\n",
      "-------- Epoch 584 --------\n",
      "epoch: 00584 loss_train: 0.00170 loss_val: 0.00189 violation_train: 0.00006 violation_val: 0.00022 time: 0.0592s\n",
      "-------- Epoch 585 --------\n",
      "epoch: 00585 loss_train: 0.00169 loss_val: 0.00186 violation_train: 0.00013 violation_val: 0.00016 time: 0.0586s\n",
      "-------- Epoch 586 --------\n",
      "epoch: 00586 loss_train: 0.00169 loss_val: 0.00186 violation_train: 0.00009 violation_val: 0.00016 time: 0.0579s\n",
      "-------- Epoch 587 --------\n",
      "epoch: 00587 loss_train: 0.00169 loss_val: 0.00192 violation_train: 0.00055 violation_val: 0.00108 time: 0.0573s\n",
      "-------- Epoch 588 --------\n",
      "epoch: 00588 loss_train: 0.00169 loss_val: 0.00194 violation_train: 0.00036 violation_val: 0.00016 time: 0.0573s\n",
      "-------- Epoch 589 --------\n",
      "epoch: 00589 loss_train: 0.00169 loss_val: 0.00186 violation_train: 0.00010 violation_val: 0.00017 time: 0.0577s\n",
      "-------- Epoch 590 --------\n",
      "epoch: 00590 loss_train: 0.00169 loss_val: 0.00190 violation_train: 0.00008 violation_val: 0.00019 time: 0.0578s\n",
      "-------- Epoch 591 --------\n",
      "epoch: 00591 loss_train: 0.00169 loss_val: 0.00194 violation_train: 0.00025 violation_val: 0.00089 time: 0.0574s\n",
      "-------- Epoch 592 --------\n",
      "epoch: 00592 loss_train: 0.00169 loss_val: 0.00190 violation_train: 0.00062 violation_val: 0.00231 time: 0.0573s\n",
      "-------- Epoch 593 --------\n",
      "epoch: 00593 loss_train: 0.00169 loss_val: 0.00187 violation_train: 0.00072 violation_val: 0.00044 time: 0.0580s\n",
      "-------- Epoch 594 --------\n",
      "epoch: 00594 loss_train: 0.00169 loss_val: 0.00190 violation_train: 0.00038 violation_val: 0.00033 time: 0.0573s\n",
      "-------- Epoch 595 --------\n",
      "epoch: 00595 loss_train: 0.00169 loss_val: 0.00189 violation_train: 0.00036 violation_val: 0.00015 time: 0.0572s\n",
      "-------- Epoch 596 --------\n",
      "epoch: 00596 loss_train: 0.00169 loss_val: 0.00187 violation_train: 0.00014 violation_val: 0.00038 time: 0.0571s\n",
      "-------- Epoch 597 --------\n",
      "epoch: 00597 loss_train: 0.00169 loss_val: 0.00195 violation_train: 0.00016 violation_val: 0.00018 time: 0.0579s\n",
      "-------- Epoch 598 --------\n",
      "epoch: 00598 loss_train: 0.00169 loss_val: 0.00189 violation_train: 0.00039 violation_val: 0.00072 time: 0.0597s\n",
      "-------- Epoch 599 --------\n",
      "epoch: 00599 loss_train: 0.00169 loss_val: 0.00192 violation_train: 0.00125 violation_val: 0.00135 time: 0.0611s\n",
      "-------- Epoch 600 --------\n",
      "epoch: 00600 loss_train: 0.00169 loss_val: 0.00193 violation_train: 0.00024 violation_val: 0.00015 time: 0.0588s\n",
      "-------- Epoch 601 --------\n",
      "epoch: 00601 loss_train: 0.00169 loss_val: 0.00194 violation_train: 0.00005 violation_val: 0.00012 time: 0.0593s\n",
      "-------- Epoch 602 --------\n",
      "epoch: 00602 loss_train: 0.00169 loss_val: 0.00192 violation_train: 0.00005 violation_val: 0.00015 time: 0.0585s\n",
      "-------- Epoch 603 --------\n",
      "epoch: 00603 loss_train: 0.00169 loss_val: 0.00190 violation_train: 0.00017 violation_val: 0.00035 time: 0.0579s\n",
      "-------- Epoch 604 --------\n",
      "epoch: 00604 loss_train: 0.00169 loss_val: 0.00190 violation_train: 0.00024 violation_val: 0.00040 time: 0.0645s\n",
      "-------- Epoch 605 --------\n",
      "epoch: 00605 loss_train: 0.00169 loss_val: 0.00192 violation_train: 0.00028 violation_val: 0.00041 time: 0.0650s\n",
      "-------- Epoch 606 --------\n",
      "epoch: 00606 loss_train: 0.00169 loss_val: 0.00191 violation_train: 0.00050 violation_val: 0.00047 time: 0.0593s\n",
      "-------- Epoch 607 --------\n",
      "epoch: 00607 loss_train: 0.00169 loss_val: 0.00191 violation_train: 0.00037 violation_val: 0.00039 time: 0.0600s\n",
      "-------- Epoch 608 --------\n",
      "epoch: 00608 loss_train: 0.00169 loss_val: 0.00189 violation_train: 0.00072 violation_val: 0.00051 time: 0.0604s\n",
      "-------- Epoch 609 --------\n",
      "epoch: 00609 loss_train: 0.00169 loss_val: 0.00190 violation_train: 0.00156 violation_val: 0.00137 time: 0.0604s\n",
      "-------- Epoch 610 --------\n",
      "epoch: 00610 loss_train: 0.00169 loss_val: 0.00198 violation_train: 0.00032 violation_val: 0.00016 time: 0.0613s\n",
      "-------- Epoch 611 --------\n",
      "epoch: 00611 loss_train: 0.00169 loss_val: 0.00186 violation_train: 0.00006 violation_val: 0.00017 time: 0.0612s\n",
      "-------- Epoch 612 --------\n",
      "epoch: 00612 loss_train: 0.00169 loss_val: 0.00195 violation_train: 0.00006 violation_val: 0.00021 time: 0.0600s\n",
      "-------- Epoch 613 --------\n",
      "epoch: 00613 loss_train: 0.00168 loss_val: 0.00185 violation_train: 0.00006 violation_val: 0.00015 time: 0.0620s\n",
      "-------- Epoch 614 --------\n",
      "epoch: 00614 loss_train: 0.00169 loss_val: 0.00194 violation_train: 0.00004 violation_val: 0.00015 time: 0.0596s\n",
      "-------- Epoch 615 --------\n",
      "epoch: 00615 loss_train: 0.00168 loss_val: 0.00191 violation_train: 0.00007 violation_val: 0.00014 time: 0.0578s\n",
      "-------- Epoch 616 --------\n",
      "epoch: 00616 loss_train: 0.00168 loss_val: 0.00190 violation_train: 0.00007 violation_val: 0.00013 time: 0.0575s\n",
      "-------- Epoch 617 --------\n",
      "epoch: 00617 loss_train: 0.00168 loss_val: 0.00190 violation_train: 0.00015 violation_val: 0.00056 time: 0.0584s\n",
      "-------- Epoch 618 --------\n",
      "epoch: 00618 loss_train: 0.00168 loss_val: 0.00190 violation_train: 0.00044 violation_val: 0.00071 time: 0.0639s\n",
      "-------- Epoch 619 --------\n",
      "epoch: 00619 loss_train: 0.00168 loss_val: 0.00190 violation_train: 0.00024 violation_val: 0.00031 time: 0.0648s\n",
      "-------- Epoch 620 --------\n",
      "epoch: 00620 loss_train: 0.00168 loss_val: 0.00191 violation_train: 0.00069 violation_val: 0.00109 time: 0.0650s\n",
      "-------- Epoch 621 --------\n",
      "epoch: 00621 loss_train: 0.00168 loss_val: 0.00189 violation_train: 0.00024 violation_val: 0.00018 time: 0.0627s\n",
      "-------- Epoch 622 --------\n",
      "epoch: 00622 loss_train: 0.00168 loss_val: 0.00188 violation_train: 0.00016 violation_val: 0.00017 time: 0.0600s\n",
      "-------- Epoch 623 --------\n",
      "epoch: 00623 loss_train: 0.00168 loss_val: 0.00185 violation_train: 0.00014 violation_val: 0.00017 time: 0.0588s\n",
      "-------- Epoch 624 --------\n",
      "epoch: 00624 loss_train: 0.00168 loss_val: 0.00189 violation_train: 0.00134 violation_val: 0.00145 time: 0.0586s\n",
      "-------- Epoch 625 --------\n",
      "epoch: 00625 loss_train: 0.00168 loss_val: 0.00192 violation_train: 0.00055 violation_val: 0.00049 time: 0.0618s\n",
      "-------- Epoch 626 --------\n",
      "epoch: 00626 loss_train: 0.00168 loss_val: 0.00189 violation_train: 0.00010 violation_val: 0.00012 time: 0.0607s\n",
      "-------- Epoch 627 --------\n",
      "epoch: 00627 loss_train: 0.00168 loss_val: 0.00185 violation_train: 0.00005 violation_val: 0.00013 time: 0.0580s\n",
      "-------- Epoch 628 --------\n",
      "epoch: 00628 loss_train: 0.00168 loss_val: 0.00190 violation_train: 0.00005 violation_val: 0.00016 time: 0.0574s\n",
      "-------- Epoch 629 --------\n",
      "epoch: 00629 loss_train: 0.00168 loss_val: 0.00192 violation_train: 0.00014 violation_val: 0.00026 time: 0.0582s\n",
      "-------- Epoch 630 --------\n",
      "epoch: 00630 loss_train: 0.00168 loss_val: 0.00187 violation_train: 0.00005 violation_val: 0.00012 time: 0.0579s\n",
      "-------- Epoch 631 --------\n",
      "epoch: 00631 loss_train: 0.00168 loss_val: 0.00190 violation_train: 0.00005 violation_val: 0.00011 time: 0.0572s\n",
      "-------- Epoch 632 --------\n",
      "epoch: 00632 loss_train: 0.00168 loss_val: 0.00191 violation_train: 0.00008 violation_val: 0.00018 time: 0.0573s\n",
      "-------- Epoch 633 --------\n",
      "epoch: 00633 loss_train: 0.00168 loss_val: 0.00192 violation_train: 0.00006 violation_val: 0.00019 time: 0.0582s\n",
      "-------- Epoch 634 --------\n",
      "epoch: 00634 loss_train: 0.00168 loss_val: 0.00190 violation_train: 0.00013 violation_val: 0.00030 time: 0.0577s\n",
      "-------- Epoch 635 --------\n",
      "epoch: 00635 loss_train: 0.00168 loss_val: 0.00191 violation_train: 0.00045 violation_val: 0.00086 time: 0.0573s\n",
      "-------- Epoch 636 --------\n",
      "epoch: 00636 loss_train: 0.00168 loss_val: 0.00195 violation_train: 0.00049 violation_val: 0.00072 time: 0.0572s\n",
      "-------- Epoch 637 --------\n",
      "epoch: 00637 loss_train: 0.00168 loss_val: 0.00193 violation_train: 0.00033 violation_val: 0.00013 time: 0.0583s\n",
      "-------- Epoch 638 --------\n",
      "epoch: 00638 loss_train: 0.00168 loss_val: 0.00188 violation_train: 0.00013 violation_val: 0.00063 time: 0.0574s\n",
      "-------- Epoch 639 --------\n",
      "epoch: 00639 loss_train: 0.00168 loss_val: 0.00186 violation_train: 0.00041 violation_val: 0.00021 time: 0.0572s\n",
      "-------- Epoch 640 --------\n",
      "epoch: 00640 loss_train: 0.00168 loss_val: 0.00186 violation_train: 0.00074 violation_val: 0.00107 time: 0.0572s\n",
      "-------- Epoch 641 --------\n",
      "epoch: 00641 loss_train: 0.00168 loss_val: 0.00186 violation_train: 0.00054 violation_val: 0.00060 time: 0.0581s\n",
      "-------- Epoch 642 --------\n",
      "epoch: 00642 loss_train: 0.00168 loss_val: 0.00187 violation_train: 0.00039 violation_val: 0.00036 time: 0.0575s\n",
      "-------- Epoch 643 --------\n",
      "epoch: 00643 loss_train: 0.00168 loss_val: 0.00192 violation_train: 0.00025 violation_val: 0.00053 time: 0.0574s\n",
      "-------- Epoch 644 --------\n",
      "epoch: 00644 loss_train: 0.00168 loss_val: 0.00195 violation_train: 0.00052 violation_val: 0.00087 time: 0.0571s\n",
      "-------- Epoch 645 --------\n",
      "epoch: 00645 loss_train: 0.00168 loss_val: 0.00189 violation_train: 0.00060 violation_val: 0.00033 time: 0.0581s\n",
      "-------- Epoch 646 --------\n",
      "epoch: 00646 loss_train: 0.00168 loss_val: 0.00187 violation_train: 0.00021 violation_val: 0.00017 time: 0.0574s\n",
      "-------- Epoch 647 --------\n",
      "epoch: 00647 loss_train: 0.00168 loss_val: 0.00191 violation_train: 0.00039 violation_val: 0.00080 time: 0.0572s\n",
      "-------- Epoch 648 --------\n",
      "epoch: 00648 loss_train: 0.00168 loss_val: 0.00188 violation_train: 0.00065 violation_val: 0.00167 time: 0.0573s\n",
      "-------- Epoch 649 --------\n",
      "epoch: 00649 loss_train: 0.00168 loss_val: 0.00188 violation_train: 0.00122 violation_val: 0.00042 time: 0.0580s\n",
      "-------- Epoch 650 --------\n",
      "epoch: 00650 loss_train: 0.00167 loss_val: 0.00193 violation_train: 0.00008 violation_val: 0.00020 time: 0.0574s\n",
      "-------- Epoch 651 --------\n",
      "epoch: 00651 loss_train: 0.00167 loss_val: 0.00188 violation_train: 0.00009 violation_val: 0.00011 time: 0.0572s\n",
      "-------- Epoch 652 --------\n",
      "epoch: 00652 loss_train: 0.00167 loss_val: 0.00187 violation_train: 0.00005 violation_val: 0.00018 time: 0.0573s\n",
      "-------- Epoch 653 --------\n",
      "epoch: 00653 loss_train: 0.00167 loss_val: 0.00187 violation_train: 0.00016 violation_val: 0.00016 time: 0.0577s\n",
      "-------- Epoch 654 --------\n",
      "epoch: 00654 loss_train: 0.00167 loss_val: 0.00186 violation_train: 0.00018 violation_val: 0.00023 time: 0.0576s\n",
      "-------- Epoch 655 --------\n",
      "epoch: 00655 loss_train: 0.00167 loss_val: 0.00188 violation_train: 0.00016 violation_val: 0.00023 time: 0.0572s\n",
      "-------- Epoch 656 --------\n",
      "epoch: 00656 loss_train: 0.00167 loss_val: 0.00191 violation_train: 0.00014 violation_val: 0.00049 time: 0.0569s\n",
      "-------- Epoch 657 --------\n",
      "epoch: 00657 loss_train: 0.00167 loss_val: 0.00190 violation_train: 0.00069 violation_val: 0.00086 time: 0.0582s\n",
      "-------- Epoch 658 --------\n",
      "epoch: 00658 loss_train: 0.00167 loss_val: 0.00195 violation_train: 0.00071 violation_val: 0.00107 time: 0.0582s\n",
      "-------- Epoch 659 --------\n",
      "epoch: 00659 loss_train: 0.00167 loss_val: 0.00191 violation_train: 0.00033 violation_val: 0.00013 time: 0.0588s\n",
      "-------- Epoch 660 --------\n",
      "epoch: 00660 loss_train: 0.00167 loss_val: 0.00186 violation_train: 0.00016 violation_val: 0.00013 time: 0.0573s\n",
      "-------- Epoch 661 --------\n",
      "epoch: 00661 loss_train: 0.00167 loss_val: 0.00186 violation_train: 0.00009 violation_val: 0.00016 time: 0.0586s\n",
      "-------- Epoch 662 --------\n",
      "epoch: 00662 loss_train: 0.00167 loss_val: 0.00188 violation_train: 0.00012 violation_val: 0.00033 time: 0.0576s\n",
      "-------- Epoch 663 --------\n",
      "epoch: 00663 loss_train: 0.00167 loss_val: 0.00187 violation_train: 0.00013 violation_val: 0.00028 time: 0.0572s\n",
      "-------- Epoch 664 --------\n",
      "epoch: 00664 loss_train: 0.00167 loss_val: 0.00192 violation_train: 0.00076 violation_val: 0.00092 time: 0.0572s\n",
      "-------- Epoch 665 --------\n",
      "epoch: 00665 loss_train: 0.00167 loss_val: 0.00184 violation_train: 0.00086 violation_val: 0.00050 time: 0.0586s\n",
      "-------- Epoch 666 --------\n",
      "epoch: 00666 loss_train: 0.00167 loss_val: 0.00187 violation_train: 0.00039 violation_val: 0.00135 time: 0.0574s\n",
      "-------- Epoch 667 --------\n",
      "epoch: 00667 loss_train: 0.00167 loss_val: 0.00185 violation_train: 0.00017 violation_val: 0.00021 time: 0.0577s\n",
      "-------- Epoch 668 --------\n",
      "epoch: 00668 loss_train: 0.00167 loss_val: 0.00196 violation_train: 0.00010 violation_val: 0.00016 time: 0.0579s\n",
      "-------- Epoch 669 --------\n",
      "epoch: 00669 loss_train: 0.00167 loss_val: 0.00189 violation_train: 0.00042 violation_val: 0.00101 time: 0.0596s\n",
      "-------- Epoch 670 --------\n",
      "epoch: 00670 loss_train: 0.00167 loss_val: 0.00198 violation_train: 0.00052 violation_val: 0.00022 time: 0.0581s\n",
      "-------- Epoch 671 --------\n",
      "epoch: 00671 loss_train: 0.00167 loss_val: 0.00192 violation_train: 0.00009 violation_val: 0.00017 time: 0.0571s\n",
      "-------- Epoch 672 --------\n",
      "epoch: 00672 loss_train: 0.00167 loss_val: 0.00188 violation_train: 0.00006 violation_val: 0.00012 time: 0.0571s\n",
      "-------- Epoch 673 --------\n",
      "epoch: 00673 loss_train: 0.00167 loss_val: 0.00195 violation_train: 0.00025 violation_val: 0.00037 time: 0.0583s\n",
      "-------- Epoch 674 --------\n",
      "epoch: 00674 loss_train: 0.00167 loss_val: 0.00186 violation_train: 0.00134 violation_val: 0.00021 time: 0.0574s\n",
      "-------- Epoch 675 --------\n",
      "epoch: 00675 loss_train: 0.00167 loss_val: 0.00187 violation_train: 0.00010 violation_val: 0.00023 time: 0.0600s\n",
      "-------- Epoch 676 --------\n",
      "epoch: 00676 loss_train: 0.00167 loss_val: 0.00192 violation_train: 0.00008 violation_val: 0.00014 time: 0.0593s\n",
      "-------- Epoch 677 --------\n",
      "epoch: 00677 loss_train: 0.00167 loss_val: 0.00189 violation_train: 0.00012 violation_val: 0.00013 time: 0.0599s\n",
      "-------- Epoch 678 --------\n",
      "epoch: 00678 loss_train: 0.00167 loss_val: 0.00184 violation_train: 0.00007 violation_val: 0.00023 time: 0.0608s\n",
      "-------- Epoch 679 --------\n",
      "epoch: 00679 loss_train: 0.00167 loss_val: 0.00184 violation_train: 0.00052 violation_val: 0.00207 time: 0.0609s\n",
      "-------- Epoch 680 --------\n",
      "epoch: 00680 loss_train: 0.00167 loss_val: 0.00188 violation_train: 0.00077 violation_val: 0.00065 time: 0.0604s\n",
      "-------- Epoch 681 --------\n",
      "epoch: 00681 loss_train: 0.00167 loss_val: 0.00188 violation_train: 0.00027 violation_val: 0.00014 time: 0.0615s\n",
      "-------- Epoch 682 --------\n",
      "epoch: 00682 loss_train: 0.00167 loss_val: 0.00189 violation_train: 0.00019 violation_val: 0.00018 time: 0.0593s\n",
      "-------- Epoch 683 --------\n",
      "epoch: 00683 loss_train: 0.00167 loss_val: 0.00187 violation_train: 0.00023 violation_val: 0.00018 time: 0.0578s\n",
      "-------- Epoch 684 --------\n",
      "epoch: 00684 loss_train: 0.00166 loss_val: 0.00188 violation_train: 0.00007 violation_val: 0.00028 time: 0.0578s\n",
      "-------- Epoch 685 --------\n",
      "epoch: 00685 loss_train: 0.00166 loss_val: 0.00193 violation_train: 0.00046 violation_val: 0.00055 time: 0.0589s\n",
      "-------- Epoch 686 --------\n",
      "epoch: 00686 loss_train: 0.00166 loss_val: 0.00196 violation_train: 0.00090 violation_val: 0.00044 time: 0.0660s\n",
      "-------- Epoch 687 --------\n",
      "epoch: 00687 loss_train: 0.00166 loss_val: 0.00193 violation_train: 0.00040 violation_val: 0.00033 time: 0.0664s\n",
      "-------- Epoch 688 --------\n",
      "epoch: 00688 loss_train: 0.00166 loss_val: 0.00190 violation_train: 0.00057 violation_val: 0.00026 time: 0.0636s\n",
      "-------- Epoch 689 --------\n",
      "epoch: 00689 loss_train: 0.00166 loss_val: 0.00190 violation_train: 0.00050 violation_val: 0.00064 time: 0.0609s\n",
      "-------- Epoch 690 --------\n",
      "epoch: 00690 loss_train: 0.00166 loss_val: 0.00185 violation_train: 0.00030 violation_val: 0.00068 time: 0.0605s\n",
      "-------- Epoch 691 --------\n",
      "epoch: 00691 loss_train: 0.00166 loss_val: 0.00188 violation_train: 0.00028 violation_val: 0.00012 time: 0.0590s\n",
      "-------- Epoch 692 --------\n",
      "epoch: 00692 loss_train: 0.00166 loss_val: 0.00187 violation_train: 0.00040 violation_val: 0.00039 time: 0.0592s\n",
      "-------- Epoch 693 --------\n",
      "epoch: 00693 loss_train: 0.00166 loss_val: 0.00188 violation_train: 0.00037 violation_val: 0.00037 time: 0.0624s\n",
      "-------- Epoch 694 --------\n",
      "epoch: 00694 loss_train: 0.00166 loss_val: 0.00189 violation_train: 0.00022 violation_val: 0.00036 time: 0.0605s\n",
      "-------- Epoch 695 --------\n",
      "epoch: 00695 loss_train: 0.00166 loss_val: 0.00188 violation_train: 0.00041 violation_val: 0.00064 time: 0.0597s\n",
      "-------- Epoch 696 --------\n",
      "epoch: 00696 loss_train: 0.00166 loss_val: 0.00188 violation_train: 0.00120 violation_val: 0.00249 time: 0.0600s\n",
      "-------- Epoch 697 --------\n",
      "epoch: 00697 loss_train: 0.00166 loss_val: 0.00186 violation_train: 0.00160 violation_val: 0.00033 time: 0.0589s\n",
      "-------- Epoch 698 --------\n",
      "epoch: 00698 loss_train: 0.00166 loss_val: 0.00191 violation_train: 0.00026 violation_val: 0.00015 time: 0.0587s\n",
      "-------- Epoch 699 --------\n",
      "epoch: 00699 loss_train: 0.00166 loss_val: 0.00184 violation_train: 0.00004 violation_val: 0.00014 time: 0.0581s\n",
      "-------- Epoch 700 --------\n",
      "epoch: 00700 loss_train: 0.00166 loss_val: 0.00188 violation_train: 0.00004 violation_val: 0.00013 time: 0.0579s\n",
      "-------- Epoch 701 --------\n",
      "epoch: 00701 loss_train: 0.00166 loss_val: 0.00184 violation_train: 0.00004 violation_val: 0.00012 time: 0.0592s\n",
      "-------- Epoch 702 --------\n",
      "epoch: 00702 loss_train: 0.00166 loss_val: 0.00189 violation_train: 0.00009 violation_val: 0.00011 time: 0.0595s\n",
      "-------- Epoch 703 --------\n",
      "epoch: 00703 loss_train: 0.00166 loss_val: 0.00192 violation_train: 0.00005 violation_val: 0.00013 time: 0.0603s\n",
      "-------- Epoch 704 --------\n",
      "epoch: 00704 loss_train: 0.00166 loss_val: 0.00190 violation_train: 0.00006 violation_val: 0.00016 time: 0.0592s\n",
      "-------- Epoch 705 --------\n",
      "epoch: 00705 loss_train: 0.00166 loss_val: 0.00187 violation_train: 0.00006 violation_val: 0.00013 time: 0.0586s\n",
      "-------- Epoch 706 --------\n",
      "epoch: 00706 loss_train: 0.00166 loss_val: 0.00189 violation_train: 0.00005 violation_val: 0.00013 time: 0.0584s\n",
      "-------- Epoch 707 --------\n",
      "epoch: 00707 loss_train: 0.00166 loss_val: 0.00189 violation_train: 0.00005 violation_val: 0.00016 time: 0.0584s\n",
      "-------- Epoch 708 --------\n",
      "epoch: 00708 loss_train: 0.00166 loss_val: 0.00184 violation_train: 0.00026 violation_val: 0.00029 time: 0.0574s\n",
      "-------- Epoch 709 --------\n",
      "epoch: 00709 loss_train: 0.00166 loss_val: 0.00186 violation_train: 0.00020 violation_val: 0.00025 time: 0.0578s\n",
      "-------- Epoch 710 --------\n",
      "epoch: 00710 loss_train: 0.00166 loss_val: 0.00188 violation_train: 0.00046 violation_val: 0.00091 time: 0.0580s\n",
      "-------- Epoch 711 --------\n",
      "epoch: 00711 loss_train: 0.00166 loss_val: 0.00184 violation_train: 0.00078 violation_val: 0.00057 time: 0.0587s\n",
      "-------- Epoch 712 --------\n",
      "epoch: 00712 loss_train: 0.00166 loss_val: 0.00186 violation_train: 0.00110 violation_val: 0.00027 time: 0.0628s\n",
      "-------- Epoch 713 --------\n",
      "epoch: 00713 loss_train: 0.00166 loss_val: 0.00188 violation_train: 0.00015 violation_val: 0.00013 time: 0.0623s\n",
      "-------- Epoch 714 --------\n",
      "epoch: 00714 loss_train: 0.00166 loss_val: 0.00184 violation_train: 0.00004 violation_val: 0.00014 time: 0.0617s\n",
      "-------- Epoch 715 --------\n",
      "epoch: 00715 loss_train: 0.00166 loss_val: 0.00195 violation_train: 0.00004 violation_val: 0.00012 time: 0.0609s\n",
      "-------- Epoch 716 --------\n",
      "epoch: 00716 loss_train: 0.00166 loss_val: 0.00191 violation_train: 0.00005 violation_val: 0.00013 time: 0.0604s\n",
      "-------- Epoch 717 --------\n",
      "epoch: 00717 loss_train: 0.00166 loss_val: 0.00189 violation_train: 0.00015 violation_val: 0.00018 time: 0.0614s\n",
      "-------- Epoch 718 --------\n",
      "epoch: 00718 loss_train: 0.00166 loss_val: 0.00189 violation_train: 0.00013 violation_val: 0.00036 time: 0.0605s\n",
      "-------- Epoch 719 --------\n",
      "epoch: 00719 loss_train: 0.00166 loss_val: 0.00192 violation_train: 0.00028 violation_val: 0.00054 time: 0.0608s\n",
      "-------- Epoch 720 --------\n",
      "epoch: 00720 loss_train: 0.00165 loss_val: 0.00193 violation_train: 0.00085 violation_val: 0.00032 time: 0.0606s\n",
      "-------- Epoch 721 --------\n",
      "epoch: 00721 loss_train: 0.00166 loss_val: 0.00184 violation_train: 0.00101 violation_val: 0.00039 time: 0.0620s\n",
      "-------- Epoch 722 --------\n",
      "epoch: 00722 loss_train: 0.00166 loss_val: 0.00186 violation_train: 0.00023 violation_val: 0.00012 time: 0.0586s\n",
      "-------- Epoch 723 --------\n",
      "epoch: 00723 loss_train: 0.00165 loss_val: 0.00187 violation_train: 0.00007 violation_val: 0.00011 time: 0.0580s\n",
      "-------- Epoch 724 --------\n",
      "epoch: 00724 loss_train: 0.00165 loss_val: 0.00186 violation_train: 0.00006 violation_val: 0.00016 time: 0.0579s\n",
      "-------- Epoch 725 --------\n",
      "epoch: 00725 loss_train: 0.00165 loss_val: 0.00193 violation_train: 0.00009 violation_val: 0.00022 time: 0.0586s\n",
      "-------- Epoch 726 --------\n",
      "epoch: 00726 loss_train: 0.00165 loss_val: 0.00186 violation_train: 0.00009 violation_val: 0.00012 time: 0.0577s\n",
      "-------- Epoch 727 --------\n",
      "epoch: 00727 loss_train: 0.00165 loss_val: 0.00183 violation_train: 0.00009 violation_val: 0.00046 time: 0.0584s\n",
      "-------- Epoch 728 --------\n",
      "epoch: 00728 loss_train: 0.00165 loss_val: 0.00187 violation_train: 0.00033 violation_val: 0.00017 time: 0.0576s\n",
      "-------- Epoch 729 --------\n",
      "epoch: 00729 loss_train: 0.00165 loss_val: 0.00183 violation_train: 0.00060 violation_val: 0.00032 time: 0.0584s\n",
      "-------- Epoch 730 --------\n",
      "epoch: 00730 loss_train: 0.00165 loss_val: 0.00190 violation_train: 0.00119 violation_val: 0.00239 time: 0.0601s\n",
      "-------- Epoch 731 --------\n",
      "epoch: 00731 loss_train: 0.00165 loss_val: 0.00185 violation_train: 0.00050 violation_val: 0.00018 time: 0.0595s\n",
      "-------- Epoch 732 --------\n",
      "epoch: 00732 loss_train: 0.00165 loss_val: 0.00186 violation_train: 0.00011 violation_val: 0.00013 time: 0.0577s\n",
      "-------- Epoch 733 --------\n",
      "epoch: 00733 loss_train: 0.00165 loss_val: 0.00187 violation_train: 0.00004 violation_val: 0.00014 time: 0.0587s\n",
      "-------- Epoch 734 --------\n",
      "epoch: 00734 loss_train: 0.00165 loss_val: 0.00192 violation_train: 0.00006 violation_val: 0.00017 time: 0.0576s\n",
      "-------- Epoch 735 --------\n",
      "epoch: 00735 loss_train: 0.00165 loss_val: 0.00182 violation_train: 0.00004 violation_val: 0.00024 time: 0.0575s\n",
      "-------- Epoch 736 --------\n",
      "epoch: 00736 loss_train: 0.00165 loss_val: 0.00190 violation_train: 0.00011 violation_val: 0.00013 time: 0.0573s\n",
      "-------- Epoch 737 --------\n",
      "epoch: 00737 loss_train: 0.00165 loss_val: 0.00190 violation_train: 0.00009 violation_val: 0.00025 time: 0.0601s\n",
      "-------- Epoch 738 --------\n",
      "epoch: 00738 loss_train: 0.00165 loss_val: 0.00186 violation_train: 0.00019 violation_val: 0.00038 time: 0.0609s\n",
      "-------- Epoch 739 --------\n",
      "epoch: 00739 loss_train: 0.00165 loss_val: 0.00190 violation_train: 0.00026 violation_val: 0.00044 time: 0.0589s\n",
      "-------- Epoch 740 --------\n",
      "epoch: 00740 loss_train: 0.00165 loss_val: 0.00188 violation_train: 0.00108 violation_val: 0.00098 time: 0.0587s\n",
      "-------- Epoch 741 --------\n",
      "epoch: 00741 loss_train: 0.00165 loss_val: 0.00189 violation_train: 0.00023 violation_val: 0.00015 time: 0.0584s\n",
      "-------- Epoch 742 --------\n",
      "epoch: 00742 loss_train: 0.00165 loss_val: 0.00188 violation_train: 0.00006 violation_val: 0.00010 time: 0.0576s\n",
      "-------- Epoch 743 --------\n",
      "epoch: 00743 loss_train: 0.00165 loss_val: 0.00196 violation_train: 0.00008 violation_val: 0.00023 time: 0.0570s\n",
      "-------- Epoch 744 --------\n",
      "epoch: 00744 loss_train: 0.00165 loss_val: 0.00184 violation_train: 0.00015 violation_val: 0.00047 time: 0.0571s\n",
      "-------- Epoch 745 --------\n",
      "epoch: 00745 loss_train: 0.00165 loss_val: 0.00194 violation_train: 0.00038 violation_val: 0.00018 time: 0.0582s\n",
      "-------- Epoch 746 --------\n",
      "epoch: 00746 loss_train: 0.00165 loss_val: 0.00182 violation_train: 0.00025 violation_val: 0.00017 time: 0.0579s\n",
      "-------- Epoch 747 --------\n",
      "epoch: 00747 loss_train: 0.00165 loss_val: 0.00186 violation_train: 0.00069 violation_val: 0.00050 time: 0.0573s\n",
      "-------- Epoch 748 --------\n",
      "epoch: 00748 loss_train: 0.00165 loss_val: 0.00182 violation_train: 0.00051 violation_val: 0.00038 time: 0.0574s\n",
      "-------- Epoch 749 --------\n",
      "epoch: 00749 loss_train: 0.00165 loss_val: 0.00189 violation_train: 0.00022 violation_val: 0.00033 time: 0.0579s\n",
      "-------- Epoch 750 --------\n",
      "epoch: 00750 loss_train: 0.00165 loss_val: 0.00192 violation_train: 0.00041 violation_val: 0.00015 time: 0.0588s\n",
      "-------- Epoch 751 --------\n",
      "epoch: 00751 loss_train: 0.00165 loss_val: 0.00184 violation_train: 0.00013 violation_val: 0.00050 time: 0.0605s\n",
      "-------- Epoch 752 --------\n",
      "epoch: 00752 loss_train: 0.00165 loss_val: 0.00187 violation_train: 0.00079 violation_val: 0.00025 time: 0.0578s\n",
      "-------- Epoch 753 --------\n",
      "epoch: 00753 loss_train: 0.00165 loss_val: 0.00183 violation_train: 0.00064 violation_val: 0.00015 time: 0.0600s\n",
      "-------- Epoch 754 --------\n",
      "epoch: 00754 loss_train: 0.00165 loss_val: 0.00183 violation_train: 0.00011 violation_val: 0.00014 time: 0.0594s\n",
      "-------- Epoch 755 --------\n",
      "epoch: 00755 loss_train: 0.00165 loss_val: 0.00187 violation_train: 0.00005 violation_val: 0.00010 time: 0.0595s\n",
      "-------- Epoch 756 --------\n",
      "epoch: 00756 loss_train: 0.00165 loss_val: 0.00188 violation_train: 0.00016 violation_val: 0.00021 time: 0.0600s\n",
      "-------- Epoch 757 --------\n",
      "epoch: 00757 loss_train: 0.00164 loss_val: 0.00185 violation_train: 0.00026 violation_val: 0.00016 time: 0.0602s\n",
      "-------- Epoch 758 --------\n",
      "epoch: 00758 loss_train: 0.00165 loss_val: 0.00186 violation_train: 0.00009 violation_val: 0.00030 time: 0.0607s\n",
      "-------- Epoch 759 --------\n",
      "epoch: 00759 loss_train: 0.00164 loss_val: 0.00186 violation_train: 0.00011 violation_val: 0.00031 time: 0.0594s\n",
      "-------- Epoch 760 --------\n",
      "epoch: 00760 loss_train: 0.00164 loss_val: 0.00188 violation_train: 0.00031 violation_val: 0.00084 time: 0.0583s\n",
      "-------- Epoch 761 --------\n",
      "epoch: 00761 loss_train: 0.00165 loss_val: 0.00188 violation_train: 0.00077 violation_val: 0.00109 time: 0.0585s\n",
      "-------- Epoch 762 --------\n",
      "epoch: 00762 loss_train: 0.00165 loss_val: 0.00186 violation_train: 0.00101 violation_val: 0.00360 time: 0.0575s\n",
      "-------- Epoch 763 --------\n",
      "epoch: 00763 loss_train: 0.00164 loss_val: 0.00185 violation_train: 0.00043 violation_val: 0.00021 time: 0.0573s\n",
      "-------- Epoch 764 --------\n",
      "epoch: 00764 loss_train: 0.00164 loss_val: 0.00187 violation_train: 0.00010 violation_val: 0.00013 time: 0.0587s\n",
      "-------- Epoch 765 --------\n",
      "epoch: 00765 loss_train: 0.00164 loss_val: 0.00182 violation_train: 0.00008 violation_val: 0.00011 time: 0.0655s\n",
      "-------- Epoch 766 --------\n",
      "epoch: 00766 loss_train: 0.00164 loss_val: 0.00193 violation_train: 0.00017 violation_val: 0.00020 time: 0.0668s\n",
      "-------- Epoch 767 --------\n",
      "epoch: 00767 loss_train: 0.00164 loss_val: 0.00186 violation_train: 0.00010 violation_val: 0.00025 time: 0.0615s\n",
      "-------- Epoch 768 --------\n",
      "epoch: 00768 loss_train: 0.00164 loss_val: 0.00185 violation_train: 0.00019 violation_val: 0.00057 time: 0.0595s\n",
      "-------- Epoch 769 --------\n",
      "epoch: 00769 loss_train: 0.00164 loss_val: 0.00187 violation_train: 0.00015 violation_val: 0.00041 time: 0.0594s\n",
      "-------- Epoch 770 --------\n",
      "epoch: 00770 loss_train: 0.00164 loss_val: 0.00186 violation_train: 0.00050 violation_val: 0.00041 time: 0.0598s\n",
      "-------- Epoch 771 --------\n",
      "epoch: 00771 loss_train: 0.00164 loss_val: 0.00191 violation_train: 0.00032 violation_val: 0.00037 time: 0.0609s\n",
      "-------- Epoch 772 --------\n",
      "epoch: 00772 loss_train: 0.00164 loss_val: 0.00183 violation_train: 0.00061 violation_val: 0.00023 time: 0.0593s\n",
      "-------- Epoch 773 --------\n",
      "epoch: 00773 loss_train: 0.00164 loss_val: 0.00183 violation_train: 0.00020 violation_val: 0.00024 time: 0.0597s\n",
      "-------- Epoch 774 --------\n",
      "epoch: 00774 loss_train: 0.00164 loss_val: 0.00183 violation_train: 0.00140 violation_val: 0.00096 time: 0.0583s\n",
      "-------- Epoch 775 --------\n",
      "epoch: 00775 loss_train: 0.00164 loss_val: 0.00183 violation_train: 0.00055 violation_val: 0.00039 time: 0.0580s\n",
      "-------- Epoch 776 --------\n",
      "epoch: 00776 loss_train: 0.00164 loss_val: 0.00188 violation_train: 0.00013 violation_val: 0.00013 time: 0.0581s\n",
      "-------- Epoch 777 --------\n",
      "epoch: 00777 loss_train: 0.00164 loss_val: 0.00188 violation_train: 0.00006 violation_val: 0.00021 time: 0.0588s\n",
      "-------- Epoch 778 --------\n",
      "epoch: 00778 loss_train: 0.00164 loss_val: 0.00187 violation_train: 0.00008 violation_val: 0.00015 time: 0.0585s\n",
      "-------- Epoch 779 --------\n",
      "epoch: 00779 loss_train: 0.00164 loss_val: 0.00183 violation_train: 0.00007 violation_val: 0.00022 time: 0.0587s\n",
      "-------- Epoch 780 --------\n",
      "epoch: 00780 loss_train: 0.00164 loss_val: 0.00186 violation_train: 0.00012 violation_val: 0.00023 time: 0.0577s\n",
      "-------- Epoch 781 --------\n",
      "epoch: 00781 loss_train: 0.00164 loss_val: 0.00186 violation_train: 0.00019 violation_val: 0.00019 time: 0.0625s\n",
      "-------- Epoch 782 --------\n",
      "epoch: 00782 loss_train: 0.00164 loss_val: 0.00183 violation_train: 0.00010 violation_val: 0.00020 time: 0.0600s\n",
      "-------- Epoch 783 --------\n",
      "epoch: 00783 loss_train: 0.00164 loss_val: 0.00185 violation_train: 0.00070 violation_val: 0.00290 time: 0.0587s\n",
      "-------- Epoch 784 --------\n",
      "epoch: 00784 loss_train: 0.00164 loss_val: 0.00185 violation_train: 0.00036 violation_val: 0.00014 time: 0.0578s\n",
      "-------- Epoch 785 --------\n",
      "epoch: 00785 loss_train: 0.00164 loss_val: 0.00184 violation_train: 0.00003 violation_val: 0.00019 time: 0.0584s\n",
      "-------- Epoch 786 --------\n",
      "epoch: 00786 loss_train: 0.00164 loss_val: 0.00187 violation_train: 0.00006 violation_val: 0.00023 time: 0.0604s\n",
      "-------- Epoch 787 --------\n",
      "epoch: 00787 loss_train: 0.00164 loss_val: 0.00183 violation_train: 0.00016 violation_val: 0.00018 time: 0.0575s\n",
      "-------- Epoch 788 --------\n",
      "epoch: 00788 loss_train: 0.00164 loss_val: 0.00190 violation_train: 0.00020 violation_val: 0.00033 time: 0.0612s\n",
      "-------- Epoch 789 --------\n",
      "epoch: 00789 loss_train: 0.00164 loss_val: 0.00183 violation_train: 0.00044 violation_val: 0.00056 time: 0.0659s\n",
      "-------- Epoch 790 --------\n",
      "epoch: 00790 loss_train: 0.00164 loss_val: 0.00184 violation_train: 0.00067 violation_val: 0.00030 time: 0.0667s\n",
      "-------- Epoch 791 --------\n",
      "epoch: 00791 loss_train: 0.00164 loss_val: 0.00192 violation_train: 0.00009 violation_val: 0.00024 time: 0.0662s\n",
      "-------- Epoch 792 --------\n",
      "epoch: 00792 loss_train: 0.00164 loss_val: 0.00186 violation_train: 0.00013 violation_val: 0.00022 time: 0.0653s\n",
      "-------- Epoch 793 --------\n",
      "epoch: 00793 loss_train: 0.00164 loss_val: 0.00186 violation_train: 0.00050 violation_val: 0.00032 time: 0.0649s\n",
      "-------- Epoch 794 --------\n",
      "epoch: 00794 loss_train: 0.00164 loss_val: 0.00184 violation_train: 0.00023 violation_val: 0.00015 time: 0.0636s\n",
      "-------- Epoch 795 --------\n",
      "epoch: 00795 loss_train: 0.00164 loss_val: 0.00189 violation_train: 0.00069 violation_val: 0.00073 time: 0.0634s\n",
      "-------- Epoch 796 --------\n",
      "epoch: 00796 loss_train: 0.00164 loss_val: 0.00183 violation_train: 0.00063 violation_val: 0.00071 time: 0.0645s\n",
      "-------- Epoch 797 --------\n",
      "epoch: 00797 loss_train: 0.00164 loss_val: 0.00184 violation_train: 0.00037 violation_val: 0.00045 time: 0.0674s\n",
      "-------- Epoch 798 --------\n",
      "epoch: 00798 loss_train: 0.00163 loss_val: 0.00196 violation_train: 0.00055 violation_val: 0.00090 time: 0.0690s\n",
      "-------- Epoch 799 --------\n",
      "epoch: 00799 loss_train: 0.00163 loss_val: 0.00181 violation_train: 0.00042 violation_val: 0.00025 time: 0.0667s\n",
      "-------- Epoch 800 --------\n",
      "epoch: 00800 loss_train: 0.00163 loss_val: 0.00184 violation_train: 0.00011 violation_val: 0.00035 time: 0.0610s\n",
      "-------- Epoch 801 --------\n",
      "epoch: 00801 loss_train: 0.00164 loss_val: 0.00192 violation_train: 0.00034 violation_val: 0.00023 time: 0.0642s\n",
      "-------- Epoch 802 --------\n",
      "epoch: 00802 loss_train: 0.00163 loss_val: 0.00196 violation_train: 0.00019 violation_val: 0.00026 time: 0.0644s\n",
      "-------- Epoch 803 --------\n",
      "epoch: 00803 loss_train: 0.00163 loss_val: 0.00183 violation_train: 0.00074 violation_val: 0.00060 time: 0.0647s\n",
      "-------- Epoch 804 --------\n",
      "epoch: 00804 loss_train: 0.00163 loss_val: 0.00187 violation_train: 0.00055 violation_val: 0.00064 time: 0.0609s\n",
      "-------- Epoch 805 --------\n",
      "epoch: 00805 loss_train: 0.00163 loss_val: 0.00182 violation_train: 0.00026 violation_val: 0.00034 time: 0.0613s\n",
      "-------- Epoch 806 --------\n",
      "epoch: 00806 loss_train: 0.00163 loss_val: 0.00183 violation_train: 0.00010 violation_val: 0.00022 time: 0.0601s\n",
      "-------- Epoch 807 --------\n",
      "epoch: 00807 loss_train: 0.00163 loss_val: 0.00185 violation_train: 0.00008 violation_val: 0.00051 time: 0.0612s\n",
      "-------- Epoch 808 --------\n",
      "epoch: 00808 loss_train: 0.00163 loss_val: 0.00183 violation_train: 0.00131 violation_val: 0.00137 time: 0.0622s\n",
      "-------- Epoch 809 --------\n",
      "epoch: 00809 loss_train: 0.00163 loss_val: 0.00190 violation_train: 0.00030 violation_val: 0.00016 time: 0.0622s\n",
      "-------- Epoch 810 --------\n",
      "epoch: 00810 loss_train: 0.00163 loss_val: 0.00184 violation_train: 0.00007 violation_val: 0.00017 time: 0.0595s\n",
      "-------- Epoch 811 --------\n",
      "epoch: 00811 loss_train: 0.00163 loss_val: 0.00183 violation_train: 0.00005 violation_val: 0.00011 time: 0.0575s\n",
      "-------- Epoch 812 --------\n",
      "epoch: 00812 loss_train: 0.00163 loss_val: 0.00190 violation_train: 0.00005 violation_val: 0.00018 time: 0.0605s\n",
      "-------- Epoch 813 --------\n",
      "epoch: 00813 loss_train: 0.00163 loss_val: 0.00187 violation_train: 0.00014 violation_val: 0.00022 time: 0.0637s\n",
      "-------- Epoch 814 --------\n",
      "epoch: 00814 loss_train: 0.00163 loss_val: 0.00186 violation_train: 0.00081 violation_val: 0.00177 time: 0.0629s\n",
      "-------- Epoch 815 --------\n",
      "epoch: 00815 loss_train: 0.00163 loss_val: 0.00188 violation_train: 0.00075 violation_val: 0.00093 time: 0.0617s\n",
      "-------- Epoch 816 --------\n",
      "epoch: 00816 loss_train: 0.00163 loss_val: 0.00187 violation_train: 0.00022 violation_val: 0.00046 time: 0.0602s\n",
      "-------- Epoch 817 --------\n",
      "epoch: 00817 loss_train: 0.00163 loss_val: 0.00185 violation_train: 0.00030 violation_val: 0.00023 time: 0.0612s\n",
      "-------- Epoch 818 --------\n",
      "epoch: 00818 loss_train: 0.00163 loss_val: 0.00183 violation_train: 0.00011 violation_val: 0.00028 time: 0.0618s\n",
      "-------- Epoch 819 --------\n",
      "epoch: 00819 loss_train: 0.00163 loss_val: 0.00184 violation_train: 0.00009 violation_val: 0.00024 time: 0.0617s\n",
      "-------- Epoch 820 --------\n",
      "epoch: 00820 loss_train: 0.00163 loss_val: 0.00189 violation_train: 0.00045 violation_val: 0.00027 time: 0.0592s\n",
      "-------- Epoch 821 --------\n",
      "epoch: 00821 loss_train: 0.00163 loss_val: 0.00186 violation_train: 0.00014 violation_val: 0.00038 time: 0.0588s\n",
      "-------- Epoch 822 --------\n",
      "epoch: 00822 loss_train: 0.00163 loss_val: 0.00181 violation_train: 0.00044 violation_val: 0.00053 time: 0.0585s\n",
      "-------- Epoch 823 --------\n",
      "epoch: 00823 loss_train: 0.00163 loss_val: 0.00192 violation_train: 0.00067 violation_val: 0.00029 time: 0.0716s\n",
      "-------- Epoch 824 --------\n",
      "epoch: 00824 loss_train: 0.00163 loss_val: 0.00193 violation_train: 0.00032 violation_val: 0.00062 time: 0.0677s\n",
      "-------- Epoch 825 --------\n",
      "epoch: 00825 loss_train: 0.00163 loss_val: 0.00180 violation_train: 0.00048 violation_val: 0.00065 time: 0.0676s\n",
      "-------- Epoch 826 --------\n",
      "epoch: 00826 loss_train: 0.00163 loss_val: 0.00184 violation_train: 0.00013 violation_val: 0.00023 time: 0.0655s\n",
      "-------- Epoch 827 --------\n",
      "epoch: 00827 loss_train: 0.00163 loss_val: 0.00184 violation_train: 0.00059 violation_val: 0.00146 time: 0.0653s\n",
      "-------- Epoch 828 --------\n",
      "epoch: 00828 loss_train: 0.00163 loss_val: 0.00184 violation_train: 0.00085 violation_val: 0.00017 time: 0.0696s\n",
      "-------- Epoch 829 --------\n",
      "epoch: 00829 loss_train: 0.00163 loss_val: 0.00185 violation_train: 0.00038 violation_val: 0.00022 time: 0.0714s\n",
      "-------- Epoch 830 --------\n",
      "epoch: 00830 loss_train: 0.00163 loss_val: 0.00184 violation_train: 0.00010 violation_val: 0.00015 time: 0.0680s\n",
      "-------- Epoch 831 --------\n",
      "epoch: 00831 loss_train: 0.00163 loss_val: 0.00186 violation_train: 0.00010 violation_val: 0.00019 time: 0.0667s\n",
      "-------- Epoch 832 --------\n",
      "epoch: 00832 loss_train: 0.00163 loss_val: 0.00184 violation_train: 0.00017 violation_val: 0.00024 time: 0.0655s\n",
      "-------- Epoch 833 --------\n",
      "epoch: 00833 loss_train: 0.00163 loss_val: 0.00183 violation_train: 0.00047 violation_val: 0.00107 time: 0.0671s\n",
      "-------- Epoch 834 --------\n",
      "epoch: 00834 loss_train: 0.00162 loss_val: 0.00187 violation_train: 0.00076 violation_val: 0.00086 time: 0.0667s\n",
      "-------- Epoch 835 --------\n",
      "epoch: 00835 loss_train: 0.00162 loss_val: 0.00181 violation_train: 0.00106 violation_val: 0.00049 time: 0.0655s\n",
      "-------- Epoch 836 --------\n",
      "epoch: 00836 loss_train: 0.00162 loss_val: 0.00197 violation_train: 0.00058 violation_val: 0.00097 time: 0.0618s\n",
      "-------- Epoch 837 --------\n",
      "epoch: 00837 loss_train: 0.00162 loss_val: 0.00181 violation_train: 0.00017 violation_val: 0.00012 time: 0.0620s\n",
      "-------- Epoch 838 --------\n",
      "epoch: 00838 loss_train: 0.00162 loss_val: 0.00180 violation_train: 0.00006 violation_val: 0.00013 time: 0.0641s\n",
      "-------- Epoch 839 --------\n",
      "epoch: 00839 loss_train: 0.00162 loss_val: 0.00187 violation_train: 0.00007 violation_val: 0.00016 time: 0.0643s\n",
      "-------- Epoch 840 --------\n",
      "epoch: 00840 loss_train: 0.00162 loss_val: 0.00187 violation_train: 0.00027 violation_val: 0.00042 time: 0.0598s\n",
      "-------- Epoch 841 --------\n",
      "epoch: 00841 loss_train: 0.00162 loss_val: 0.00192 violation_train: 0.00039 violation_val: 0.00025 time: 0.0620s\n",
      "-------- Epoch 842 --------\n",
      "epoch: 00842 loss_train: 0.00162 loss_val: 0.00184 violation_train: 0.00039 violation_val: 0.00105 time: 0.0601s\n",
      "-------- Epoch 843 --------\n",
      "epoch: 00843 loss_train: 0.00162 loss_val: 0.00190 violation_train: 0.00102 violation_val: 0.00106 time: 0.0610s\n",
      "-------- Epoch 844 --------\n",
      "epoch: 00844 loss_train: 0.00162 loss_val: 0.00187 violation_train: 0.00031 violation_val: 0.00009 time: 0.0648s\n",
      "-------- Epoch 845 --------\n",
      "epoch: 00845 loss_train: 0.00162 loss_val: 0.00187 violation_train: 0.00003 violation_val: 0.00021 time: 0.0649s\n",
      "-------- Epoch 846 --------\n",
      "epoch: 00846 loss_train: 0.00162 loss_val: 0.00185 violation_train: 0.00006 violation_val: 0.00010 time: 0.0646s\n",
      "-------- Epoch 847 --------\n",
      "epoch: 00847 loss_train: 0.00162 loss_val: 0.00182 violation_train: 0.00011 violation_val: 0.00045 time: 0.0648s\n",
      "-------- Epoch 848 --------\n",
      "epoch: 00848 loss_train: 0.00162 loss_val: 0.00184 violation_train: 0.00027 violation_val: 0.00053 time: 0.0611s\n",
      "-------- Epoch 849 --------\n",
      "epoch: 00849 loss_train: 0.00162 loss_val: 0.00189 violation_train: 0.00106 violation_val: 0.00091 time: 0.0604s\n",
      "-------- Epoch 850 --------\n",
      "epoch: 00850 loss_train: 0.00162 loss_val: 0.00185 violation_train: 0.00049 violation_val: 0.00017 time: 0.0610s\n",
      "-------- Epoch 851 --------\n",
      "epoch: 00851 loss_train: 0.00162 loss_val: 0.00185 violation_train: 0.00025 violation_val: 0.00029 time: 0.0639s\n",
      "-------- Epoch 852 --------\n",
      "epoch: 00852 loss_train: 0.00162 loss_val: 0.00192 violation_train: 0.00012 violation_val: 0.00010 time: 0.0641s\n",
      "-------- Epoch 853 --------\n",
      "epoch: 00853 loss_train: 0.00162 loss_val: 0.00183 violation_train: 0.00006 violation_val: 0.00009 time: 0.0610s\n",
      "-------- Epoch 854 --------\n",
      "epoch: 00854 loss_train: 0.00162 loss_val: 0.00189 violation_train: 0.00018 violation_val: 0.00041 time: 0.0611s\n",
      "-------- Epoch 855 --------\n",
      "epoch: 00855 loss_train: 0.00162 loss_val: 0.00181 violation_train: 0.00149 violation_val: 0.00470 time: 0.0611s\n",
      "-------- Epoch 856 --------\n",
      "epoch: 00856 loss_train: 0.00162 loss_val: 0.00179 violation_train: 0.00106 violation_val: 0.00030 time: 0.0629s\n",
      "-------- Epoch 857 --------\n",
      "epoch: 00857 loss_train: 0.00162 loss_val: 0.00180 violation_train: 0.00011 violation_val: 0.00011 time: 0.0618s\n",
      "-------- Epoch 858 --------\n",
      "epoch: 00858 loss_train: 0.00162 loss_val: 0.00189 violation_train: 0.00003 violation_val: 0.00011 time: 0.0607s\n",
      "-------- Epoch 859 --------\n",
      "epoch: 00859 loss_train: 0.00162 loss_val: 0.00185 violation_train: 0.00004 violation_val: 0.00009 time: 0.0611s\n",
      "-------- Epoch 860 --------\n",
      "epoch: 00860 loss_train: 0.00162 loss_val: 0.00187 violation_train: 0.00006 violation_val: 0.00013 time: 0.0608s\n",
      "-------- Epoch 861 --------\n",
      "epoch: 00861 loss_train: 0.00162 loss_val: 0.00182 violation_train: 0.00004 violation_val: 0.00012 time: 0.0626s\n",
      "-------- Epoch 862 --------\n",
      "epoch: 00862 loss_train: 0.00162 loss_val: 0.00191 violation_train: 0.00004 violation_val: 0.00010 time: 0.0664s\n",
      "-------- Epoch 863 --------\n",
      "epoch: 00863 loss_train: 0.00162 loss_val: 0.00184 violation_train: 0.00007 violation_val: 0.00014 time: 0.0694s\n",
      "-------- Epoch 864 --------\n",
      "epoch: 00864 loss_train: 0.00162 loss_val: 0.00181 violation_train: 0.00007 violation_val: 0.00014 time: 0.0646s\n",
      "-------- Epoch 865 --------\n",
      "epoch: 00865 loss_train: 0.00162 loss_val: 0.00183 violation_train: 0.00015 violation_val: 0.00011 time: 0.0667s\n",
      "-------- Epoch 866 --------\n",
      "epoch: 00866 loss_train: 0.00162 loss_val: 0.00183 violation_train: 0.00009 violation_val: 0.00013 time: 0.0672s\n",
      "-------- Epoch 867 --------\n",
      "epoch: 00867 loss_train: 0.00162 loss_val: 0.00187 violation_train: 0.00038 violation_val: 0.00087 time: 0.0621s\n",
      "-------- Epoch 868 --------\n",
      "epoch: 00868 loss_train: 0.00162 loss_val: 0.00185 violation_train: 0.00067 violation_val: 0.00080 time: 0.0639s\n",
      "-------- Epoch 869 --------\n",
      "epoch: 00869 loss_train: 0.00162 loss_val: 0.00184 violation_train: 0.00037 violation_val: 0.00127 time: 0.0629s\n",
      "-------- Epoch 870 --------\n",
      "epoch: 00870 loss_train: 0.00162 loss_val: 0.00181 violation_train: 0.00075 violation_val: 0.00061 time: 0.0589s\n",
      "-------- Epoch 871 --------\n",
      "epoch: 00871 loss_train: 0.00162 loss_val: 0.00186 violation_train: 0.00017 violation_val: 0.00011 time: 0.0591s\n",
      "-------- Epoch 872 --------\n",
      "epoch: 00872 loss_train: 0.00162 loss_val: 0.00184 violation_train: 0.00015 violation_val: 0.00013 time: 0.0604s\n",
      "-------- Epoch 873 --------\n",
      "epoch: 00873 loss_train: 0.00162 loss_val: 0.00183 violation_train: 0.00021 violation_val: 0.00014 time: 0.0611s\n",
      "-------- Epoch 874 --------\n",
      "epoch: 00874 loss_train: 0.00162 loss_val: 0.00185 violation_train: 0.00040 violation_val: 0.00116 time: 0.0600s\n",
      "-------- Epoch 875 --------\n",
      "epoch: 00875 loss_train: 0.00162 loss_val: 0.00180 violation_train: 0.00058 violation_val: 0.00058 time: 0.0575s\n",
      "-------- Epoch 876 --------\n",
      "epoch: 00876 loss_train: 0.00161 loss_val: 0.00186 violation_train: 0.00017 violation_val: 0.00019 time: 0.0572s\n",
      "-------- Epoch 877 --------\n",
      "epoch: 00877 loss_train: 0.00161 loss_val: 0.00186 violation_train: 0.00011 violation_val: 0.00026 time: 0.0585s\n",
      "-------- Epoch 878 --------\n",
      "epoch: 00878 loss_train: 0.00161 loss_val: 0.00181 violation_train: 0.00091 violation_val: 0.00112 time: 0.0578s\n",
      "-------- Epoch 879 --------\n",
      "epoch: 00879 loss_train: 0.00161 loss_val: 0.00183 violation_train: 0.00074 violation_val: 0.00017 time: 0.0587s\n",
      "-------- Epoch 880 --------\n",
      "epoch: 00880 loss_train: 0.00161 loss_val: 0.00182 violation_train: 0.00005 violation_val: 0.00011 time: 0.0644s\n",
      "-------- Epoch 881 --------\n",
      "epoch: 00881 loss_train: 0.00161 loss_val: 0.00183 violation_train: 0.00005 violation_val: 0.00015 time: 0.0680s\n",
      "-------- Epoch 882 --------\n",
      "epoch: 00882 loss_train: 0.00161 loss_val: 0.00182 violation_train: 0.00007 violation_val: 0.00016 time: 0.0653s\n",
      "-------- Epoch 883 --------\n",
      "epoch: 00883 loss_train: 0.00161 loss_val: 0.00186 violation_train: 0.00023 violation_val: 0.00020 time: 0.0623s\n",
      "-------- Epoch 884 --------\n",
      "epoch: 00884 loss_train: 0.00161 loss_val: 0.00179 violation_train: 0.00013 violation_val: 0.00156 time: 0.0620s\n",
      "-------- Epoch 885 --------\n",
      "epoch: 00885 loss_train: 0.00161 loss_val: 0.00182 violation_train: 0.00043 violation_val: 0.00017 time: 0.0615s\n",
      "-------- Epoch 886 --------\n",
      "epoch: 00886 loss_train: 0.00161 loss_val: 0.00181 violation_train: 0.00052 violation_val: 0.00038 time: 0.0596s\n",
      "-------- Epoch 887 --------\n",
      "epoch: 00887 loss_train: 0.00161 loss_val: 0.00182 violation_train: 0.00026 violation_val: 0.00016 time: 0.0586s\n",
      "-------- Epoch 888 --------\n",
      "epoch: 00888 loss_train: 0.00161 loss_val: 0.00182 violation_train: 0.00021 violation_val: 0.00041 time: 0.0579s\n",
      "-------- Epoch 889 --------\n",
      "epoch: 00889 loss_train: 0.00161 loss_val: 0.00184 violation_train: 0.00122 violation_val: 0.00185 time: 0.0586s\n",
      "-------- Epoch 890 --------\n",
      "epoch: 00890 loss_train: 0.00161 loss_val: 0.00179 violation_train: 0.00123 violation_val: 0.00079 time: 0.0575s\n",
      "-------- Epoch 891 --------\n",
      "epoch: 00891 loss_train: 0.00161 loss_val: 0.00188 violation_train: 0.00049 violation_val: 0.00047 time: 0.0572s\n",
      "-------- Epoch 892 --------\n",
      "epoch: 00892 loss_train: 0.00161 loss_val: 0.00178 violation_train: 0.00008 violation_val: 0.00010 time: 0.0576s\n",
      "-------- Epoch 893 --------\n",
      "epoch: 00893 loss_train: 0.00161 loss_val: 0.00185 violation_train: 0.00006 violation_val: 0.00010 time: 0.0582s\n",
      "-------- Epoch 894 --------\n",
      "epoch: 00894 loss_train: 0.00161 loss_val: 0.00181 violation_train: 0.00003 violation_val: 0.00014 time: 0.0576s\n",
      "-------- Epoch 895 --------\n",
      "epoch: 00895 loss_train: 0.00161 loss_val: 0.00182 violation_train: 0.00006 violation_val: 0.00009 time: 0.0570s\n",
      "-------- Epoch 896 --------\n",
      "epoch: 00896 loss_train: 0.00161 loss_val: 0.00181 violation_train: 0.00005 violation_val: 0.00012 time: 0.0578s\n",
      "-------- Epoch 897 --------\n",
      "epoch: 00897 loss_train: 0.00161 loss_val: 0.00181 violation_train: 0.00005 violation_val: 0.00009 time: 0.0608s\n",
      "-------- Epoch 898 --------\n",
      "epoch: 00898 loss_train: 0.00161 loss_val: 0.00183 violation_train: 0.00004 violation_val: 0.00010 time: 0.0621s\n",
      "-------- Epoch 899 --------\n",
      "epoch: 00899 loss_train: 0.00161 loss_val: 0.00184 violation_train: 0.00005 violation_val: 0.00012 time: 0.0605s\n",
      "-------- Epoch 900 --------\n",
      "epoch: 00900 loss_train: 0.00161 loss_val: 0.00182 violation_train: 0.00009 violation_val: 0.00022 time: 0.0587s\n",
      "-------- Epoch 901 --------\n",
      "epoch: 00901 loss_train: 0.00161 loss_val: 0.00182 violation_train: 0.00050 violation_val: 0.00119 time: 0.0585s\n",
      "-------- Epoch 902 --------\n",
      "epoch: 00902 loss_train: 0.00161 loss_val: 0.00184 violation_train: 0.00275 violation_val: 0.00236 time: 0.0577s\n",
      "-------- Epoch 903 --------\n",
      "epoch: 00903 loss_train: 0.00161 loss_val: 0.00183 violation_train: 0.00068 violation_val: 0.00028 time: 0.0572s\n",
      "-------- Epoch 904 --------\n",
      "epoch: 00904 loss_train: 0.00161 loss_val: 0.00189 violation_train: 0.00006 violation_val: 0.00008 time: 0.0573s\n",
      "-------- Epoch 905 --------\n",
      "epoch: 00905 loss_train: 0.00161 loss_val: 0.00185 violation_train: 0.00002 violation_val: 0.00009 time: 0.0581s\n",
      "-------- Epoch 906 --------\n",
      "epoch: 00906 loss_train: 0.00161 loss_val: 0.00181 violation_train: 0.00002 violation_val: 0.00011 time: 0.0576s\n",
      "-------- Epoch 907 --------\n",
      "epoch: 00907 loss_train: 0.00161 loss_val: 0.00178 violation_train: 0.00002 violation_val: 0.00008 time: 0.0577s\n",
      "-------- Epoch 908 --------\n",
      "epoch: 00908 loss_train: 0.00161 loss_val: 0.00180 violation_train: 0.00002 violation_val: 0.00010 time: 0.0572s\n",
      "-------- Epoch 909 --------\n",
      "epoch: 00909 loss_train: 0.00161 loss_val: 0.00190 violation_train: 0.00003 violation_val: 0.00009 time: 0.0581s\n",
      "-------- Epoch 910 --------\n",
      "epoch: 00910 loss_train: 0.00161 loss_val: 0.00202 violation_train: 0.00003 violation_val: 0.00008 time: 0.0576s\n",
      "-------- Epoch 911 --------\n",
      "epoch: 00911 loss_train: 0.00161 loss_val: 0.00182 violation_train: 0.00002 violation_val: 0.00010 time: 0.0573s\n",
      "-------- Epoch 912 --------\n",
      "epoch: 00912 loss_train: 0.00161 loss_val: 0.00182 violation_train: 0.00003 violation_val: 0.00010 time: 0.0573s\n",
      "-------- Epoch 913 --------\n",
      "epoch: 00913 loss_train: 0.00161 loss_val: 0.00182 violation_train: 0.00003 violation_val: 0.00015 time: 0.0582s\n",
      "-------- Epoch 914 --------\n",
      "epoch: 00914 loss_train: 0.00161 loss_val: 0.00184 violation_train: 0.00003 violation_val: 0.00009 time: 0.0575s\n",
      "-------- Epoch 915 --------\n",
      "epoch: 00915 loss_train: 0.00161 loss_val: 0.00181 violation_train: 0.00003 violation_val: 0.00010 time: 0.0579s\n",
      "-------- Epoch 916 --------\n",
      "epoch: 00916 loss_train: 0.00161 loss_val: 0.00181 violation_train: 0.00004 violation_val: 0.00009 time: 0.0617s\n",
      "-------- Epoch 917 --------\n",
      "epoch: 00917 loss_train: 0.00161 loss_val: 0.00185 violation_train: 0.00007 violation_val: 0.00018 time: 0.0637s\n",
      "-------- Epoch 918 --------\n",
      "epoch: 00918 loss_train: 0.00161 loss_val: 0.00183 violation_train: 0.00018 violation_val: 0.00022 time: 0.0617s\n",
      "-------- Epoch 919 --------\n",
      "epoch: 00919 loss_train: 0.00160 loss_val: 0.00193 violation_train: 0.00007 violation_val: 0.00011 time: 0.0607s\n",
      "-------- Epoch 920 --------\n",
      "epoch: 00920 loss_train: 0.00160 loss_val: 0.00181 violation_train: 0.00017 violation_val: 0.00028 time: 0.0586s\n",
      "-------- Epoch 921 --------\n",
      "epoch: 00921 loss_train: 0.00160 loss_val: 0.00182 violation_train: 0.00073 violation_val: 0.00160 time: 0.0613s\n",
      "-------- Epoch 922 --------\n",
      "epoch: 00922 loss_train: 0.00160 loss_val: 0.00186 violation_train: 0.00146 violation_val: 0.00025 time: 0.0584s\n",
      "-------- Epoch 923 --------\n",
      "epoch: 00923 loss_train: 0.00160 loss_val: 0.00186 violation_train: 0.00007 violation_val: 0.00011 time: 0.0578s\n",
      "-------- Epoch 924 --------\n",
      "epoch: 00924 loss_train: 0.00160 loss_val: 0.00182 violation_train: 0.00003 violation_val: 0.00012 time: 0.0615s\n",
      "-------- Epoch 925 --------\n",
      "epoch: 00925 loss_train: 0.00160 loss_val: 0.00183 violation_train: 0.00003 violation_val: 0.00008 time: 0.0618s\n",
      "-------- Epoch 926 --------\n",
      "epoch: 00926 loss_train: 0.00160 loss_val: 0.00180 violation_train: 0.00004 violation_val: 0.00011 time: 0.0600s\n",
      "-------- Epoch 927 --------\n",
      "epoch: 00927 loss_train: 0.00160 loss_val: 0.00183 violation_train: 0.00005 violation_val: 0.00010 time: 0.0590s\n",
      "-------- Epoch 928 --------\n",
      "epoch: 00928 loss_train: 0.00160 loss_val: 0.00181 violation_train: 0.00004 violation_val: 0.00010 time: 0.0577s\n",
      "-------- Epoch 929 --------\n",
      "epoch: 00929 loss_train: 0.00160 loss_val: 0.00182 violation_train: 0.00005 violation_val: 0.00012 time: 0.0581s\n",
      "-------- Epoch 930 --------\n",
      "epoch: 00930 loss_train: 0.00160 loss_val: 0.00185 violation_train: 0.00025 violation_val: 0.00052 time: 0.0587s\n",
      "-------- Epoch 931 --------\n",
      "epoch: 00931 loss_train: 0.00160 loss_val: 0.00187 violation_train: 0.00019 violation_val: 0.00016 time: 0.0578s\n",
      "-------- Epoch 932 --------\n",
      "epoch: 00932 loss_train: 0.00160 loss_val: 0.00185 violation_train: 0.00014 violation_val: 0.00052 time: 0.0578s\n",
      "-------- Epoch 933 --------\n",
      "epoch: 00933 loss_train: 0.00160 loss_val: 0.00184 violation_train: 0.00102 violation_val: 0.00146 time: 0.0586s\n",
      "-------- Epoch 934 --------\n",
      "epoch: 00934 loss_train: 0.00160 loss_val: 0.00186 violation_train: 0.00024 violation_val: 0.00017 time: 0.0577s\n",
      "-------- Epoch 935 --------\n",
      "epoch: 00935 loss_train: 0.00160 loss_val: 0.00182 violation_train: 0.00015 violation_val: 0.00009 time: 0.0574s\n",
      "-------- Epoch 936 --------\n",
      "epoch: 00936 loss_train: 0.00160 loss_val: 0.00184 violation_train: 0.00004 violation_val: 0.00014 time: 0.0590s\n",
      "-------- Epoch 937 --------\n",
      "epoch: 00937 loss_train: 0.00160 loss_val: 0.00182 violation_train: 0.00015 violation_val: 0.00010 time: 0.0591s\n",
      "-------- Epoch 938 --------\n",
      "epoch: 00938 loss_train: 0.00160 loss_val: 0.00180 violation_train: 0.00007 violation_val: 0.00011 time: 0.0581s\n",
      "-------- Epoch 939 --------\n",
      "epoch: 00939 loss_train: 0.00160 loss_val: 0.00184 violation_train: 0.00009 violation_val: 0.00047 time: 0.0593s\n",
      "-------- Epoch 940 --------\n",
      "epoch: 00940 loss_train: 0.00160 loss_val: 0.00178 violation_train: 0.00093 violation_val: 0.00036 time: 0.0579s\n",
      "-------- Epoch 941 --------\n",
      "epoch: 00941 loss_train: 0.00160 loss_val: 0.00191 violation_train: 0.00046 violation_val: 0.00019 time: 0.0608s\n",
      "-------- Epoch 942 --------\n",
      "epoch: 00942 loss_train: 0.00160 loss_val: 0.00183 violation_train: 0.00010 violation_val: 0.00011 time: 0.0579s\n",
      "-------- Epoch 943 --------\n",
      "epoch: 00943 loss_train: 0.00160 loss_val: 0.00188 violation_train: 0.00010 violation_val: 0.00018 time: 0.0573s\n",
      "-------- Epoch 944 --------\n",
      "epoch: 00944 loss_train: 0.00160 loss_val: 0.00183 violation_train: 0.00082 violation_val: 0.00196 time: 0.0590s\n",
      "-------- Epoch 945 --------\n",
      "epoch: 00945 loss_train: 0.00160 loss_val: 0.00178 violation_train: 0.00051 violation_val: 0.00044 time: 0.0587s\n",
      "-------- Epoch 946 --------\n",
      "epoch: 00946 loss_train: 0.00160 loss_val: 0.00181 violation_train: 0.00027 violation_val: 0.00013 time: 0.0591s\n",
      "-------- Epoch 947 --------\n",
      "epoch: 00947 loss_train: 0.00160 loss_val: 0.00186 violation_train: 0.00005 violation_val: 0.00012 time: 0.0588s\n",
      "-------- Epoch 948 --------\n",
      "epoch: 00948 loss_train: 0.00160 loss_val: 0.00180 violation_train: 0.00005 violation_val: 0.00008 time: 0.0573s\n",
      "-------- Epoch 949 --------\n",
      "epoch: 00949 loss_train: 0.00160 loss_val: 0.00181 violation_train: 0.00008 violation_val: 0.00022 time: 0.0583s\n",
      "-------- Epoch 950 --------\n",
      "epoch: 00950 loss_train: 0.00160 loss_val: 0.00179 violation_train: 0.00028 violation_val: 0.00046 time: 0.0575s\n",
      "-------- Epoch 951 --------\n",
      "epoch: 00951 loss_train: 0.00160 loss_val: 0.00182 violation_train: 0.00077 violation_val: 0.00055 time: 0.0573s\n",
      "-------- Epoch 952 --------\n",
      "epoch: 00952 loss_train: 0.00160 loss_val: 0.00180 violation_train: 0.00039 violation_val: 0.00117 time: 0.0572s\n",
      "-------- Epoch 953 --------\n",
      "epoch: 00953 loss_train: 0.00160 loss_val: 0.00190 violation_train: 0.00054 violation_val: 0.00018 time: 0.0578s\n",
      "-------- Epoch 954 --------\n",
      "epoch: 00954 loss_train: 0.00160 loss_val: 0.00182 violation_train: 0.00011 violation_val: 0.00021 time: 0.0573s\n",
      "-------- Epoch 955 --------\n",
      "epoch: 00955 loss_train: 0.00160 loss_val: 0.00179 violation_train: 0.00011 violation_val: 0.00016 time: 0.0572s\n",
      "-------- Epoch 956 --------\n",
      "epoch: 00956 loss_train: 0.00160 loss_val: 0.00187 violation_train: 0.00089 violation_val: 0.00367 time: 0.0571s\n",
      "-------- Epoch 957 --------\n",
      "epoch: 00957 loss_train: 0.00159 loss_val: 0.00182 violation_train: 0.00084 violation_val: 0.00014 time: 0.0581s\n",
      "-------- Epoch 958 --------\n",
      "epoch: 00958 loss_train: 0.00160 loss_val: 0.00179 violation_train: 0.00011 violation_val: 0.00023 time: 0.0575s\n",
      "-------- Epoch 959 --------\n",
      "epoch: 00959 loss_train: 0.00159 loss_val: 0.00180 violation_train: 0.00012 violation_val: 0.00015 time: 0.0573s\n",
      "-------- Epoch 960 --------\n",
      "epoch: 00960 loss_train: 0.00159 loss_val: 0.00188 violation_train: 0.00007 violation_val: 0.00010 time: 0.0572s\n",
      "-------- Epoch 961 --------\n",
      "epoch: 00961 loss_train: 0.00159 loss_val: 0.00181 violation_train: 0.00007 violation_val: 0.00009 time: 0.0584s\n",
      "-------- Epoch 962 --------\n",
      "epoch: 00962 loss_train: 0.00159 loss_val: 0.00184 violation_train: 0.00005 violation_val: 0.00008 time: 0.0574s\n",
      "-------- Epoch 963 --------\n",
      "epoch: 00963 loss_train: 0.00159 loss_val: 0.00180 violation_train: 0.00018 violation_val: 0.00062 time: 0.0571s\n",
      "-------- Epoch 964 --------\n",
      "epoch: 00964 loss_train: 0.00159 loss_val: 0.00179 violation_train: 0.00086 violation_val: 0.00029 time: 0.0572s\n",
      "-------- Epoch 965 --------\n",
      "epoch: 00965 loss_train: 0.00159 loss_val: 0.00179 violation_train: 0.00022 violation_val: 0.00032 time: 0.0578s\n",
      "-------- Epoch 966 --------\n",
      "epoch: 00966 loss_train: 0.00159 loss_val: 0.00186 violation_train: 0.00022 violation_val: 0.00009 time: 0.0575s\n",
      "-------- Epoch 967 --------\n",
      "epoch: 00967 loss_train: 0.00159 loss_val: 0.00181 violation_train: 0.00026 violation_val: 0.00056 time: 0.0587s\n",
      "-------- Epoch 968 --------\n",
      "epoch: 00968 loss_train: 0.00159 loss_val: 0.00181 violation_train: 0.00104 violation_val: 0.00078 time: 0.0600s\n",
      "-------- Epoch 969 --------\n",
      "epoch: 00969 loss_train: 0.00159 loss_val: 0.00194 violation_train: 0.00042 violation_val: 0.00071 time: 0.0602s\n",
      "-------- Epoch 970 --------\n",
      "epoch: 00970 loss_train: 0.00159 loss_val: 0.00178 violation_train: 0.00015 violation_val: 0.00011 time: 0.0589s\n",
      "-------- Epoch 971 --------\n",
      "epoch: 00971 loss_train: 0.00159 loss_val: 0.00192 violation_train: 0.00008 violation_val: 0.00015 time: 0.0588s\n",
      "-------- Epoch 972 --------\n",
      "epoch: 00972 loss_train: 0.00159 loss_val: 0.00181 violation_train: 0.00007 violation_val: 0.00025 time: 0.0581s\n",
      "-------- Epoch 973 --------\n",
      "epoch: 00973 loss_train: 0.00159 loss_val: 0.00179 violation_train: 0.00032 violation_val: 0.00105 time: 0.0597s\n",
      "-------- Epoch 974 --------\n",
      "epoch: 00974 loss_train: 0.00159 loss_val: 0.00179 violation_train: 0.00043 violation_val: 0.00030 time: 0.0578s\n",
      "-------- Epoch 975 --------\n",
      "epoch: 00975 loss_train: 0.00159 loss_val: 0.00182 violation_train: 0.00021 violation_val: 0.00044 time: 0.0573s\n",
      "-------- Epoch 976 --------\n",
      "epoch: 00976 loss_train: 0.00159 loss_val: 0.00181 violation_train: 0.00082 violation_val: 0.00104 time: 0.0571s\n",
      "-------- Epoch 977 --------\n",
      "epoch: 00977 loss_train: 0.00159 loss_val: 0.00184 violation_train: 0.00035 violation_val: 0.00009 time: 0.0581s\n",
      "-------- Epoch 978 --------\n",
      "epoch: 00978 loss_train: 0.00159 loss_val: 0.00179 violation_train: 0.00011 violation_val: 0.00021 time: 0.0576s\n",
      "-------- Epoch 979 --------\n",
      "epoch: 00979 loss_train: 0.00159 loss_val: 0.00182 violation_train: 0.00006 violation_val: 0.00019 time: 0.0573s\n",
      "-------- Epoch 980 --------\n",
      "epoch: 00980 loss_train: 0.00159 loss_val: 0.00194 violation_train: 0.00021 violation_val: 0.00036 time: 0.0572s\n",
      "-------- Epoch 981 --------\n",
      "epoch: 00981 loss_train: 0.00159 loss_val: 0.00182 violation_train: 0.00093 violation_val: 0.00073 time: 0.0581s\n",
      "-------- Epoch 982 --------\n",
      "epoch: 00982 loss_train: 0.00159 loss_val: 0.00177 violation_train: 0.00084 violation_val: 0.00062 time: 0.0579s\n",
      "-------- Epoch 983 --------\n",
      "epoch: 00983 loss_train: 0.00159 loss_val: 0.00179 violation_train: 0.00025 violation_val: 0.00010 time: 0.0573s\n",
      "-------- Epoch 984 --------\n",
      "epoch: 00984 loss_train: 0.00159 loss_val: 0.00183 violation_train: 0.00006 violation_val: 0.00013 time: 0.0571s\n",
      "-------- Epoch 985 --------\n",
      "epoch: 00985 loss_train: 0.00159 loss_val: 0.00180 violation_train: 0.00005 violation_val: 0.00019 time: 0.0583s\n",
      "-------- Epoch 986 --------\n",
      "epoch: 00986 loss_train: 0.00159 loss_val: 0.00185 violation_train: 0.00013 violation_val: 0.00069 time: 0.0578s\n",
      "-------- Epoch 987 --------\n",
      "epoch: 00987 loss_train: 0.00159 loss_val: 0.00187 violation_train: 0.00038 violation_val: 0.00038 time: 0.0572s\n",
      "-------- Epoch 988 --------\n",
      "epoch: 00988 loss_train: 0.00159 loss_val: 0.00186 violation_train: 0.00062 violation_val: 0.00047 time: 0.0571s\n",
      "-------- Epoch 989 --------\n",
      "epoch: 00989 loss_train: 0.00159 loss_val: 0.00182 violation_train: 0.00040 violation_val: 0.00030 time: 0.0581s\n",
      "-------- Epoch 990 --------\n",
      "epoch: 00990 loss_train: 0.00159 loss_val: 0.00191 violation_train: 0.00012 violation_val: 0.00012 time: 0.0577s\n",
      "-------- Epoch 991 --------\n",
      "epoch: 00991 loss_train: 0.00159 loss_val: 0.00181 violation_train: 0.00011 violation_val: 0.00027 time: 0.0604s\n",
      "-------- Epoch 992 --------\n",
      "epoch: 00992 loss_train: 0.00159 loss_val: 0.00178 violation_train: 0.00082 violation_val: 0.00087 time: 0.0599s\n",
      "-------- Epoch 993 --------\n",
      "epoch: 00993 loss_train: 0.00159 loss_val: 0.00180 violation_train: 0.00103 violation_val: 0.00012 time: 0.0612s\n",
      "-------- Epoch 994 --------\n",
      "epoch: 00994 loss_train: 0.00159 loss_val: 0.00178 violation_train: 0.00005 violation_val: 0.00018 time: 0.0603s\n",
      "-------- Epoch 995 --------\n",
      "epoch: 00995 loss_train: 0.00159 loss_val: 0.00180 violation_train: 0.00006 violation_val: 0.00011 time: 0.0592s\n",
      "-------- Epoch 996 --------\n",
      "epoch: 00996 loss_train: 0.00158 loss_val: 0.00178 violation_train: 0.00008 violation_val: 0.00016 time: 0.0576s\n",
      "-------- Epoch 997 --------\n",
      "epoch: 00997 loss_train: 0.00158 loss_val: 0.00179 violation_train: 0.00014 violation_val: 0.00014 time: 0.0582s\n",
      "-------- Epoch 998 --------\n",
      "epoch: 00998 loss_train: 0.00158 loss_val: 0.00194 violation_train: 0.00012 violation_val: 0.00022 time: 0.0581s\n",
      "-------- Epoch 999 --------\n",
      "epoch: 00999 loss_train: 0.00158 loss_val: 0.00179 violation_train: 0.00011 violation_val: 0.00012 time: 0.0574s\n",
      "-------- Epoch 1000 --------\n",
      "epoch: 01000 loss_train: 0.00159 loss_val: 0.00182 violation_train: 0.00026 violation_val: 0.00037 time: 0.0574s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 60.1287s\n",
      "Start Training...\n",
      "-------- Epoch 1 --------\n",
      "epoch: 00001 loss_train: 0.00408 loss_val: 0.00457 violation_train: 0.00000 violation_val: 0.00000 time: 0.0510s\n",
      "-------- Epoch 2 --------\n",
      "epoch: 00002 loss_train: 0.00352 loss_val: 0.00413 violation_train: 0.00000 violation_val: 0.00000 time: 0.0507s\n",
      "-------- Epoch 3 --------\n",
      "epoch: 00003 loss_train: 0.00307 loss_val: 0.00353 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 4 --------\n",
      "epoch: 00004 loss_train: 0.00270 loss_val: 0.00322 violation_train: 0.00000 violation_val: 0.00000 time: 0.0503s\n",
      "-------- Epoch 5 --------\n",
      "epoch: 00005 loss_train: 0.00241 loss_val: 0.00275 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 6 --------\n",
      "epoch: 00006 loss_train: 0.00219 loss_val: 0.00255 violation_train: 0.00000 violation_val: 0.00000 time: 0.0512s\n",
      "-------- Epoch 7 --------\n",
      "epoch: 00007 loss_train: 0.00204 loss_val: 0.00239 violation_train: 0.00000 violation_val: 0.00000 time: 0.0508s\n",
      "-------- Epoch 8 --------\n",
      "epoch: 00008 loss_train: 0.00194 loss_val: 0.00224 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 9 --------\n",
      "epoch: 00009 loss_train: 0.00188 loss_val: 0.00213 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 10 --------\n",
      "epoch: 00010 loss_train: 0.00185 loss_val: 0.00213 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 11 --------\n",
      "epoch: 00011 loss_train: 0.00183 loss_val: 0.00212 violation_train: 0.00000 violation_val: 0.00000 time: 0.0526s\n",
      "-------- Epoch 12 --------\n",
      "epoch: 00012 loss_train: 0.00182 loss_val: 0.00216 violation_train: 0.00000 violation_val: 0.00000 time: 0.0542s\n",
      "-------- Epoch 13 --------\n",
      "epoch: 00013 loss_train: 0.00181 loss_val: 0.00208 violation_train: 0.00000 violation_val: 0.00000 time: 0.0538s\n",
      "-------- Epoch 14 --------\n",
      "epoch: 00014 loss_train: 0.00180 loss_val: 0.00204 violation_train: 0.00000 violation_val: 0.00000 time: 0.0523s\n",
      "-------- Epoch 15 --------\n",
      "epoch: 00015 loss_train: 0.00179 loss_val: 0.00206 violation_train: 0.00000 violation_val: 0.00000 time: 0.0526s\n",
      "-------- Epoch 16 --------\n",
      "epoch: 00016 loss_train: 0.00178 loss_val: 0.00211 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 17 --------\n",
      "epoch: 00017 loss_train: 0.00177 loss_val: 0.00210 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 18 --------\n",
      "epoch: 00018 loss_train: 0.00176 loss_val: 0.00205 violation_train: 0.00000 violation_val: 0.00000 time: 0.0497s\n",
      "-------- Epoch 19 --------\n",
      "epoch: 00019 loss_train: 0.00175 loss_val: 0.00199 violation_train: 0.00000 violation_val: 0.00000 time: 0.0503s\n",
      "-------- Epoch 20 --------\n",
      "epoch: 00020 loss_train: 0.00175 loss_val: 0.00196 violation_train: 0.00000 violation_val: 0.00000 time: 0.0516s\n",
      "-------- Epoch 21 --------\n",
      "epoch: 00021 loss_train: 0.00174 loss_val: 0.00200 violation_train: 0.00000 violation_val: 0.00000 time: 0.0545s\n",
      "-------- Epoch 22 --------\n",
      "epoch: 00022 loss_train: 0.00173 loss_val: 0.00199 violation_train: 0.00000 violation_val: 0.00000 time: 0.0522s\n",
      "-------- Epoch 23 --------\n",
      "epoch: 00023 loss_train: 0.00172 loss_val: 0.00196 violation_train: 0.00000 violation_val: 0.00000 time: 0.0575s\n",
      "-------- Epoch 24 --------\n",
      "epoch: 00024 loss_train: 0.00171 loss_val: 0.00193 violation_train: 0.00000 violation_val: 0.00000 time: 0.0560s\n",
      "-------- Epoch 25 --------\n",
      "epoch: 00025 loss_train: 0.00170 loss_val: 0.00192 violation_train: 0.00000 violation_val: 0.00000 time: 0.0537s\n",
      "-------- Epoch 26 --------\n",
      "epoch: 00026 loss_train: 0.00169 loss_val: 0.00191 violation_train: 0.00000 violation_val: 0.00000 time: 0.0558s\n",
      "-------- Epoch 27 --------\n",
      "epoch: 00027 loss_train: 0.00169 loss_val: 0.00190 violation_train: 0.00000 violation_val: 0.00000 time: 0.0536s\n",
      "-------- Epoch 28 --------\n",
      "epoch: 00028 loss_train: 0.00167 loss_val: 0.00189 violation_train: 0.00000 violation_val: 0.00000 time: 0.0531s\n",
      "-------- Epoch 29 --------\n",
      "epoch: 00029 loss_train: 0.00167 loss_val: 0.00186 violation_train: 0.00000 violation_val: 0.00000 time: 0.0524s\n",
      "-------- Epoch 30 --------\n",
      "epoch: 00030 loss_train: 0.00165 loss_val: 0.00185 violation_train: 0.00000 violation_val: 0.00000 time: 0.0538s\n",
      "-------- Epoch 31 --------\n",
      "epoch: 00031 loss_train: 0.00164 loss_val: 0.00186 violation_train: 0.00000 violation_val: 0.00000 time: 0.0531s\n",
      "-------- Epoch 32 --------\n",
      "epoch: 00032 loss_train: 0.00163 loss_val: 0.00193 violation_train: 0.00000 violation_val: 0.00000 time: 0.0522s\n",
      "-------- Epoch 33 --------\n",
      "epoch: 00033 loss_train: 0.00162 loss_val: 0.00180 violation_train: 0.00000 violation_val: 0.00000 time: 0.0520s\n",
      "-------- Epoch 34 --------\n",
      "epoch: 00034 loss_train: 0.00161 loss_val: 0.00183 violation_train: 0.00000 violation_val: 0.00000 time: 0.0523s\n",
      "-------- Epoch 35 --------\n",
      "epoch: 00035 loss_train: 0.00160 loss_val: 0.00181 violation_train: 0.00000 violation_val: 0.00000 time: 0.0544s\n",
      "-------- Epoch 36 --------\n",
      "epoch: 00036 loss_train: 0.00158 loss_val: 0.00180 violation_train: 0.00000 violation_val: 0.00000 time: 0.0585s\n",
      "-------- Epoch 37 --------\n",
      "epoch: 00037 loss_train: 0.00157 loss_val: 0.00182 violation_train: 0.00000 violation_val: 0.00000 time: 0.0544s\n",
      "-------- Epoch 38 --------\n",
      "epoch: 00038 loss_train: 0.00156 loss_val: 0.00173 violation_train: 0.00000 violation_val: 0.00000 time: 0.0546s\n",
      "-------- Epoch 39 --------\n",
      "epoch: 00039 loss_train: 0.00154 loss_val: 0.00179 violation_train: 0.00000 violation_val: 0.00000 time: 0.0547s\n",
      "-------- Epoch 40 --------\n",
      "epoch: 00040 loss_train: 0.00153 loss_val: 0.00176 violation_train: 0.00000 violation_val: 0.00000 time: 0.0543s\n",
      "-------- Epoch 41 --------\n",
      "epoch: 00041 loss_train: 0.00151 loss_val: 0.00172 violation_train: 0.00000 violation_val: 0.00000 time: 0.0563s\n",
      "-------- Epoch 42 --------\n",
      "epoch: 00042 loss_train: 0.00150 loss_val: 0.00169 violation_train: 0.00000 violation_val: 0.00000 time: 0.0533s\n",
      "-------- Epoch 43 --------\n",
      "epoch: 00043 loss_train: 0.00148 loss_val: 0.00168 violation_train: 0.00000 violation_val: 0.00000 time: 0.0554s\n",
      "-------- Epoch 44 --------\n",
      "epoch: 00044 loss_train: 0.00146 loss_val: 0.00167 violation_train: 0.00000 violation_val: 0.00000 time: 0.0556s\n",
      "-------- Epoch 45 --------\n",
      "epoch: 00045 loss_train: 0.00144 loss_val: 0.00163 violation_train: 0.00000 violation_val: 0.00000 time: 0.0555s\n",
      "-------- Epoch 46 --------\n",
      "epoch: 00046 loss_train: 0.00142 loss_val: 0.00163 violation_train: 0.00000 violation_val: 0.00000 time: 0.0546s\n",
      "-------- Epoch 47 --------\n",
      "epoch: 00047 loss_train: 0.00140 loss_val: 0.00156 violation_train: 0.00000 violation_val: 0.00000 time: 0.0558s\n",
      "-------- Epoch 48 --------\n",
      "epoch: 00048 loss_train: 0.00138 loss_val: 0.00156 violation_train: 0.00000 violation_val: 0.00000 time: 0.0568s\n",
      "-------- Epoch 49 --------\n",
      "epoch: 00049 loss_train: 0.00136 loss_val: 0.00163 violation_train: 0.00000 violation_val: 0.00000 time: 0.0564s\n",
      "-------- Epoch 50 --------\n",
      "epoch: 00050 loss_train: 0.00134 loss_val: 0.00149 violation_train: 0.00000 violation_val: 0.00000 time: 0.0549s\n",
      "-------- Epoch 51 --------\n",
      "epoch: 00051 loss_train: 0.00132 loss_val: 0.00149 violation_train: 0.00000 violation_val: 0.00000 time: 0.0543s\n",
      "-------- Epoch 52 --------\n",
      "epoch: 00052 loss_train: 0.00130 loss_val: 0.00145 violation_train: 0.00000 violation_val: 0.00000 time: 0.0572s\n",
      "-------- Epoch 53 --------\n",
      "epoch: 00053 loss_train: 0.00127 loss_val: 0.00147 violation_train: 0.00000 violation_val: 0.00000 time: 0.0553s\n",
      "-------- Epoch 54 --------\n",
      "epoch: 00054 loss_train: 0.00125 loss_val: 0.00142 violation_train: 0.00000 violation_val: 0.00000 time: 0.0540s\n",
      "-------- Epoch 55 --------\n",
      "epoch: 00055 loss_train: 0.00123 loss_val: 0.00141 violation_train: 0.00000 violation_val: 0.00000 time: 0.0520s\n",
      "-------- Epoch 56 --------\n",
      "epoch: 00056 loss_train: 0.00121 loss_val: 0.00139 violation_train: 0.00000 violation_val: 0.00000 time: 0.0521s\n",
      "-------- Epoch 57 --------\n",
      "epoch: 00057 loss_train: 0.00118 loss_val: 0.00132 violation_train: 0.00000 violation_val: 0.00000 time: 0.0527s\n",
      "-------- Epoch 58 --------\n",
      "epoch: 00058 loss_train: 0.00116 loss_val: 0.00132 violation_train: 0.00000 violation_val: 0.00000 time: 0.0528s\n",
      "-------- Epoch 59 --------\n",
      "epoch: 00059 loss_train: 0.00114 loss_val: 0.00130 violation_train: 0.00000 violation_val: 0.00000 time: 0.0528s\n",
      "-------- Epoch 60 --------\n",
      "epoch: 00060 loss_train: 0.00112 loss_val: 0.00126 violation_train: 0.00000 violation_val: 0.00000 time: 0.0530s\n",
      "-------- Epoch 61 --------\n",
      "epoch: 00061 loss_train: 0.00109 loss_val: 0.00126 violation_train: 0.00000 violation_val: 0.00000 time: 0.0517s\n",
      "-------- Epoch 62 --------\n",
      "epoch: 00062 loss_train: 0.00107 loss_val: 0.00122 violation_train: 0.00000 violation_val: 0.00000 time: 0.0513s\n",
      "-------- Epoch 63 --------\n",
      "epoch: 00063 loss_train: 0.00105 loss_val: 0.00121 violation_train: 0.00000 violation_val: 0.00000 time: 0.0518s\n",
      "-------- Epoch 64 --------\n",
      "epoch: 00064 loss_train: 0.00103 loss_val: 0.00115 violation_train: 0.00000 violation_val: 0.00000 time: 0.0512s\n",
      "-------- Epoch 65 --------\n",
      "epoch: 00065 loss_train: 0.00101 loss_val: 0.00115 violation_train: 0.00000 violation_val: 0.00000 time: 0.0502s\n",
      "-------- Epoch 66 --------\n",
      "epoch: 00066 loss_train: 0.00098 loss_val: 0.00111 violation_train: 0.00000 violation_val: 0.00000 time: 0.0506s\n",
      "-------- Epoch 67 --------\n",
      "epoch: 00067 loss_train: 0.00096 loss_val: 0.00108 violation_train: 0.00000 violation_val: 0.00000 time: 0.0506s\n",
      "-------- Epoch 68 --------\n",
      "epoch: 00068 loss_train: 0.00094 loss_val: 0.00106 violation_train: 0.00000 violation_val: 0.00000 time: 0.0508s\n",
      "-------- Epoch 69 --------\n",
      "epoch: 00069 loss_train: 0.00092 loss_val: 0.00104 violation_train: 0.00000 violation_val: 0.00000 time: 0.0521s\n",
      "-------- Epoch 70 --------\n",
      "epoch: 00070 loss_train: 0.00090 loss_val: 0.00101 violation_train: 0.00000 violation_val: 0.00000 time: 0.0512s\n",
      "-------- Epoch 71 --------\n",
      "epoch: 00071 loss_train: 0.00088 loss_val: 0.00101 violation_train: 0.00000 violation_val: 0.00000 time: 0.0518s\n",
      "-------- Epoch 72 --------\n",
      "epoch: 00072 loss_train: 0.00086 loss_val: 0.00097 violation_train: 0.00000 violation_val: 0.00000 time: 0.0527s\n",
      "-------- Epoch 73 --------\n",
      "epoch: 00073 loss_train: 0.00084 loss_val: 0.00097 violation_train: 0.00000 violation_val: 0.00000 time: 0.0523s\n",
      "-------- Epoch 74 --------\n",
      "epoch: 00074 loss_train: 0.00083 loss_val: 0.00099 violation_train: 0.00000 violation_val: 0.00000 time: 0.0507s\n",
      "-------- Epoch 75 --------\n",
      "epoch: 00075 loss_train: 0.00081 loss_val: 0.00094 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 76 --------\n",
      "epoch: 00076 loss_train: 0.00079 loss_val: 0.00087 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 77 --------\n",
      "epoch: 00077 loss_train: 0.00078 loss_val: 0.00088 violation_train: 0.00000 violation_val: 0.00000 time: 0.0502s\n",
      "-------- Epoch 78 --------\n",
      "epoch: 00078 loss_train: 0.00076 loss_val: 0.00088 violation_train: 0.00000 violation_val: 0.00000 time: 0.0517s\n",
      "-------- Epoch 79 --------\n",
      "epoch: 00079 loss_train: 0.00075 loss_val: 0.00083 violation_train: 0.00000 violation_val: 0.00000 time: 0.0511s\n",
      "-------- Epoch 80 --------\n",
      "epoch: 00080 loss_train: 0.00073 loss_val: 0.00086 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 81 --------\n",
      "epoch: 00081 loss_train: 0.00072 loss_val: 0.00079 violation_train: 0.00000 violation_val: 0.00000 time: 0.0503s\n",
      "-------- Epoch 82 --------\n",
      "epoch: 00082 loss_train: 0.00070 loss_val: 0.00080 violation_train: 0.00000 violation_val: 0.00000 time: 0.0520s\n",
      "-------- Epoch 83 --------\n",
      "epoch: 00083 loss_train: 0.00069 loss_val: 0.00077 violation_train: 0.00000 violation_val: 0.00000 time: 0.0530s\n",
      "-------- Epoch 84 --------\n",
      "epoch: 00084 loss_train: 0.00068 loss_val: 0.00075 violation_train: 0.00000 violation_val: 0.00000 time: 0.0524s\n",
      "-------- Epoch 85 --------\n",
      "epoch: 00085 loss_train: 0.00067 loss_val: 0.00074 violation_train: 0.00000 violation_val: 0.00000 time: 0.0518s\n",
      "-------- Epoch 86 --------\n",
      "epoch: 00086 loss_train: 0.00065 loss_val: 0.00073 violation_train: 0.00000 violation_val: 0.00000 time: 0.0522s\n",
      "-------- Epoch 87 --------\n",
      "epoch: 00087 loss_train: 0.00064 loss_val: 0.00076 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 88 --------\n",
      "epoch: 00088 loss_train: 0.00063 loss_val: 0.00068 violation_train: 0.00000 violation_val: 0.00000 time: 0.0513s\n",
      "-------- Epoch 89 --------\n",
      "epoch: 00089 loss_train: 0.00062 loss_val: 0.00068 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 90 --------\n",
      "epoch: 00090 loss_train: 0.00061 loss_val: 0.00067 violation_train: 0.00000 violation_val: 0.00000 time: 0.0515s\n",
      "-------- Epoch 91 --------\n",
      "epoch: 00091 loss_train: 0.00060 loss_val: 0.00067 violation_train: 0.00000 violation_val: 0.00000 time: 0.0510s\n",
      "-------- Epoch 92 --------\n",
      "epoch: 00092 loss_train: 0.00059 loss_val: 0.00066 violation_train: 0.00000 violation_val: 0.00000 time: 0.0516s\n",
      "-------- Epoch 93 --------\n",
      "epoch: 00093 loss_train: 0.00058 loss_val: 0.00064 violation_train: 0.00000 violation_val: 0.00000 time: 0.0509s\n",
      "-------- Epoch 94 --------\n",
      "epoch: 00094 loss_train: 0.00057 loss_val: 0.00063 violation_train: 0.00000 violation_val: 0.00000 time: 0.0511s\n",
      "-------- Epoch 95 --------\n",
      "epoch: 00095 loss_train: 0.00056 loss_val: 0.00063 violation_train: 0.00000 violation_val: 0.00000 time: 0.0510s\n",
      "-------- Epoch 96 --------\n",
      "epoch: 00096 loss_train: 0.00055 loss_val: 0.00060 violation_train: 0.00000 violation_val: 0.00000 time: 0.0506s\n",
      "-------- Epoch 97 --------\n",
      "epoch: 00097 loss_train: 0.00055 loss_val: 0.00059 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 98 --------\n",
      "epoch: 00098 loss_train: 0.00054 loss_val: 0.00060 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 99 --------\n",
      "epoch: 00099 loss_train: 0.00053 loss_val: 0.00059 violation_train: 0.00000 violation_val: 0.00000 time: 0.0508s\n",
      "-------- Epoch 100 --------\n",
      "epoch: 00100 loss_train: 0.00052 loss_val: 0.00057 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 101 --------\n",
      "epoch: 00101 loss_train: 0.00051 loss_val: 0.00057 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 102 --------\n",
      "epoch: 00102 loss_train: 0.00051 loss_val: 0.00057 violation_train: 0.00000 violation_val: 0.00000 time: 0.0497s\n",
      "-------- Epoch 103 --------\n",
      "epoch: 00103 loss_train: 0.00050 loss_val: 0.00055 violation_train: 0.00000 violation_val: 0.00000 time: 0.0521s\n",
      "-------- Epoch 104 --------\n",
      "epoch: 00104 loss_train: 0.00049 loss_val: 0.00053 violation_train: 0.00000 violation_val: 0.00000 time: 0.0506s\n",
      "-------- Epoch 105 --------\n",
      "epoch: 00105 loss_train: 0.00049 loss_val: 0.00056 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 106 --------\n",
      "epoch: 00106 loss_train: 0.00048 loss_val: 0.00053 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 107 --------\n",
      "epoch: 00107 loss_train: 0.00047 loss_val: 0.00051 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 108 --------\n",
      "epoch: 00108 loss_train: 0.00047 loss_val: 0.00052 violation_train: 0.00000 violation_val: 0.00000 time: 0.0506s\n",
      "-------- Epoch 109 --------\n",
      "epoch: 00109 loss_train: 0.00046 loss_val: 0.00050 violation_train: 0.00000 violation_val: 0.00000 time: 0.0509s\n",
      "-------- Epoch 110 --------\n",
      "epoch: 00110 loss_train: 0.00045 loss_val: 0.00050 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 111 --------\n",
      "epoch: 00111 loss_train: 0.00045 loss_val: 0.00048 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 112 --------\n",
      "epoch: 00112 loss_train: 0.00044 loss_val: 0.00051 violation_train: 0.00000 violation_val: 0.00000 time: 0.0502s\n",
      "-------- Epoch 113 --------\n",
      "epoch: 00113 loss_train: 0.00043 loss_val: 0.00047 violation_train: 0.00000 violation_val: 0.00000 time: 0.0513s\n",
      "-------- Epoch 114 --------\n",
      "epoch: 00114 loss_train: 0.00043 loss_val: 0.00046 violation_train: 0.00000 violation_val: 0.00000 time: 0.0508s\n",
      "-------- Epoch 115 --------\n",
      "epoch: 00115 loss_train: 0.00042 loss_val: 0.00047 violation_train: 0.00000 violation_val: 0.00000 time: 0.0503s\n",
      "-------- Epoch 116 --------\n",
      "epoch: 00116 loss_train: 0.00042 loss_val: 0.00048 violation_train: 0.00000 violation_val: 0.00000 time: 0.0508s\n",
      "-------- Epoch 117 --------\n",
      "epoch: 00117 loss_train: 0.00041 loss_val: 0.00044 violation_train: 0.00000 violation_val: 0.00000 time: 0.0511s\n",
      "-------- Epoch 118 --------\n",
      "epoch: 00118 loss_train: 0.00041 loss_val: 0.00046 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 119 --------\n",
      "epoch: 00119 loss_train: 0.00040 loss_val: 0.00046 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 120 --------\n",
      "epoch: 00120 loss_train: 0.00040 loss_val: 0.00042 violation_train: 0.00000 violation_val: 0.00000 time: 0.0503s\n",
      "-------- Epoch 121 --------\n",
      "epoch: 00121 loss_train: 0.00039 loss_val: 0.00042 violation_train: 0.00000 violation_val: 0.00000 time: 0.0513s\n",
      "-------- Epoch 122 --------\n",
      "epoch: 00122 loss_train: 0.00039 loss_val: 0.00040 violation_train: 0.00000 violation_val: 0.00000 time: 0.0509s\n",
      "-------- Epoch 123 --------\n",
      "epoch: 00123 loss_train: 0.00038 loss_val: 0.00042 violation_train: 0.00000 violation_val: 0.00000 time: 0.0501s\n",
      "-------- Epoch 124 --------\n",
      "epoch: 00124 loss_train: 0.00038 loss_val: 0.00042 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 125 --------\n",
      "epoch: 00125 loss_train: 0.00037 loss_val: 0.00040 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 126 --------\n",
      "epoch: 00126 loss_train: 0.00037 loss_val: 0.00039 violation_train: 0.00000 violation_val: 0.00000 time: 0.0547s\n",
      "-------- Epoch 127 --------\n",
      "epoch: 00127 loss_train: 0.00036 loss_val: 0.00038 violation_train: 0.00000 violation_val: 0.00000 time: 0.0535s\n",
      "-------- Epoch 128 --------\n",
      "epoch: 00128 loss_train: 0.00036 loss_val: 0.00038 violation_train: 0.00000 violation_val: 0.00000 time: 0.0531s\n",
      "-------- Epoch 129 --------\n",
      "epoch: 00129 loss_train: 0.00035 loss_val: 0.00038 violation_train: 0.00000 violation_val: 0.00000 time: 0.0517s\n",
      "-------- Epoch 130 --------\n",
      "epoch: 00130 loss_train: 0.00035 loss_val: 0.00038 violation_train: 0.00000 violation_val: 0.00000 time: 0.0537s\n",
      "-------- Epoch 131 --------\n",
      "epoch: 00131 loss_train: 0.00034 loss_val: 0.00036 violation_train: 0.00000 violation_val: 0.00000 time: 0.0538s\n",
      "-------- Epoch 132 --------\n",
      "epoch: 00132 loss_train: 0.00034 loss_val: 0.00036 violation_train: 0.00000 violation_val: 0.00000 time: 0.0534s\n",
      "-------- Epoch 133 --------\n",
      "epoch: 00133 loss_train: 0.00033 loss_val: 0.00035 violation_train: 0.00000 violation_val: 0.00000 time: 0.0540s\n",
      "-------- Epoch 134 --------\n",
      "epoch: 00134 loss_train: 0.00033 loss_val: 0.00036 violation_train: 0.00000 violation_val: 0.00000 time: 0.0538s\n",
      "-------- Epoch 135 --------\n",
      "epoch: 00135 loss_train: 0.00033 loss_val: 0.00034 violation_train: 0.00000 violation_val: 0.00000 time: 0.0549s\n",
      "-------- Epoch 136 --------\n",
      "epoch: 00136 loss_train: 0.00032 loss_val: 0.00035 violation_train: 0.00000 violation_val: 0.00000 time: 0.0527s\n",
      "-------- Epoch 137 --------\n",
      "epoch: 00137 loss_train: 0.00032 loss_val: 0.00034 violation_train: 0.00000 violation_val: 0.00000 time: 0.0522s\n",
      "-------- Epoch 138 --------\n",
      "epoch: 00138 loss_train: 0.00031 loss_val: 0.00033 violation_train: 0.00000 violation_val: 0.00000 time: 0.0537s\n",
      "-------- Epoch 139 --------\n",
      "epoch: 00139 loss_train: 0.00031 loss_val: 0.00033 violation_train: 0.00000 violation_val: 0.00000 time: 0.0520s\n",
      "-------- Epoch 140 --------\n",
      "epoch: 00140 loss_train: 0.00030 loss_val: 0.00033 violation_train: 0.00000 violation_val: 0.00000 time: 0.0520s\n",
      "-------- Epoch 141 --------\n",
      "epoch: 00141 loss_train: 0.00030 loss_val: 0.00034 violation_train: 0.00000 violation_val: 0.00000 time: 0.0500s\n",
      "-------- Epoch 142 --------\n",
      "epoch: 00142 loss_train: 0.00030 loss_val: 0.00031 violation_train: 0.00000 violation_val: 0.00000 time: 0.0512s\n",
      "-------- Epoch 143 --------\n",
      "epoch: 00143 loss_train: 0.00029 loss_val: 0.00032 violation_train: 0.00000 violation_val: 0.00000 time: 0.0509s\n",
      "-------- Epoch 144 --------\n",
      "epoch: 00144 loss_train: 0.00029 loss_val: 0.00030 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 145 --------\n",
      "epoch: 00145 loss_train: 0.00029 loss_val: 0.00031 violation_train: 0.00000 violation_val: 0.00000 time: 0.0516s\n",
      "-------- Epoch 146 --------\n",
      "epoch: 00146 loss_train: 0.00028 loss_val: 0.00030 violation_train: 0.00000 violation_val: 0.00000 time: 0.0547s\n",
      "-------- Epoch 147 --------\n",
      "epoch: 00147 loss_train: 0.00028 loss_val: 0.00029 violation_train: 0.00000 violation_val: 0.00000 time: 0.0512s\n",
      "-------- Epoch 148 --------\n",
      "epoch: 00148 loss_train: 0.00027 loss_val: 0.00032 violation_train: 0.00000 violation_val: 0.00000 time: 0.0500s\n",
      "-------- Epoch 149 --------\n",
      "epoch: 00149 loss_train: 0.00027 loss_val: 0.00029 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 150 --------\n",
      "epoch: 00150 loss_train: 0.00027 loss_val: 0.00029 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 151 --------\n",
      "epoch: 00151 loss_train: 0.00026 loss_val: 0.00027 violation_train: 0.00000 violation_val: 0.00000 time: 0.0517s\n",
      "-------- Epoch 152 --------\n",
      "epoch: 00152 loss_train: 0.00026 loss_val: 0.00027 violation_train: 0.00000 violation_val: 0.00000 time: 0.0502s\n",
      "-------- Epoch 153 --------\n",
      "epoch: 00153 loss_train: 0.00026 loss_val: 0.00026 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 154 --------\n",
      "epoch: 00154 loss_train: 0.00025 loss_val: 0.00028 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 155 --------\n",
      "epoch: 00155 loss_train: 0.00025 loss_val: 0.00028 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 156 --------\n",
      "epoch: 00156 loss_train: 0.00025 loss_val: 0.00026 violation_train: 0.00000 violation_val: 0.00000 time: 0.0503s\n",
      "-------- Epoch 157 --------\n",
      "epoch: 00157 loss_train: 0.00024 loss_val: 0.00025 violation_train: 0.00000 violation_val: 0.00000 time: 0.0508s\n",
      "-------- Epoch 158 --------\n",
      "epoch: 00158 loss_train: 0.00024 loss_val: 0.00024 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 159 --------\n",
      "epoch: 00159 loss_train: 0.00024 loss_val: 0.00024 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 160 --------\n",
      "epoch: 00160 loss_train: 0.00023 loss_val: 0.00023 violation_train: 0.00000 violation_val: 0.00000 time: 0.0503s\n",
      "-------- Epoch 161 --------\n",
      "epoch: 00161 loss_train: 0.00023 loss_val: 0.00023 violation_train: 0.00000 violation_val: 0.00000 time: 0.0515s\n",
      "-------- Epoch 162 --------\n",
      "epoch: 00162 loss_train: 0.00023 loss_val: 0.00025 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 163 --------\n",
      "epoch: 00163 loss_train: 0.00022 loss_val: 0.00024 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 164 --------\n",
      "epoch: 00164 loss_train: 0.00022 loss_val: 0.00022 violation_train: 0.00000 violation_val: 0.00000 time: 0.0503s\n",
      "-------- Epoch 165 --------\n",
      "epoch: 00165 loss_train: 0.00022 loss_val: 0.00022 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 166 --------\n",
      "epoch: 00166 loss_train: 0.00021 loss_val: 0.00024 violation_train: 0.00000 violation_val: 0.00000 time: 0.0511s\n",
      "-------- Epoch 167 --------\n",
      "epoch: 00167 loss_train: 0.00021 loss_val: 0.00022 violation_train: 0.00000 violation_val: 0.00000 time: 0.0508s\n",
      "-------- Epoch 168 --------\n",
      "epoch: 00168 loss_train: 0.00021 loss_val: 0.00021 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 169 --------\n",
      "epoch: 00169 loss_train: 0.00020 loss_val: 0.00022 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 170 --------\n",
      "epoch: 00170 loss_train: 0.00020 loss_val: 0.00022 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 171 --------\n",
      "epoch: 00171 loss_train: 0.00020 loss_val: 0.00020 violation_train: 0.00000 violation_val: 0.00000 time: 0.0513s\n",
      "-------- Epoch 172 --------\n",
      "epoch: 00172 loss_train: 0.00020 loss_val: 0.00020 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 173 --------\n",
      "epoch: 00173 loss_train: 0.00019 loss_val: 0.00020 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 174 --------\n",
      "epoch: 00174 loss_train: 0.00019 loss_val: 0.00019 violation_train: 0.00000 violation_val: 0.00000 time: 0.0502s\n",
      "-------- Epoch 175 --------\n",
      "epoch: 00175 loss_train: 0.00019 loss_val: 0.00019 violation_train: 0.00000 violation_val: 0.00000 time: 0.0506s\n",
      "-------- Epoch 176 --------\n",
      "epoch: 00176 loss_train: 0.00019 loss_val: 0.00018 violation_train: 0.00000 violation_val: 0.00000 time: 0.0530s\n",
      "-------- Epoch 177 --------\n",
      "epoch: 00177 loss_train: 0.00018 loss_val: 0.00019 violation_train: 0.00000 violation_val: 0.00000 time: 0.0516s\n",
      "-------- Epoch 178 --------\n",
      "epoch: 00178 loss_train: 0.00018 loss_val: 0.00018 violation_train: 0.00000 violation_val: 0.00000 time: 0.0506s\n",
      "-------- Epoch 179 --------\n",
      "epoch: 00179 loss_train: 0.00018 loss_val: 0.00020 violation_train: 0.00000 violation_val: 0.00000 time: 0.0500s\n",
      "-------- Epoch 180 --------\n",
      "epoch: 00180 loss_train: 0.00018 loss_val: 0.00018 violation_train: 0.00000 violation_val: 0.00000 time: 0.0510s\n",
      "-------- Epoch 181 --------\n",
      "epoch: 00181 loss_train: 0.00017 loss_val: 0.00018 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 182 --------\n",
      "epoch: 00182 loss_train: 0.00017 loss_val: 0.00019 violation_train: 0.00000 violation_val: 0.00000 time: 0.0497s\n",
      "-------- Epoch 183 --------\n",
      "epoch: 00183 loss_train: 0.00017 loss_val: 0.00017 violation_train: 0.00000 violation_val: 0.00000 time: 0.0503s\n",
      "-------- Epoch 184 --------\n",
      "epoch: 00184 loss_train: 0.00017 loss_val: 0.00016 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 185 --------\n",
      "epoch: 00185 loss_train: 0.00017 loss_val: 0.00017 violation_train: 0.00000 violation_val: 0.00000 time: 0.0512s\n",
      "-------- Epoch 186 --------\n",
      "epoch: 00186 loss_train: 0.00016 loss_val: 0.00016 violation_train: 0.00000 violation_val: 0.00000 time: 0.0508s\n",
      "-------- Epoch 187 --------\n",
      "epoch: 00187 loss_train: 0.00016 loss_val: 0.00017 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 188 --------\n",
      "epoch: 00188 loss_train: 0.00016 loss_val: 0.00016 violation_train: 0.00000 violation_val: 0.00000 time: 0.0497s\n",
      "-------- Epoch 189 --------\n",
      "epoch: 00189 loss_train: 0.00016 loss_val: 0.00015 violation_train: 0.00000 violation_val: 0.00000 time: 0.0503s\n",
      "-------- Epoch 190 --------\n",
      "epoch: 00190 loss_train: 0.00016 loss_val: 0.00015 violation_train: 0.00000 violation_val: 0.00000 time: 0.0509s\n",
      "-------- Epoch 191 --------\n",
      "epoch: 00191 loss_train: 0.00015 loss_val: 0.00015 violation_train: 0.00000 violation_val: 0.00000 time: 0.0503s\n",
      "-------- Epoch 192 --------\n",
      "epoch: 00192 loss_train: 0.00015 loss_val: 0.00015 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 193 --------\n",
      "epoch: 00193 loss_train: 0.00015 loss_val: 0.00014 violation_train: 0.00000 violation_val: 0.00000 time: 0.0503s\n",
      "-------- Epoch 194 --------\n",
      "epoch: 00194 loss_train: 0.00015 loss_val: 0.00014 violation_train: 0.00000 violation_val: 0.00000 time: 0.0506s\n",
      "-------- Epoch 195 --------\n",
      "epoch: 00195 loss_train: 0.00015 loss_val: 0.00015 violation_train: 0.00000 violation_val: 0.00000 time: 0.0507s\n",
      "-------- Epoch 196 --------\n",
      "epoch: 00196 loss_train: 0.00014 loss_val: 0.00015 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 197 --------\n",
      "epoch: 00197 loss_train: 0.00014 loss_val: 0.00013 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 198 --------\n",
      "epoch: 00198 loss_train: 0.00014 loss_val: 0.00014 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 199 --------\n",
      "epoch: 00199 loss_train: 0.00014 loss_val: 0.00014 violation_train: 0.00000 violation_val: 0.00000 time: 0.0497s\n",
      "-------- Epoch 200 --------\n",
      "epoch: 00200 loss_train: 0.00014 loss_val: 0.00014 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 201 --------\n",
      "epoch: 00201 loss_train: 0.00014 loss_val: 0.00014 violation_train: 0.00000 violation_val: 0.00000 time: 0.0502s\n",
      "-------- Epoch 202 --------\n",
      "epoch: 00202 loss_train: 0.00013 loss_val: 0.00013 violation_train: 0.00000 violation_val: 0.00000 time: 0.0503s\n",
      "-------- Epoch 203 --------\n",
      "epoch: 00203 loss_train: 0.00013 loss_val: 0.00013 violation_train: 0.00000 violation_val: 0.00000 time: 0.0497s\n",
      "-------- Epoch 204 --------\n",
      "epoch: 00204 loss_train: 0.00013 loss_val: 0.00013 violation_train: 0.00000 violation_val: 0.00000 time: 0.0503s\n",
      "-------- Epoch 205 --------\n",
      "epoch: 00205 loss_train: 0.00013 loss_val: 0.00013 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 206 --------\n",
      "epoch: 00206 loss_train: 0.00013 loss_val: 0.00013 violation_train: 0.00000 violation_val: 0.00000 time: 0.0501s\n",
      "-------- Epoch 207 --------\n",
      "epoch: 00207 loss_train: 0.00013 loss_val: 0.00012 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 208 --------\n",
      "epoch: 00208 loss_train: 0.00012 loss_val: 0.00013 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 209 --------\n",
      "epoch: 00209 loss_train: 0.00012 loss_val: 0.00012 violation_train: 0.00000 violation_val: 0.00000 time: 0.0502s\n",
      "-------- Epoch 210 --------\n",
      "epoch: 00210 loss_train: 0.00012 loss_val: 0.00011 violation_train: 0.00000 violation_val: 0.00000 time: 0.0515s\n",
      "-------- Epoch 211 --------\n",
      "epoch: 00211 loss_train: 0.00012 loss_val: 0.00011 violation_train: 0.00000 violation_val: 0.00000 time: 0.0507s\n",
      "-------- Epoch 212 --------\n",
      "epoch: 00212 loss_train: 0.00012 loss_val: 0.00011 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 213 --------\n",
      "epoch: 00213 loss_train: 0.00012 loss_val: 0.00011 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 214 --------\n",
      "epoch: 00214 loss_train: 0.00012 loss_val: 0.00012 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 215 --------\n",
      "epoch: 00215 loss_train: 0.00011 loss_val: 0.00011 violation_train: 0.00000 violation_val: 0.00000 time: 0.0546s\n",
      "-------- Epoch 216 --------\n",
      "epoch: 00216 loss_train: 0.00011 loss_val: 0.00011 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 217 --------\n",
      "epoch: 00217 loss_train: 0.00011 loss_val: 0.00011 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 218 --------\n",
      "epoch: 00218 loss_train: 0.00011 loss_val: 0.00010 violation_train: 0.00000 violation_val: 0.00000 time: 0.0503s\n",
      "-------- Epoch 219 --------\n",
      "epoch: 00219 loss_train: 0.00011 loss_val: 0.00010 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 220 --------\n",
      "epoch: 00220 loss_train: 0.00011 loss_val: 0.00011 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 221 --------\n",
      "epoch: 00221 loss_train: 0.00011 loss_val: 0.00011 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 222 --------\n",
      "epoch: 00222 loss_train: 0.00011 loss_val: 0.00010 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 223 --------\n",
      "epoch: 00223 loss_train: 0.00011 loss_val: 0.00010 violation_train: 0.00000 violation_val: 0.00000 time: 0.0502s\n",
      "-------- Epoch 224 --------\n",
      "epoch: 00224 loss_train: 0.00011 loss_val: 0.00010 violation_train: 0.00000 violation_val: 0.00000 time: 0.0503s\n",
      "-------- Epoch 225 --------\n",
      "epoch: 00225 loss_train: 0.00010 loss_val: 0.00009 violation_train: 0.00000 violation_val: 0.00000 time: 0.0515s\n",
      "-------- Epoch 226 --------\n",
      "epoch: 00226 loss_train: 0.00010 loss_val: 0.00009 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 227 --------\n",
      "epoch: 00227 loss_train: 0.00010 loss_val: 0.00010 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 228 --------\n",
      "epoch: 00228 loss_train: 0.00010 loss_val: 0.00011 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 229 --------\n",
      "epoch: 00229 loss_train: 0.00010 loss_val: 0.00010 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 230 --------\n",
      "epoch: 00230 loss_train: 0.00010 loss_val: 0.00009 violation_train: 0.00000 violation_val: 0.00000 time: 0.0510s\n",
      "-------- Epoch 231 --------\n",
      "epoch: 00231 loss_train: 0.00010 loss_val: 0.00009 violation_train: 0.00000 violation_val: 0.00000 time: 0.0500s\n",
      "-------- Epoch 232 --------\n",
      "epoch: 00232 loss_train: 0.00010 loss_val: 0.00009 violation_train: 0.00000 violation_val: 0.00000 time: 0.0497s\n",
      "-------- Epoch 233 --------\n",
      "epoch: 00233 loss_train: 0.00010 loss_val: 0.00009 violation_train: 0.00000 violation_val: 0.00000 time: 0.0572s\n",
      "-------- Epoch 234 --------\n",
      "epoch: 00234 loss_train: 0.00010 loss_val: 0.00008 violation_train: 0.00000 violation_val: 0.00000 time: 0.0558s\n",
      "-------- Epoch 235 --------\n",
      "epoch: 00235 loss_train: 0.00009 loss_val: 0.00009 violation_train: 0.00000 violation_val: 0.00000 time: 0.0538s\n",
      "-------- Epoch 236 --------\n",
      "epoch: 00236 loss_train: 0.00009 loss_val: 0.00008 violation_train: 0.00000 violation_val: 0.00000 time: 0.0523s\n",
      "-------- Epoch 237 --------\n",
      "epoch: 00237 loss_train: 0.00009 loss_val: 0.00009 violation_train: 0.00000 violation_val: 0.00000 time: 0.0540s\n",
      "-------- Epoch 238 --------\n",
      "epoch: 00238 loss_train: 0.00009 loss_val: 0.00008 violation_train: 0.00000 violation_val: 0.00000 time: 0.0545s\n",
      "-------- Epoch 239 --------\n",
      "epoch: 00239 loss_train: 0.00009 loss_val: 0.00008 violation_train: 0.00000 violation_val: 0.00000 time: 0.0532s\n",
      "-------- Epoch 240 --------\n",
      "epoch: 00240 loss_train: 0.00009 loss_val: 0.00008 violation_train: 0.00000 violation_val: 0.00000 time: 0.0514s\n",
      "-------- Epoch 241 --------\n",
      "epoch: 00241 loss_train: 0.00009 loss_val: 0.00008 violation_train: 0.00000 violation_val: 0.00000 time: 0.0512s\n",
      "-------- Epoch 242 --------\n",
      "epoch: 00242 loss_train: 0.00009 loss_val: 0.00008 violation_train: 0.00000 violation_val: 0.00000 time: 0.0514s\n",
      "-------- Epoch 243 --------\n",
      "epoch: 00243 loss_train: 0.00009 loss_val: 0.00008 violation_train: 0.00000 violation_val: 0.00000 time: 0.0510s\n",
      "-------- Epoch 244 --------\n",
      "epoch: 00244 loss_train: 0.00009 loss_val: 0.00008 violation_train: 0.00000 violation_val: 0.00000 time: 0.0503s\n",
      "-------- Epoch 245 --------\n",
      "epoch: 00245 loss_train: 0.00009 loss_val: 0.00008 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 246 --------\n",
      "epoch: 00246 loss_train: 0.00009 loss_val: 0.00008 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 247 --------\n",
      "epoch: 00247 loss_train: 0.00009 loss_val: 0.00008 violation_train: 0.00000 violation_val: 0.00000 time: 0.0512s\n",
      "-------- Epoch 248 --------\n",
      "epoch: 00248 loss_train: 0.00008 loss_val: 0.00008 violation_train: 0.00000 violation_val: 0.00000 time: 0.0546s\n",
      "-------- Epoch 249 --------\n",
      "epoch: 00249 loss_train: 0.00008 loss_val: 0.00008 violation_train: 0.00000 violation_val: 0.00000 time: 0.0533s\n",
      "-------- Epoch 250 --------\n",
      "epoch: 00250 loss_train: 0.00008 loss_val: 0.00007 violation_train: 0.00000 violation_val: 0.00000 time: 0.0536s\n",
      "-------- Epoch 251 --------\n",
      "epoch: 00251 loss_train: 0.00008 loss_val: 0.00007 violation_train: 0.00000 violation_val: 0.00000 time: 0.0532s\n",
      "-------- Epoch 252 --------\n",
      "epoch: 00252 loss_train: 0.00008 loss_val: 0.00007 violation_train: 0.00000 violation_val: 0.00000 time: 0.0515s\n",
      "-------- Epoch 253 --------\n",
      "epoch: 00253 loss_train: 0.00008 loss_val: 0.00007 violation_train: 0.00000 violation_val: 0.00000 time: 0.0518s\n",
      "-------- Epoch 254 --------\n",
      "epoch: 00254 loss_train: 0.00008 loss_val: 0.00007 violation_train: 0.00000 violation_val: 0.00000 time: 0.0539s\n",
      "-------- Epoch 255 --------\n",
      "epoch: 00255 loss_train: 0.00008 loss_val: 0.00007 violation_train: 0.00000 violation_val: 0.00000 time: 0.0542s\n",
      "-------- Epoch 256 --------\n",
      "epoch: 00256 loss_train: 0.00008 loss_val: 0.00007 violation_train: 0.00000 violation_val: 0.00000 time: 0.0521s\n",
      "-------- Epoch 257 --------\n",
      "epoch: 00257 loss_train: 0.00008 loss_val: 0.00007 violation_train: 0.00000 violation_val: 0.00000 time: 0.0514s\n",
      "-------- Epoch 258 --------\n",
      "epoch: 00258 loss_train: 0.00008 loss_val: 0.00007 violation_train: 0.00000 violation_val: 0.00000 time: 0.0527s\n",
      "-------- Epoch 259 --------\n",
      "epoch: 00259 loss_train: 0.00008 loss_val: 0.00007 violation_train: 0.00000 violation_val: 0.00000 time: 0.0526s\n",
      "-------- Epoch 260 --------\n",
      "epoch: 00260 loss_train: 0.00008 loss_val: 0.00007 violation_train: 0.00000 violation_val: 0.00000 time: 0.0532s\n",
      "-------- Epoch 261 --------\n",
      "epoch: 00261 loss_train: 0.00008 loss_val: 0.00007 violation_train: 0.00000 violation_val: 0.00000 time: 0.0512s\n",
      "-------- Epoch 262 --------\n",
      "epoch: 00262 loss_train: 0.00008 loss_val: 0.00007 violation_train: 0.00000 violation_val: 0.00000 time: 0.0506s\n",
      "-------- Epoch 263 --------\n",
      "epoch: 00263 loss_train: 0.00008 loss_val: 0.00007 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 264 --------\n",
      "epoch: 00264 loss_train: 0.00007 loss_val: 0.00007 violation_train: 0.00000 violation_val: 0.00000 time: 0.0526s\n",
      "-------- Epoch 265 --------\n",
      "epoch: 00265 loss_train: 0.00007 loss_val: 0.00007 violation_train: 0.00000 violation_val: 0.00000 time: 0.0527s\n",
      "-------- Epoch 266 --------\n",
      "epoch: 00266 loss_train: 0.00007 loss_val: 0.00006 violation_train: 0.00000 violation_val: 0.00000 time: 0.0528s\n",
      "-------- Epoch 267 --------\n",
      "epoch: 00267 loss_train: 0.00007 loss_val: 0.00007 violation_train: 0.00000 violation_val: 0.00000 time: 0.0523s\n",
      "-------- Epoch 268 --------\n",
      "epoch: 00268 loss_train: 0.00007 loss_val: 0.00007 violation_train: 0.00000 violation_val: 0.00000 time: 0.0539s\n",
      "-------- Epoch 269 --------\n",
      "epoch: 00269 loss_train: 0.00007 loss_val: 0.00006 violation_train: 0.00000 violation_val: 0.00000 time: 0.0540s\n",
      "-------- Epoch 270 --------\n",
      "epoch: 00270 loss_train: 0.00007 loss_val: 0.00006 violation_train: 0.00000 violation_val: 0.00000 time: 0.0536s\n",
      "-------- Epoch 271 --------\n",
      "epoch: 00271 loss_train: 0.00007 loss_val: 0.00006 violation_train: 0.00000 violation_val: 0.00000 time: 0.0549s\n",
      "-------- Epoch 272 --------\n",
      "epoch: 00272 loss_train: 0.00007 loss_val: 0.00006 violation_train: 0.00000 violation_val: 0.00000 time: 0.0514s\n",
      "-------- Epoch 273 --------\n",
      "epoch: 00273 loss_train: 0.00007 loss_val: 0.00006 violation_train: 0.00000 violation_val: 0.00000 time: 0.0509s\n",
      "-------- Epoch 274 --------\n",
      "epoch: 00274 loss_train: 0.00007 loss_val: 0.00007 violation_train: 0.00000 violation_val: 0.00000 time: 0.0507s\n",
      "-------- Epoch 275 --------\n",
      "epoch: 00275 loss_train: 0.00007 loss_val: 0.00006 violation_train: 0.00000 violation_val: 0.00000 time: 0.0516s\n",
      "-------- Epoch 276 --------\n",
      "epoch: 00276 loss_train: 0.00007 loss_val: 0.00006 violation_train: 0.00000 violation_val: 0.00000 time: 0.0522s\n",
      "-------- Epoch 277 --------\n",
      "epoch: 00277 loss_train: 0.00007 loss_val: 0.00006 violation_train: 0.00000 violation_val: 0.00000 time: 0.0600s\n",
      "-------- Epoch 278 --------\n",
      "epoch: 00278 loss_train: 0.00007 loss_val: 0.00006 violation_train: 0.00000 violation_val: 0.00000 time: 0.0555s\n",
      "-------- Epoch 279 --------\n",
      "epoch: 00279 loss_train: 0.00007 loss_val: 0.00006 violation_train: 0.00000 violation_val: 0.00000 time: 0.0544s\n",
      "-------- Epoch 280 --------\n",
      "epoch: 00280 loss_train: 0.00007 loss_val: 0.00006 violation_train: 0.00000 violation_val: 0.00000 time: 0.0541s\n",
      "-------- Epoch 281 --------\n",
      "epoch: 00281 loss_train: 0.00007 loss_val: 0.00006 violation_train: 0.00000 violation_val: 0.00000 time: 0.0523s\n",
      "-------- Epoch 282 --------\n",
      "epoch: 00282 loss_train: 0.00007 loss_val: 0.00006 violation_train: 0.00000 violation_val: 0.00000 time: 0.0532s\n",
      "-------- Epoch 283 --------\n",
      "epoch: 00283 loss_train: 0.00007 loss_val: 0.00006 violation_train: 0.00000 violation_val: 0.00000 time: 0.0521s\n",
      "-------- Epoch 284 --------\n",
      "epoch: 00284 loss_train: 0.00007 loss_val: 0.00006 violation_train: 0.00000 violation_val: 0.00000 time: 0.0506s\n",
      "-------- Epoch 285 --------\n",
      "epoch: 00285 loss_train: 0.00007 loss_val: 0.00006 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 286 --------\n",
      "epoch: 00286 loss_train: 0.00006 loss_val: 0.00006 violation_train: 0.00000 violation_val: 0.00000 time: 0.0502s\n",
      "-------- Epoch 287 --------\n",
      "epoch: 00287 loss_train: 0.00006 loss_val: 0.00006 violation_train: 0.00000 violation_val: 0.00000 time: 0.0500s\n",
      "-------- Epoch 288 --------\n",
      "epoch: 00288 loss_train: 0.00006 loss_val: 0.00006 violation_train: 0.00000 violation_val: 0.00000 time: 0.0520s\n",
      "-------- Epoch 289 --------\n",
      "epoch: 00289 loss_train: 0.00006 loss_val: 0.00006 violation_train: 0.00000 violation_val: 0.00000 time: 0.0502s\n",
      "-------- Epoch 290 --------\n",
      "epoch: 00290 loss_train: 0.00006 loss_val: 0.00006 violation_train: 0.00000 violation_val: 0.00000 time: 0.0500s\n",
      "-------- Epoch 291 --------\n",
      "epoch: 00291 loss_train: 0.00006 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0507s\n",
      "-------- Epoch 292 --------\n",
      "epoch: 00292 loss_train: 0.00006 loss_val: 0.00006 violation_train: 0.00000 violation_val: 0.00000 time: 0.0516s\n",
      "-------- Epoch 293 --------\n",
      "epoch: 00293 loss_train: 0.00006 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0510s\n",
      "-------- Epoch 294 --------\n",
      "epoch: 00294 loss_train: 0.00006 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0500s\n",
      "-------- Epoch 295 --------\n",
      "epoch: 00295 loss_train: 0.00006 loss_val: 0.00006 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 296 --------\n",
      "epoch: 00296 loss_train: 0.00006 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 297 --------\n",
      "epoch: 00297 loss_train: 0.00006 loss_val: 0.00006 violation_train: 0.00000 violation_val: 0.00000 time: 0.0506s\n",
      "-------- Epoch 298 --------\n",
      "epoch: 00298 loss_train: 0.00006 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0510s\n",
      "-------- Epoch 299 --------\n",
      "epoch: 00299 loss_train: 0.00006 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0500s\n",
      "-------- Epoch 300 --------\n",
      "epoch: 00300 loss_train: 0.00006 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0501s\n",
      "-------- Epoch 301 --------\n",
      "epoch: 00301 loss_train: 0.00006 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0510s\n",
      "-------- Epoch 302 --------\n",
      "epoch: 00302 loss_train: 0.00006 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0506s\n",
      "-------- Epoch 303 --------\n",
      "epoch: 00303 loss_train: 0.00006 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0538s\n",
      "-------- Epoch 304 --------\n",
      "epoch: 00304 loss_train: 0.00006 loss_val: 0.00006 violation_train: 0.00000 violation_val: 0.00000 time: 0.0540s\n",
      "-------- Epoch 305 --------\n",
      "epoch: 00305 loss_train: 0.00006 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0531s\n",
      "-------- Epoch 306 --------\n",
      "epoch: 00306 loss_train: 0.00006 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0542s\n",
      "-------- Epoch 307 --------\n",
      "epoch: 00307 loss_train: 0.00006 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0536s\n",
      "-------- Epoch 308 --------\n",
      "epoch: 00308 loss_train: 0.00006 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0542s\n",
      "-------- Epoch 309 --------\n",
      "epoch: 00309 loss_train: 0.00006 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0668s\n",
      "-------- Epoch 310 --------\n",
      "epoch: 00310 loss_train: 0.00006 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0805s\n",
      "-------- Epoch 311 --------\n",
      "epoch: 00311 loss_train: 0.00006 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0717s\n",
      "-------- Epoch 312 --------\n",
      "epoch: 00312 loss_train: 0.00006 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0568s\n",
      "-------- Epoch 313 --------\n",
      "epoch: 00313 loss_train: 0.00006 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0565s\n",
      "-------- Epoch 314 --------\n",
      "epoch: 00314 loss_train: 0.00006 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0565s\n",
      "-------- Epoch 315 --------\n",
      "epoch: 00315 loss_train: 0.00006 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0549s\n",
      "-------- Epoch 316 --------\n",
      "epoch: 00316 loss_train: 0.00006 loss_val: 0.00006 violation_train: 0.00000 violation_val: 0.00000 time: 0.0536s\n",
      "-------- Epoch 317 --------\n",
      "epoch: 00317 loss_train: 0.00006 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0537s\n",
      "-------- Epoch 318 --------\n",
      "epoch: 00318 loss_train: 0.00006 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0535s\n",
      "-------- Epoch 319 --------\n",
      "epoch: 00319 loss_train: 0.00006 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0549s\n",
      "-------- Epoch 320 --------\n",
      "epoch: 00320 loss_train: 0.00006 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0532s\n",
      "-------- Epoch 321 --------\n",
      "epoch: 00321 loss_train: 0.00006 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0541s\n",
      "-------- Epoch 322 --------\n",
      "epoch: 00322 loss_train: 0.00006 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0534s\n",
      "-------- Epoch 323 --------\n",
      "epoch: 00323 loss_train: 0.00006 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0578s\n",
      "-------- Epoch 324 --------\n",
      "epoch: 00324 loss_train: 0.00006 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0546s\n",
      "-------- Epoch 325 --------\n",
      "epoch: 00325 loss_train: 0.00006 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0539s\n",
      "-------- Epoch 326 --------\n",
      "epoch: 00326 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0557s\n",
      "-------- Epoch 327 --------\n",
      "epoch: 00327 loss_train: 0.00006 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0546s\n",
      "-------- Epoch 328 --------\n",
      "epoch: 00328 loss_train: 0.00006 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0535s\n",
      "-------- Epoch 329 --------\n",
      "epoch: 00329 loss_train: 0.00006 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0535s\n",
      "-------- Epoch 330 --------\n",
      "epoch: 00330 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0533s\n",
      "-------- Epoch 331 --------\n",
      "epoch: 00331 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0525s\n",
      "-------- Epoch 332 --------\n",
      "epoch: 00332 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0512s\n",
      "-------- Epoch 333 --------\n",
      "epoch: 00333 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0509s\n",
      "-------- Epoch 334 --------\n",
      "epoch: 00334 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0507s\n",
      "-------- Epoch 335 --------\n",
      "epoch: 00335 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0503s\n",
      "-------- Epoch 336 --------\n",
      "epoch: 00336 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0500s\n",
      "-------- Epoch 337 --------\n",
      "epoch: 00337 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 338 --------\n",
      "epoch: 00338 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 339 --------\n",
      "epoch: 00339 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0509s\n",
      "-------- Epoch 340 --------\n",
      "epoch: 00340 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0517s\n",
      "-------- Epoch 341 --------\n",
      "epoch: 00341 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0510s\n",
      "-------- Epoch 342 --------\n",
      "epoch: 00342 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 343 --------\n",
      "epoch: 00343 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0508s\n",
      "-------- Epoch 344 --------\n",
      "epoch: 00344 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0511s\n",
      "-------- Epoch 345 --------\n",
      "epoch: 00345 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0509s\n",
      "-------- Epoch 346 --------\n",
      "epoch: 00346 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 347 --------\n",
      "epoch: 00347 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 348 --------\n",
      "epoch: 00348 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0503s\n",
      "-------- Epoch 349 --------\n",
      "epoch: 00349 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 350 --------\n",
      "epoch: 00350 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0534s\n",
      "-------- Epoch 351 --------\n",
      "epoch: 00351 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0541s\n",
      "-------- Epoch 352 --------\n",
      "epoch: 00352 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0524s\n",
      "-------- Epoch 353 --------\n",
      "epoch: 00353 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0517s\n",
      "-------- Epoch 354 --------\n",
      "epoch: 00354 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0510s\n",
      "-------- Epoch 355 --------\n",
      "epoch: 00355 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0506s\n",
      "-------- Epoch 356 --------\n",
      "epoch: 00356 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0503s\n",
      "-------- Epoch 357 --------\n",
      "epoch: 00357 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 358 --------\n",
      "epoch: 00358 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 359 --------\n",
      "epoch: 00359 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0503s\n",
      "-------- Epoch 360 --------\n",
      "epoch: 00360 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0510s\n",
      "-------- Epoch 361 --------\n",
      "epoch: 00361 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0519s\n",
      "-------- Epoch 362 --------\n",
      "epoch: 00362 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0501s\n",
      "-------- Epoch 363 --------\n",
      "epoch: 00363 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0500s\n",
      "-------- Epoch 364 --------\n",
      "epoch: 00364 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0503s\n",
      "-------- Epoch 365 --------\n",
      "epoch: 00365 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 366 --------\n",
      "epoch: 00366 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 367 --------\n",
      "epoch: 00367 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0523s\n",
      "-------- Epoch 368 --------\n",
      "epoch: 00368 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0521s\n",
      "-------- Epoch 369 --------\n",
      "epoch: 00369 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0528s\n",
      "-------- Epoch 370 --------\n",
      "epoch: 00370 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0596s\n",
      "-------- Epoch 371 --------\n",
      "epoch: 00371 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0556s\n",
      "-------- Epoch 372 --------\n",
      "epoch: 00372 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0558s\n",
      "-------- Epoch 373 --------\n",
      "epoch: 00373 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0540s\n",
      "-------- Epoch 374 --------\n",
      "epoch: 00374 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0531s\n",
      "-------- Epoch 375 --------\n",
      "epoch: 00375 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0536s\n",
      "-------- Epoch 376 --------\n",
      "epoch: 00376 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0544s\n",
      "-------- Epoch 377 --------\n",
      "epoch: 00377 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0526s\n",
      "-------- Epoch 378 --------\n",
      "epoch: 00378 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0531s\n",
      "-------- Epoch 379 --------\n",
      "epoch: 00379 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0551s\n",
      "-------- Epoch 380 --------\n",
      "epoch: 00380 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0548s\n",
      "-------- Epoch 381 --------\n",
      "epoch: 00381 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0533s\n",
      "-------- Epoch 382 --------\n",
      "epoch: 00382 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0529s\n",
      "-------- Epoch 383 --------\n",
      "epoch: 00383 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0517s\n",
      "-------- Epoch 384 --------\n",
      "epoch: 00384 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0537s\n",
      "-------- Epoch 385 --------\n",
      "epoch: 00385 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0531s\n",
      "-------- Epoch 386 --------\n",
      "epoch: 00386 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0533s\n",
      "-------- Epoch 387 --------\n",
      "epoch: 00387 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0506s\n",
      "-------- Epoch 388 --------\n",
      "epoch: 00388 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 389 --------\n",
      "epoch: 00389 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0513s\n",
      "-------- Epoch 390 --------\n",
      "epoch: 00390 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0520s\n",
      "-------- Epoch 391 --------\n",
      "epoch: 00391 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0547s\n",
      "-------- Epoch 392 --------\n",
      "epoch: 00392 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0528s\n",
      "-------- Epoch 393 --------\n",
      "epoch: 00393 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0517s\n",
      "-------- Epoch 394 --------\n",
      "epoch: 00394 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0507s\n",
      "-------- Epoch 395 --------\n",
      "epoch: 00395 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0512s\n",
      "-------- Epoch 396 --------\n",
      "epoch: 00396 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0538s\n",
      "-------- Epoch 397 --------\n",
      "epoch: 00397 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0546s\n",
      "-------- Epoch 398 --------\n",
      "epoch: 00398 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0526s\n",
      "-------- Epoch 399 --------\n",
      "epoch: 00399 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0517s\n",
      "-------- Epoch 400 --------\n",
      "epoch: 00400 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0532s\n",
      "-------- Epoch 401 --------\n",
      "epoch: 00401 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0529s\n",
      "-------- Epoch 402 --------\n",
      "epoch: 00402 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0529s\n",
      "-------- Epoch 403 --------\n",
      "epoch: 00403 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0513s\n",
      "-------- Epoch 404 --------\n",
      "epoch: 00404 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0514s\n",
      "-------- Epoch 405 --------\n",
      "epoch: 00405 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 406 --------\n",
      "epoch: 00406 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0516s\n",
      "-------- Epoch 407 --------\n",
      "epoch: 00407 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0503s\n",
      "-------- Epoch 408 --------\n",
      "epoch: 00408 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0514s\n",
      "-------- Epoch 409 --------\n",
      "epoch: 00409 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0509s\n",
      "-------- Epoch 410 --------\n",
      "epoch: 00410 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0513s\n",
      "-------- Epoch 411 --------\n",
      "epoch: 00411 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0507s\n",
      "-------- Epoch 412 --------\n",
      "epoch: 00412 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0507s\n",
      "-------- Epoch 413 --------\n",
      "epoch: 00413 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0506s\n",
      "-------- Epoch 414 --------\n",
      "epoch: 00414 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 415 --------\n",
      "epoch: 00415 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 416 --------\n",
      "epoch: 00416 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 417 --------\n",
      "epoch: 00417 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 418 --------\n",
      "epoch: 00418 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0509s\n",
      "-------- Epoch 419 --------\n",
      "epoch: 00419 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 420 --------\n",
      "epoch: 00420 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 421 --------\n",
      "epoch: 00421 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0497s\n",
      "-------- Epoch 422 --------\n",
      "epoch: 00422 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0506s\n",
      "-------- Epoch 423 --------\n",
      "epoch: 00423 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0500s\n",
      "-------- Epoch 424 --------\n",
      "epoch: 00424 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 425 --------\n",
      "epoch: 00425 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 426 --------\n",
      "epoch: 00426 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 427 --------\n",
      "epoch: 00427 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0507s\n",
      "-------- Epoch 428 --------\n",
      "epoch: 00428 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0500s\n",
      "-------- Epoch 429 --------\n",
      "epoch: 00429 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 430 --------\n",
      "epoch: 00430 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0497s\n",
      "-------- Epoch 431 --------\n",
      "epoch: 00431 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0497s\n",
      "-------- Epoch 432 --------\n",
      "epoch: 00432 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0508s\n",
      "-------- Epoch 433 --------\n",
      "epoch: 00433 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0500s\n",
      "-------- Epoch 434 --------\n",
      "epoch: 00434 loss_train: 0.00005 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 435 --------\n",
      "epoch: 00435 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0510s\n",
      "-------- Epoch 436 --------\n",
      "epoch: 00436 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 437 --------\n",
      "epoch: 00437 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0508s\n",
      "-------- Epoch 438 --------\n",
      "epoch: 00438 loss_train: 0.00005 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0502s\n",
      "-------- Epoch 439 --------\n",
      "epoch: 00439 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 440 --------\n",
      "epoch: 00440 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 441 --------\n",
      "epoch: 00441 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0511s\n",
      "-------- Epoch 442 --------\n",
      "epoch: 00442 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0519s\n",
      "-------- Epoch 443 --------\n",
      "epoch: 00443 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0520s\n",
      "-------- Epoch 444 --------\n",
      "epoch: 00444 loss_train: 0.00004 loss_val: 0.00005 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 445 --------\n",
      "epoch: 00445 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 446 --------\n",
      "epoch: 00446 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0532s\n",
      "-------- Epoch 447 --------\n",
      "epoch: 00447 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0513s\n",
      "-------- Epoch 448 --------\n",
      "epoch: 00448 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0511s\n",
      "-------- Epoch 449 --------\n",
      "epoch: 00449 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0533s\n",
      "-------- Epoch 450 --------\n",
      "epoch: 00450 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0526s\n",
      "-------- Epoch 451 --------\n",
      "epoch: 00451 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0525s\n",
      "-------- Epoch 452 --------\n",
      "epoch: 00452 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0510s\n",
      "-------- Epoch 453 --------\n",
      "epoch: 00453 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0502s\n",
      "-------- Epoch 454 --------\n",
      "epoch: 00454 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0506s\n",
      "-------- Epoch 455 --------\n",
      "epoch: 00455 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0520s\n",
      "-------- Epoch 456 --------\n",
      "epoch: 00456 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0579s\n",
      "-------- Epoch 457 --------\n",
      "epoch: 00457 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0570s\n",
      "-------- Epoch 458 --------\n",
      "epoch: 00458 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0570s\n",
      "-------- Epoch 459 --------\n",
      "epoch: 00459 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0531s\n",
      "-------- Epoch 460 --------\n",
      "epoch: 00460 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0520s\n",
      "-------- Epoch 461 --------\n",
      "epoch: 00461 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0513s\n",
      "-------- Epoch 462 --------\n",
      "epoch: 00462 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0517s\n",
      "-------- Epoch 463 --------\n",
      "epoch: 00463 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0514s\n",
      "-------- Epoch 464 --------\n",
      "epoch: 00464 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 465 --------\n",
      "epoch: 00465 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0503s\n",
      "-------- Epoch 466 --------\n",
      "epoch: 00466 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0530s\n",
      "-------- Epoch 467 --------\n",
      "epoch: 00467 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0519s\n",
      "-------- Epoch 468 --------\n",
      "epoch: 00468 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0503s\n",
      "-------- Epoch 469 --------\n",
      "epoch: 00469 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0512s\n",
      "-------- Epoch 470 --------\n",
      "epoch: 00470 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0526s\n",
      "-------- Epoch 471 --------\n",
      "epoch: 00471 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 472 --------\n",
      "epoch: 00472 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0512s\n",
      "-------- Epoch 473 --------\n",
      "epoch: 00473 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0517s\n",
      "-------- Epoch 474 --------\n",
      "epoch: 00474 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0514s\n",
      "-------- Epoch 475 --------\n",
      "epoch: 00475 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 476 --------\n",
      "epoch: 00476 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 477 --------\n",
      "epoch: 00477 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 478 --------\n",
      "epoch: 00478 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 479 --------\n",
      "epoch: 00479 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0571s\n",
      "-------- Epoch 480 --------\n",
      "epoch: 00480 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0592s\n",
      "-------- Epoch 481 --------\n",
      "epoch: 00481 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0575s\n",
      "-------- Epoch 482 --------\n",
      "epoch: 00482 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0544s\n",
      "-------- Epoch 483 --------\n",
      "epoch: 00483 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0545s\n",
      "-------- Epoch 484 --------\n",
      "epoch: 00484 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0524s\n",
      "-------- Epoch 485 --------\n",
      "epoch: 00485 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0507s\n",
      "-------- Epoch 486 --------\n",
      "epoch: 00486 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0508s\n",
      "-------- Epoch 487 --------\n",
      "epoch: 00487 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0517s\n",
      "-------- Epoch 488 --------\n",
      "epoch: 00488 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0507s\n",
      "-------- Epoch 489 --------\n",
      "epoch: 00489 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0555s\n",
      "-------- Epoch 490 --------\n",
      "epoch: 00490 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0533s\n",
      "-------- Epoch 491 --------\n",
      "epoch: 00491 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0522s\n",
      "-------- Epoch 492 --------\n",
      "epoch: 00492 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0522s\n",
      "-------- Epoch 493 --------\n",
      "epoch: 00493 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0514s\n",
      "-------- Epoch 494 --------\n",
      "epoch: 00494 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0526s\n",
      "-------- Epoch 495 --------\n",
      "epoch: 00495 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0522s\n",
      "-------- Epoch 496 --------\n",
      "epoch: 00496 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0516s\n",
      "-------- Epoch 497 --------\n",
      "epoch: 00497 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0515s\n",
      "-------- Epoch 498 --------\n",
      "epoch: 00498 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0508s\n",
      "-------- Epoch 499 --------\n",
      "epoch: 00499 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0507s\n",
      "-------- Epoch 500 --------\n",
      "epoch: 00500 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0547s\n",
      "-------- Epoch 501 --------\n",
      "epoch: 00501 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0567s\n",
      "-------- Epoch 502 --------\n",
      "epoch: 00502 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0568s\n",
      "-------- Epoch 503 --------\n",
      "epoch: 00503 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0536s\n",
      "-------- Epoch 504 --------\n",
      "epoch: 00504 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0517s\n",
      "-------- Epoch 505 --------\n",
      "epoch: 00505 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0519s\n",
      "-------- Epoch 506 --------\n",
      "epoch: 00506 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0514s\n",
      "-------- Epoch 507 --------\n",
      "epoch: 00507 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0517s\n",
      "-------- Epoch 508 --------\n",
      "epoch: 00508 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0536s\n",
      "-------- Epoch 509 --------\n",
      "epoch: 00509 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0517s\n",
      "-------- Epoch 510 --------\n",
      "epoch: 00510 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0509s\n",
      "-------- Epoch 511 --------\n",
      "epoch: 00511 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0510s\n",
      "-------- Epoch 512 --------\n",
      "epoch: 00512 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 513 --------\n",
      "epoch: 00513 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 514 --------\n",
      "epoch: 00514 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 515 --------\n",
      "epoch: 00515 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0500s\n",
      "-------- Epoch 516 --------\n",
      "epoch: 00516 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0508s\n",
      "-------- Epoch 517 --------\n",
      "epoch: 00517 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0510s\n",
      "-------- Epoch 518 --------\n",
      "epoch: 00518 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 519 --------\n",
      "epoch: 00519 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 520 --------\n",
      "epoch: 00520 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 521 --------\n",
      "epoch: 00521 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0506s\n",
      "-------- Epoch 522 --------\n",
      "epoch: 00522 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 523 --------\n",
      "epoch: 00523 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 524 --------\n",
      "epoch: 00524 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 525 --------\n",
      "epoch: 00525 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 526 --------\n",
      "epoch: 00526 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0506s\n",
      "-------- Epoch 527 --------\n",
      "epoch: 00527 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0501s\n",
      "-------- Epoch 528 --------\n",
      "epoch: 00528 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 529 --------\n",
      "epoch: 00529 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0503s\n",
      "-------- Epoch 530 --------\n",
      "epoch: 00530 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0506s\n",
      "-------- Epoch 531 --------\n",
      "epoch: 00531 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0514s\n",
      "-------- Epoch 532 --------\n",
      "epoch: 00532 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0518s\n",
      "-------- Epoch 533 --------\n",
      "epoch: 00533 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0546s\n",
      "-------- Epoch 534 --------\n",
      "epoch: 00534 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0519s\n",
      "-------- Epoch 535 --------\n",
      "epoch: 00535 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0540s\n",
      "-------- Epoch 536 --------\n",
      "epoch: 00536 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0524s\n",
      "-------- Epoch 537 --------\n",
      "epoch: 00537 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0510s\n",
      "-------- Epoch 538 --------\n",
      "epoch: 00538 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0517s\n",
      "-------- Epoch 539 --------\n",
      "epoch: 00539 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0513s\n",
      "-------- Epoch 540 --------\n",
      "epoch: 00540 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0536s\n",
      "-------- Epoch 541 --------\n",
      "epoch: 00541 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0530s\n",
      "-------- Epoch 542 --------\n",
      "epoch: 00542 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0509s\n",
      "-------- Epoch 543 --------\n",
      "epoch: 00543 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0537s\n",
      "-------- Epoch 544 --------\n",
      "epoch: 00544 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0520s\n",
      "-------- Epoch 545 --------\n",
      "epoch: 00545 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0516s\n",
      "-------- Epoch 546 --------\n",
      "epoch: 00546 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0503s\n",
      "-------- Epoch 547 --------\n",
      "epoch: 00547 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 548 --------\n",
      "epoch: 00548 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0513s\n",
      "-------- Epoch 549 --------\n",
      "epoch: 00549 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0525s\n",
      "-------- Epoch 550 --------\n",
      "epoch: 00550 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0556s\n",
      "-------- Epoch 551 --------\n",
      "epoch: 00551 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0572s\n",
      "-------- Epoch 552 --------\n",
      "epoch: 00552 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0532s\n",
      "-------- Epoch 553 --------\n",
      "epoch: 00553 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0525s\n",
      "-------- Epoch 554 --------\n",
      "epoch: 00554 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0516s\n",
      "-------- Epoch 555 --------\n",
      "epoch: 00555 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0518s\n",
      "-------- Epoch 556 --------\n",
      "epoch: 00556 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0522s\n",
      "-------- Epoch 557 --------\n",
      "epoch: 00557 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0539s\n",
      "-------- Epoch 558 --------\n",
      "epoch: 00558 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0532s\n",
      "-------- Epoch 559 --------\n",
      "epoch: 00559 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0512s\n",
      "-------- Epoch 560 --------\n",
      "epoch: 00560 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 561 --------\n",
      "epoch: 00561 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 562 --------\n",
      "epoch: 00562 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 563 --------\n",
      "epoch: 00563 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 564 --------\n",
      "epoch: 00564 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0510s\n",
      "-------- Epoch 565 --------\n",
      "epoch: 00565 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0513s\n",
      "-------- Epoch 566 --------\n",
      "epoch: 00566 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 567 --------\n",
      "epoch: 00567 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0497s\n",
      "-------- Epoch 568 --------\n",
      "epoch: 00568 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 569 --------\n",
      "epoch: 00569 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 570 --------\n",
      "epoch: 00570 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0500s\n",
      "-------- Epoch 571 --------\n",
      "epoch: 00571 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0497s\n",
      "-------- Epoch 572 --------\n",
      "epoch: 00572 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 573 --------\n",
      "epoch: 00573 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 574 --------\n",
      "epoch: 00574 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0517s\n",
      "-------- Epoch 575 --------\n",
      "epoch: 00575 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0517s\n",
      "-------- Epoch 576 --------\n",
      "epoch: 00576 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0506s\n",
      "-------- Epoch 577 --------\n",
      "epoch: 00577 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 578 --------\n",
      "epoch: 00578 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0501s\n",
      "-------- Epoch 579 --------\n",
      "epoch: 00579 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0511s\n",
      "-------- Epoch 580 --------\n",
      "epoch: 00580 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0502s\n",
      "-------- Epoch 581 --------\n",
      "epoch: 00581 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 582 --------\n",
      "epoch: 00582 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 583 --------\n",
      "epoch: 00583 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0507s\n",
      "-------- Epoch 584 --------\n",
      "epoch: 00584 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 585 --------\n",
      "epoch: 00585 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0507s\n",
      "-------- Epoch 586 --------\n",
      "epoch: 00586 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0512s\n",
      "-------- Epoch 587 --------\n",
      "epoch: 00587 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0515s\n",
      "-------- Epoch 588 --------\n",
      "epoch: 00588 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0500s\n",
      "-------- Epoch 589 --------\n",
      "epoch: 00589 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0514s\n",
      "-------- Epoch 590 --------\n",
      "epoch: 00590 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0522s\n",
      "-------- Epoch 591 --------\n",
      "epoch: 00591 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0550s\n",
      "-------- Epoch 592 --------\n",
      "epoch: 00592 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0530s\n",
      "-------- Epoch 593 --------\n",
      "epoch: 00593 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0532s\n",
      "-------- Epoch 594 --------\n",
      "epoch: 00594 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0518s\n",
      "-------- Epoch 595 --------\n",
      "epoch: 00595 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0534s\n",
      "-------- Epoch 596 --------\n",
      "epoch: 00596 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0542s\n",
      "-------- Epoch 597 --------\n",
      "epoch: 00597 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0538s\n",
      "-------- Epoch 598 --------\n",
      "epoch: 00598 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0540s\n",
      "-------- Epoch 599 --------\n",
      "epoch: 00599 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0518s\n",
      "-------- Epoch 600 --------\n",
      "epoch: 00600 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0556s\n",
      "-------- Epoch 601 --------\n",
      "epoch: 00601 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0521s\n",
      "-------- Epoch 602 --------\n",
      "epoch: 00602 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0517s\n",
      "-------- Epoch 603 --------\n",
      "epoch: 00603 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0521s\n",
      "-------- Epoch 604 --------\n",
      "epoch: 00604 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0535s\n",
      "-------- Epoch 605 --------\n",
      "epoch: 00605 loss_train: 0.00004 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0509s\n",
      "-------- Epoch 606 --------\n",
      "epoch: 00606 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0502s\n",
      "-------- Epoch 607 --------\n",
      "epoch: 00607 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0533s\n",
      "-------- Epoch 608 --------\n",
      "epoch: 00608 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0526s\n",
      "-------- Epoch 609 --------\n",
      "epoch: 00609 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0538s\n",
      "-------- Epoch 610 --------\n",
      "epoch: 00610 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0508s\n",
      "-------- Epoch 611 --------\n",
      "epoch: 00611 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0509s\n",
      "-------- Epoch 612 --------\n",
      "epoch: 00612 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0507s\n",
      "-------- Epoch 613 --------\n",
      "epoch: 00613 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0508s\n",
      "-------- Epoch 614 --------\n",
      "epoch: 00614 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0510s\n",
      "-------- Epoch 615 --------\n",
      "epoch: 00615 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0561s\n",
      "-------- Epoch 616 --------\n",
      "epoch: 00616 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0542s\n",
      "-------- Epoch 617 --------\n",
      "epoch: 00617 loss_train: 0.00004 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0528s\n",
      "-------- Epoch 618 --------\n",
      "epoch: 00618 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0518s\n",
      "-------- Epoch 619 --------\n",
      "epoch: 00619 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0523s\n",
      "-------- Epoch 620 --------\n",
      "epoch: 00620 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0524s\n",
      "-------- Epoch 621 --------\n",
      "epoch: 00621 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0524s\n",
      "-------- Epoch 622 --------\n",
      "epoch: 00622 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0506s\n",
      "-------- Epoch 623 --------\n",
      "epoch: 00623 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0506s\n",
      "-------- Epoch 624 --------\n",
      "epoch: 00624 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0511s\n",
      "-------- Epoch 625 --------\n",
      "epoch: 00625 loss_train: 0.00003 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0500s\n",
      "-------- Epoch 626 --------\n",
      "epoch: 00626 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 627 --------\n",
      "epoch: 00627 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0518s\n",
      "-------- Epoch 628 --------\n",
      "epoch: 00628 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 629 --------\n",
      "epoch: 00629 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0501s\n",
      "-------- Epoch 630 --------\n",
      "epoch: 00630 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 631 --------\n",
      "epoch: 00631 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0500s\n",
      "-------- Epoch 632 --------\n",
      "epoch: 00632 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0509s\n",
      "-------- Epoch 633 --------\n",
      "epoch: 00633 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0530s\n",
      "-------- Epoch 634 --------\n",
      "epoch: 00634 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0523s\n",
      "-------- Epoch 635 --------\n",
      "epoch: 00635 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0522s\n",
      "-------- Epoch 636 --------\n",
      "epoch: 00636 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0535s\n",
      "-------- Epoch 637 --------\n",
      "epoch: 00637 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0525s\n",
      "-------- Epoch 638 --------\n",
      "epoch: 00638 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0520s\n",
      "-------- Epoch 639 --------\n",
      "epoch: 00639 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0524s\n",
      "-------- Epoch 640 --------\n",
      "epoch: 00640 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0508s\n",
      "-------- Epoch 641 --------\n",
      "epoch: 00641 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0509s\n",
      "-------- Epoch 642 --------\n",
      "epoch: 00642 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 643 --------\n",
      "epoch: 00643 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0501s\n",
      "-------- Epoch 644 --------\n",
      "epoch: 00644 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 645 --------\n",
      "epoch: 00645 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0520s\n",
      "-------- Epoch 646 --------\n",
      "epoch: 00646 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0518s\n",
      "-------- Epoch 647 --------\n",
      "epoch: 00647 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0506s\n",
      "-------- Epoch 648 --------\n",
      "epoch: 00648 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0515s\n",
      "-------- Epoch 649 --------\n",
      "epoch: 00649 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0506s\n",
      "-------- Epoch 650 --------\n",
      "epoch: 00650 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0513s\n",
      "-------- Epoch 651 --------\n",
      "epoch: 00651 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0547s\n",
      "-------- Epoch 652 --------\n",
      "epoch: 00652 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0522s\n",
      "-------- Epoch 653 --------\n",
      "epoch: 00653 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0525s\n",
      "-------- Epoch 654 --------\n",
      "epoch: 00654 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0526s\n",
      "-------- Epoch 655 --------\n",
      "epoch: 00655 loss_train: 0.00003 loss_val: 0.00004 violation_train: 0.00000 violation_val: 0.00000 time: 0.0515s\n",
      "-------- Epoch 656 --------\n",
      "epoch: 00656 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0512s\n",
      "-------- Epoch 657 --------\n",
      "epoch: 00657 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0532s\n",
      "-------- Epoch 658 --------\n",
      "epoch: 00658 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0545s\n",
      "-------- Epoch 659 --------\n",
      "epoch: 00659 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0527s\n",
      "-------- Epoch 660 --------\n",
      "epoch: 00660 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0529s\n",
      "-------- Epoch 661 --------\n",
      "epoch: 00661 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0542s\n",
      "-------- Epoch 662 --------\n",
      "epoch: 00662 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0530s\n",
      "-------- Epoch 663 --------\n",
      "epoch: 00663 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0514s\n",
      "-------- Epoch 664 --------\n",
      "epoch: 00664 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0509s\n",
      "-------- Epoch 665 --------\n",
      "epoch: 00665 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0506s\n",
      "-------- Epoch 666 --------\n",
      "epoch: 00666 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0524s\n",
      "-------- Epoch 667 --------\n",
      "epoch: 00667 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0527s\n",
      "-------- Epoch 668 --------\n",
      "epoch: 00668 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0520s\n",
      "-------- Epoch 669 --------\n",
      "epoch: 00669 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0535s\n",
      "-------- Epoch 670 --------\n",
      "epoch: 00670 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0510s\n",
      "-------- Epoch 671 --------\n",
      "epoch: 00671 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0501s\n",
      "-------- Epoch 672 --------\n",
      "epoch: 00672 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0500s\n",
      "-------- Epoch 673 --------\n",
      "epoch: 00673 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 674 --------\n",
      "epoch: 00674 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0509s\n",
      "-------- Epoch 675 --------\n",
      "epoch: 00675 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0521s\n",
      "-------- Epoch 676 --------\n",
      "epoch: 00676 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0531s\n",
      "-------- Epoch 677 --------\n",
      "epoch: 00677 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0525s\n",
      "-------- Epoch 678 --------\n",
      "epoch: 00678 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0509s\n",
      "-------- Epoch 679 --------\n",
      "epoch: 00679 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0507s\n",
      "-------- Epoch 680 --------\n",
      "epoch: 00680 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 681 --------\n",
      "epoch: 00681 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0497s\n",
      "-------- Epoch 682 --------\n",
      "epoch: 00682 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 683 --------\n",
      "epoch: 00683 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0512s\n",
      "-------- Epoch 684 --------\n",
      "epoch: 00684 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0520s\n",
      "-------- Epoch 685 --------\n",
      "epoch: 00685 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0506s\n",
      "-------- Epoch 686 --------\n",
      "epoch: 00686 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0516s\n",
      "-------- Epoch 687 --------\n",
      "epoch: 00687 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0508s\n",
      "-------- Epoch 688 --------\n",
      "epoch: 00688 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0503s\n",
      "-------- Epoch 689 --------\n",
      "epoch: 00689 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 690 --------\n",
      "epoch: 00690 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0537s\n",
      "-------- Epoch 691 --------\n",
      "epoch: 00691 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0533s\n",
      "-------- Epoch 692 --------\n",
      "epoch: 00692 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0534s\n",
      "-------- Epoch 693 --------\n",
      "epoch: 00693 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0531s\n",
      "-------- Epoch 694 --------\n",
      "epoch: 00694 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0529s\n",
      "-------- Epoch 695 --------\n",
      "epoch: 00695 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0510s\n",
      "-------- Epoch 696 --------\n",
      "epoch: 00696 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 697 --------\n",
      "epoch: 00697 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 698 --------\n",
      "epoch: 00698 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0500s\n",
      "-------- Epoch 699 --------\n",
      "epoch: 00699 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 700 --------\n",
      "epoch: 00700 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0511s\n",
      "-------- Epoch 701 --------\n",
      "epoch: 00701 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0508s\n",
      "-------- Epoch 702 --------\n",
      "epoch: 00702 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0513s\n",
      "-------- Epoch 703 --------\n",
      "epoch: 00703 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0501s\n",
      "-------- Epoch 704 --------\n",
      "epoch: 00704 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0510s\n",
      "-------- Epoch 705 --------\n",
      "epoch: 00705 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 706 --------\n",
      "epoch: 00706 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 707 --------\n",
      "epoch: 00707 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0503s\n",
      "-------- Epoch 708 --------\n",
      "epoch: 00708 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 709 --------\n",
      "epoch: 00709 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0515s\n",
      "-------- Epoch 710 --------\n",
      "epoch: 00710 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0502s\n",
      "-------- Epoch 711 --------\n",
      "epoch: 00711 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 712 --------\n",
      "epoch: 00712 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 713 --------\n",
      "epoch: 00713 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0502s\n",
      "-------- Epoch 714 --------\n",
      "epoch: 00714 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0507s\n",
      "-------- Epoch 715 --------\n",
      "epoch: 00715 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0501s\n",
      "-------- Epoch 716 --------\n",
      "epoch: 00716 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0509s\n",
      "-------- Epoch 717 --------\n",
      "epoch: 00717 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0508s\n",
      "-------- Epoch 718 --------\n",
      "epoch: 00718 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0510s\n",
      "-------- Epoch 719 --------\n",
      "epoch: 00719 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0508s\n",
      "-------- Epoch 720 --------\n",
      "epoch: 00720 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0506s\n",
      "-------- Epoch 721 --------\n",
      "epoch: 00721 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0511s\n",
      "-------- Epoch 722 --------\n",
      "epoch: 00722 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0522s\n",
      "-------- Epoch 723 --------\n",
      "epoch: 00723 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0518s\n",
      "-------- Epoch 724 --------\n",
      "epoch: 00724 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0502s\n",
      "-------- Epoch 725 --------\n",
      "epoch: 00725 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0501s\n",
      "-------- Epoch 726 --------\n",
      "epoch: 00726 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0525s\n",
      "-------- Epoch 727 --------\n",
      "epoch: 00727 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0530s\n",
      "-------- Epoch 728 --------\n",
      "epoch: 00728 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0540s\n",
      "-------- Epoch 729 --------\n",
      "epoch: 00729 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0544s\n",
      "-------- Epoch 730 --------\n",
      "epoch: 00730 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0538s\n",
      "-------- Epoch 731 --------\n",
      "epoch: 00731 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0520s\n",
      "-------- Epoch 732 --------\n",
      "epoch: 00732 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0521s\n",
      "-------- Epoch 733 --------\n",
      "epoch: 00733 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0535s\n",
      "-------- Epoch 734 --------\n",
      "epoch: 00734 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0518s\n",
      "-------- Epoch 735 --------\n",
      "epoch: 00735 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0510s\n",
      "-------- Epoch 736 --------\n",
      "epoch: 00736 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0563s\n",
      "-------- Epoch 737 --------\n",
      "epoch: 00737 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0532s\n",
      "-------- Epoch 738 --------\n",
      "epoch: 00738 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0517s\n",
      "-------- Epoch 739 --------\n",
      "epoch: 00739 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0515s\n",
      "-------- Epoch 740 --------\n",
      "epoch: 00740 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0508s\n",
      "-------- Epoch 741 --------\n",
      "epoch: 00741 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0513s\n",
      "-------- Epoch 742 --------\n",
      "epoch: 00742 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0513s\n",
      "-------- Epoch 743 --------\n",
      "epoch: 00743 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 744 --------\n",
      "epoch: 00744 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0503s\n",
      "-------- Epoch 745 --------\n",
      "epoch: 00745 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0512s\n",
      "-------- Epoch 746 --------\n",
      "epoch: 00746 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0503s\n",
      "-------- Epoch 747 --------\n",
      "epoch: 00747 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0506s\n",
      "-------- Epoch 748 --------\n",
      "epoch: 00748 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 749 --------\n",
      "epoch: 00749 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0542s\n",
      "-------- Epoch 750 --------\n",
      "epoch: 00750 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0571s\n",
      "-------- Epoch 751 --------\n",
      "epoch: 00751 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0575s\n",
      "-------- Epoch 752 --------\n",
      "epoch: 00752 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0532s\n",
      "-------- Epoch 753 --------\n",
      "epoch: 00753 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0514s\n",
      "-------- Epoch 754 --------\n",
      "epoch: 00754 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0510s\n",
      "-------- Epoch 755 --------\n",
      "epoch: 00755 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0520s\n",
      "-------- Epoch 756 --------\n",
      "epoch: 00756 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0514s\n",
      "-------- Epoch 757 --------\n",
      "epoch: 00757 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0512s\n",
      "-------- Epoch 758 --------\n",
      "epoch: 00758 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0506s\n",
      "-------- Epoch 759 --------\n",
      "epoch: 00759 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0544s\n",
      "-------- Epoch 760 --------\n",
      "epoch: 00760 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0508s\n",
      "-------- Epoch 761 --------\n",
      "epoch: 00761 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0501s\n",
      "-------- Epoch 762 --------\n",
      "epoch: 00762 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 763 --------\n",
      "epoch: 00763 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 764 --------\n",
      "epoch: 00764 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0507s\n",
      "-------- Epoch 765 --------\n",
      "epoch: 00765 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0506s\n",
      "-------- Epoch 766 --------\n",
      "epoch: 00766 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0508s\n",
      "-------- Epoch 767 --------\n",
      "epoch: 00767 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 768 --------\n",
      "epoch: 00768 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0523s\n",
      "-------- Epoch 769 --------\n",
      "epoch: 00769 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0519s\n",
      "-------- Epoch 770 --------\n",
      "epoch: 00770 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0524s\n",
      "-------- Epoch 771 --------\n",
      "epoch: 00771 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0531s\n",
      "-------- Epoch 772 --------\n",
      "epoch: 00772 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0523s\n",
      "-------- Epoch 773 --------\n",
      "epoch: 00773 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0519s\n",
      "-------- Epoch 774 --------\n",
      "epoch: 00774 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0512s\n",
      "-------- Epoch 775 --------\n",
      "epoch: 00775 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0513s\n",
      "-------- Epoch 776 --------\n",
      "epoch: 00776 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0502s\n",
      "-------- Epoch 777 --------\n",
      "epoch: 00777 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0506s\n",
      "-------- Epoch 778 --------\n",
      "epoch: 00778 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0506s\n",
      "-------- Epoch 779 --------\n",
      "epoch: 00779 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0503s\n",
      "-------- Epoch 780 --------\n",
      "epoch: 00780 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 781 --------\n",
      "epoch: 00781 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 782 --------\n",
      "epoch: 00782 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 783 --------\n",
      "epoch: 00783 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0506s\n",
      "-------- Epoch 784 --------\n",
      "epoch: 00784 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0508s\n",
      "-------- Epoch 785 --------\n",
      "epoch: 00785 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 786 --------\n",
      "epoch: 00786 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0516s\n",
      "-------- Epoch 787 --------\n",
      "epoch: 00787 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0543s\n",
      "-------- Epoch 788 --------\n",
      "epoch: 00788 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0521s\n",
      "-------- Epoch 789 --------\n",
      "epoch: 00789 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0515s\n",
      "-------- Epoch 790 --------\n",
      "epoch: 00790 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0528s\n",
      "-------- Epoch 791 --------\n",
      "epoch: 00791 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0517s\n",
      "-------- Epoch 792 --------\n",
      "epoch: 00792 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0511s\n",
      "-------- Epoch 793 --------\n",
      "epoch: 00793 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0509s\n",
      "-------- Epoch 794 --------\n",
      "epoch: 00794 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0516s\n",
      "-------- Epoch 795 --------\n",
      "epoch: 00795 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0507s\n",
      "-------- Epoch 796 --------\n",
      "epoch: 00796 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0519s\n",
      "-------- Epoch 797 --------\n",
      "epoch: 00797 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0501s\n",
      "-------- Epoch 798 --------\n",
      "epoch: 00798 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 799 --------\n",
      "epoch: 00799 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0510s\n",
      "-------- Epoch 800 --------\n",
      "epoch: 00800 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0509s\n",
      "-------- Epoch 801 --------\n",
      "epoch: 00801 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0514s\n",
      "-------- Epoch 802 --------\n",
      "epoch: 00802 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0507s\n",
      "-------- Epoch 803 --------\n",
      "epoch: 00803 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0516s\n",
      "-------- Epoch 804 --------\n",
      "epoch: 00804 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0521s\n",
      "-------- Epoch 805 --------\n",
      "epoch: 00805 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0509s\n",
      "-------- Epoch 806 --------\n",
      "epoch: 00806 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 807 --------\n",
      "epoch: 00807 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 808 --------\n",
      "epoch: 00808 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0517s\n",
      "-------- Epoch 809 --------\n",
      "epoch: 00809 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 810 --------\n",
      "epoch: 00810 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0511s\n",
      "-------- Epoch 811 --------\n",
      "epoch: 00811 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0518s\n",
      "-------- Epoch 812 --------\n",
      "epoch: 00812 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0503s\n",
      "-------- Epoch 813 --------\n",
      "epoch: 00813 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0500s\n",
      "-------- Epoch 814 --------\n",
      "epoch: 00814 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 815 --------\n",
      "epoch: 00815 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 816 --------\n",
      "epoch: 00816 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0509s\n",
      "-------- Epoch 817 --------\n",
      "epoch: 00817 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0507s\n",
      "-------- Epoch 818 --------\n",
      "epoch: 00818 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 819 --------\n",
      "epoch: 00819 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 820 --------\n",
      "epoch: 00820 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 821 --------\n",
      "epoch: 00821 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0506s\n",
      "-------- Epoch 822 --------\n",
      "epoch: 00822 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0503s\n",
      "-------- Epoch 823 --------\n",
      "epoch: 00823 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0510s\n",
      "-------- Epoch 824 --------\n",
      "epoch: 00824 loss_train: 0.00003 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0501s\n",
      "-------- Epoch 825 --------\n",
      "epoch: 00825 loss_train: 0.00002 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0503s\n",
      "-------- Epoch 826 --------\n",
      "epoch: 00826 loss_train: 0.00002 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0509s\n",
      "-------- Epoch 827 --------\n",
      "epoch: 00827 loss_train: 0.00002 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0500s\n",
      "-------- Epoch 828 --------\n",
      "epoch: 00828 loss_train: 0.00002 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 829 --------\n",
      "epoch: 00829 loss_train: 0.00002 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 830 --------\n",
      "epoch: 00830 loss_train: 0.00002 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 831 --------\n",
      "epoch: 00831 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0512s\n",
      "-------- Epoch 832 --------\n",
      "epoch: 00832 loss_train: 0.00002 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0501s\n",
      "-------- Epoch 833 --------\n",
      "epoch: 00833 loss_train: 0.00002 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 834 --------\n",
      "epoch: 00834 loss_train: 0.00002 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 835 --------\n",
      "epoch: 00835 loss_train: 0.00002 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 836 --------\n",
      "epoch: 00836 loss_train: 0.00002 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0507s\n",
      "-------- Epoch 837 --------\n",
      "epoch: 00837 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0508s\n",
      "-------- Epoch 838 --------\n",
      "epoch: 00838 loss_train: 0.00002 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 839 --------\n",
      "epoch: 00839 loss_train: 0.00002 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 840 --------\n",
      "epoch: 00840 loss_train: 0.00002 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 841 --------\n",
      "epoch: 00841 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0542s\n",
      "-------- Epoch 842 --------\n",
      "epoch: 00842 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0501s\n",
      "-------- Epoch 843 --------\n",
      "epoch: 00843 loss_train: 0.00002 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0497s\n",
      "-------- Epoch 844 --------\n",
      "epoch: 00844 loss_train: 0.00002 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0497s\n",
      "-------- Epoch 845 --------\n",
      "epoch: 00845 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0496s\n",
      "-------- Epoch 846 --------\n",
      "epoch: 00846 loss_train: 0.00002 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 847 --------\n",
      "epoch: 00847 loss_train: 0.00002 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0500s\n",
      "-------- Epoch 848 --------\n",
      "epoch: 00848 loss_train: 0.00002 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 849 --------\n",
      "epoch: 00849 loss_train: 0.00002 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 850 --------\n",
      "epoch: 00850 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0503s\n",
      "-------- Epoch 851 --------\n",
      "epoch: 00851 loss_train: 0.00002 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0514s\n",
      "-------- Epoch 852 --------\n",
      "epoch: 00852 loss_train: 0.00002 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0501s\n",
      "-------- Epoch 853 --------\n",
      "epoch: 00853 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0525s\n",
      "-------- Epoch 854 --------\n",
      "epoch: 00854 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 855 --------\n",
      "epoch: 00855 loss_train: 0.00002 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0507s\n",
      "-------- Epoch 856 --------\n",
      "epoch: 00856 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0511s\n",
      "-------- Epoch 857 --------\n",
      "epoch: 00857 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 858 --------\n",
      "epoch: 00858 loss_train: 0.00002 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0496s\n",
      "-------- Epoch 859 --------\n",
      "epoch: 00859 loss_train: 0.00002 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0540s\n",
      "-------- Epoch 860 --------\n",
      "epoch: 00860 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0530s\n",
      "-------- Epoch 861 --------\n",
      "epoch: 00861 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0532s\n",
      "-------- Epoch 862 --------\n",
      "epoch: 00862 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0530s\n",
      "-------- Epoch 863 --------\n",
      "epoch: 00863 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0522s\n",
      "-------- Epoch 864 --------\n",
      "epoch: 00864 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0533s\n",
      "-------- Epoch 865 --------\n",
      "epoch: 00865 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0517s\n",
      "-------- Epoch 866 --------\n",
      "epoch: 00866 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0531s\n",
      "-------- Epoch 867 --------\n",
      "epoch: 00867 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0526s\n",
      "-------- Epoch 868 --------\n",
      "epoch: 00868 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0525s\n",
      "-------- Epoch 869 --------\n",
      "epoch: 00869 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0528s\n",
      "-------- Epoch 870 --------\n",
      "epoch: 00870 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0527s\n",
      "-------- Epoch 871 --------\n",
      "epoch: 00871 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0513s\n",
      "-------- Epoch 872 --------\n",
      "epoch: 00872 loss_train: 0.00002 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0516s\n",
      "-------- Epoch 873 --------\n",
      "epoch: 00873 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0500s\n",
      "-------- Epoch 874 --------\n",
      "epoch: 00874 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0521s\n",
      "-------- Epoch 875 --------\n",
      "epoch: 00875 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0520s\n",
      "-------- Epoch 876 --------\n",
      "epoch: 00876 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0510s\n",
      "-------- Epoch 877 --------\n",
      "epoch: 00877 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0502s\n",
      "-------- Epoch 878 --------\n",
      "epoch: 00878 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0502s\n",
      "-------- Epoch 879 --------\n",
      "epoch: 00879 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0501s\n",
      "-------- Epoch 880 --------\n",
      "epoch: 00880 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0507s\n",
      "-------- Epoch 881 --------\n",
      "epoch: 00881 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0513s\n",
      "-------- Epoch 882 --------\n",
      "epoch: 00882 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0510s\n",
      "-------- Epoch 883 --------\n",
      "epoch: 00883 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0517s\n",
      "-------- Epoch 884 --------\n",
      "epoch: 00884 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0521s\n",
      "-------- Epoch 885 --------\n",
      "epoch: 00885 loss_train: 0.00002 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0513s\n",
      "-------- Epoch 886 --------\n",
      "epoch: 00886 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0515s\n",
      "-------- Epoch 887 --------\n",
      "epoch: 00887 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0537s\n",
      "-------- Epoch 888 --------\n",
      "epoch: 00888 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0530s\n",
      "-------- Epoch 889 --------\n",
      "epoch: 00889 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0522s\n",
      "-------- Epoch 890 --------\n",
      "epoch: 00890 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0520s\n",
      "-------- Epoch 891 --------\n",
      "epoch: 00891 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0516s\n",
      "-------- Epoch 892 --------\n",
      "epoch: 00892 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0520s\n",
      "-------- Epoch 893 --------\n",
      "epoch: 00893 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0527s\n",
      "-------- Epoch 894 --------\n",
      "epoch: 00894 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0501s\n",
      "-------- Epoch 895 --------\n",
      "epoch: 00895 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0513s\n",
      "-------- Epoch 896 --------\n",
      "epoch: 00896 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0507s\n",
      "-------- Epoch 897 --------\n",
      "epoch: 00897 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 898 --------\n",
      "epoch: 00898 loss_train: 0.00002 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 899 --------\n",
      "epoch: 00899 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 900 --------\n",
      "epoch: 00900 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0528s\n",
      "-------- Epoch 901 --------\n",
      "epoch: 00901 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0530s\n",
      "-------- Epoch 902 --------\n",
      "epoch: 00902 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0514s\n",
      "-------- Epoch 903 --------\n",
      "epoch: 00903 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 904 --------\n",
      "epoch: 00904 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 905 --------\n",
      "epoch: 00905 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0502s\n",
      "-------- Epoch 906 --------\n",
      "epoch: 00906 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0512s\n",
      "-------- Epoch 907 --------\n",
      "epoch: 00907 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0517s\n",
      "-------- Epoch 908 --------\n",
      "epoch: 00908 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0510s\n",
      "-------- Epoch 909 --------\n",
      "epoch: 00909 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 910 --------\n",
      "epoch: 00910 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 911 --------\n",
      "epoch: 00911 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0509s\n",
      "-------- Epoch 912 --------\n",
      "epoch: 00912 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0500s\n",
      "-------- Epoch 913 --------\n",
      "epoch: 00913 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0514s\n",
      "-------- Epoch 914 --------\n",
      "epoch: 00914 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0506s\n",
      "-------- Epoch 915 --------\n",
      "epoch: 00915 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0509s\n",
      "-------- Epoch 916 --------\n",
      "epoch: 00916 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0498s\n",
      "-------- Epoch 917 --------\n",
      "epoch: 00917 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0512s\n",
      "-------- Epoch 918 --------\n",
      "epoch: 00918 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0542s\n",
      "-------- Epoch 919 --------\n",
      "epoch: 00919 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 920 --------\n",
      "epoch: 00920 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0500s\n",
      "-------- Epoch 921 --------\n",
      "epoch: 00921 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0513s\n",
      "-------- Epoch 922 --------\n",
      "epoch: 00922 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 923 --------\n",
      "epoch: 00923 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0495s\n",
      "-------- Epoch 924 --------\n",
      "epoch: 00924 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0494s\n",
      "-------- Epoch 925 --------\n",
      "epoch: 00925 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0507s\n",
      "-------- Epoch 926 --------\n",
      "epoch: 00926 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0516s\n",
      "-------- Epoch 927 --------\n",
      "epoch: 00927 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0512s\n",
      "-------- Epoch 928 --------\n",
      "epoch: 00928 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 929 --------\n",
      "epoch: 00929 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0500s\n",
      "-------- Epoch 930 --------\n",
      "epoch: 00930 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0516s\n",
      "-------- Epoch 931 --------\n",
      "epoch: 00931 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 932 --------\n",
      "epoch: 00932 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 933 --------\n",
      "epoch: 00933 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0515s\n",
      "-------- Epoch 934 --------\n",
      "epoch: 00934 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0516s\n",
      "-------- Epoch 935 --------\n",
      "epoch: 00935 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0508s\n",
      "-------- Epoch 936 --------\n",
      "epoch: 00936 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0507s\n",
      "-------- Epoch 937 --------\n",
      "epoch: 00937 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0501s\n",
      "-------- Epoch 938 --------\n",
      "epoch: 00938 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0523s\n",
      "-------- Epoch 939 --------\n",
      "epoch: 00939 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0507s\n",
      "-------- Epoch 940 --------\n",
      "epoch: 00940 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 941 --------\n",
      "epoch: 00941 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 942 --------\n",
      "epoch: 00942 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0496s\n",
      "-------- Epoch 943 --------\n",
      "epoch: 00943 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0508s\n",
      "-------- Epoch 944 --------\n",
      "epoch: 00944 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0517s\n",
      "-------- Epoch 945 --------\n",
      "epoch: 00945 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0502s\n",
      "-------- Epoch 946 --------\n",
      "epoch: 00946 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 947 --------\n",
      "epoch: 00947 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0511s\n",
      "-------- Epoch 948 --------\n",
      "epoch: 00948 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0502s\n",
      "-------- Epoch 949 --------\n",
      "epoch: 00949 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0497s\n",
      "-------- Epoch 950 --------\n",
      "epoch: 00950 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0501s\n",
      "-------- Epoch 951 --------\n",
      "epoch: 00951 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0525s\n",
      "-------- Epoch 952 --------\n",
      "epoch: 00952 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0520s\n",
      "-------- Epoch 953 --------\n",
      "epoch: 00953 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0504s\n",
      "-------- Epoch 954 --------\n",
      "epoch: 00954 loss_train: 0.00002 loss_val: 0.00003 violation_train: 0.00000 violation_val: 0.00000 time: 0.0505s\n",
      "-------- Epoch 955 --------\n",
      "epoch: 00955 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0508s\n",
      "-------- Epoch 956 --------\n",
      "epoch: 00956 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0506s\n",
      "-------- Epoch 957 --------\n",
      "epoch: 00957 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0510s\n",
      "-------- Epoch 958 --------\n",
      "epoch: 00958 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0499s\n",
      "-------- Epoch 959 --------\n",
      "epoch: 00959 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0549s\n",
      "-------- Epoch 960 --------\n",
      "epoch: 00960 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0539s\n",
      "-------- Epoch 961 --------\n",
      "epoch: 00961 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0527s\n",
      "-------- Epoch 962 --------\n",
      "epoch: 00962 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0525s\n",
      "-------- Epoch 963 --------\n",
      "epoch: 00963 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0529s\n",
      "-------- Epoch 964 --------\n",
      "epoch: 00964 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0511s\n",
      "-------- Epoch 965 --------\n",
      "epoch: 00965 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0500s\n",
      "-------- Epoch 966 --------\n",
      "epoch: 00966 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0510s\n",
      "-------- Epoch 967 --------\n",
      "epoch: 00967 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0538s\n",
      "-------- Epoch 968 --------\n",
      "epoch: 00968 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0524s\n",
      "-------- Epoch 969 --------\n",
      "epoch: 00969 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0536s\n",
      "-------- Epoch 970 --------\n",
      "epoch: 00970 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0512s\n",
      "-------- Epoch 971 --------\n",
      "epoch: 00971 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0526s\n",
      "-------- Epoch 972 --------\n",
      "epoch: 00972 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0587s\n",
      "-------- Epoch 973 --------\n",
      "epoch: 00973 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0562s\n",
      "-------- Epoch 974 --------\n",
      "epoch: 00974 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0539s\n",
      "-------- Epoch 975 --------\n",
      "epoch: 00975 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0529s\n",
      "-------- Epoch 976 --------\n",
      "epoch: 00976 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0543s\n",
      "-------- Epoch 977 --------\n",
      "epoch: 00977 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0539s\n",
      "-------- Epoch 978 --------\n",
      "epoch: 00978 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.1380s\n",
      "-------- Epoch 979 --------\n",
      "epoch: 00979 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0823s\n",
      "-------- Epoch 980 --------\n",
      "epoch: 00980 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0708s\n",
      "-------- Epoch 981 --------\n",
      "epoch: 00981 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0626s\n",
      "-------- Epoch 982 --------\n",
      "epoch: 00982 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0598s\n",
      "-------- Epoch 983 --------\n",
      "epoch: 00983 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0600s\n",
      "-------- Epoch 984 --------\n",
      "epoch: 00984 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0571s\n",
      "-------- Epoch 985 --------\n",
      "epoch: 00985 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0616s\n",
      "-------- Epoch 986 --------\n",
      "epoch: 00986 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0578s\n",
      "-------- Epoch 987 --------\n",
      "epoch: 00987 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0585s\n",
      "-------- Epoch 988 --------\n",
      "epoch: 00988 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0564s\n",
      "-------- Epoch 989 --------\n",
      "epoch: 00989 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0573s\n",
      "-------- Epoch 990 --------\n",
      "epoch: 00990 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0569s\n",
      "-------- Epoch 991 --------\n",
      "epoch: 00991 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0555s\n",
      "-------- Epoch 992 --------\n",
      "epoch: 00992 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0560s\n",
      "-------- Epoch 993 --------\n",
      "epoch: 00993 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0579s\n",
      "-------- Epoch 994 --------\n",
      "epoch: 00994 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0575s\n",
      "-------- Epoch 995 --------\n",
      "epoch: 00995 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0565s\n",
      "-------- Epoch 996 --------\n",
      "epoch: 00996 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0518s\n",
      "-------- Epoch 997 --------\n",
      "epoch: 00997 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0514s\n",
      "-------- Epoch 998 --------\n",
      "epoch: 00998 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0506s\n",
      "-------- Epoch 999 --------\n",
      "epoch: 00999 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0509s\n",
      "-------- Epoch 1000 --------\n",
      "epoch: 01000 loss_train: 0.00002 loss_val: 0.00002 violation_train: 0.00000 violation_val: 0.00000 time: 0.0500s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 51.9557s\n"
     ]
    }
   ],
   "source": [
    "# only take 1 run here\n",
    "NN_train_losses, NN_val_losses, \\\n",
    "            NN_train_violations, NN_val_violations, \\\n",
    "            NN_model_max = train(NN_model, train_loader, val_loader, nn.MSELoss())\n",
    "\n",
    "PINN_train_losses, PINN_val_losses, \\\n",
    "            PINN_train_violations, PINN_val_violations, \\\n",
    "            PINN_model_max = train(PINN_model, train_loader, val_loader, PINNLoss(A, B, b, eta))\n",
    "\n",
    "NNOPT_train_losses, NNOPT_val_losses, \\\n",
    "            NNOPT_train_violations, NNOPT_val_violations, \\\n",
    "            NNOPT_model_max = train(NNOPT_model, train_loader, val_loader, nn.MSELoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqkAAAEiCAYAAADauUtBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAClxElEQVR4nOydd3hT5ffAPzdJ96SDlkJLWzYUKJQhyN5LUIbAlyFTERUFceEPBUSGExFBRbAoIgiKiqIMZcqSUZC9uoBCaeneGb8/QtOkSdq0tE1b3s/z5GnuO8+96b05Oe95z5E0Go0GgUAgEAgEAoGgEiGztgACgUAgEAgEAkFhhJIqEAgEAoFAIKh0CCVVIBAIBAKBQFDpEEqqQCAQCAQCgaDSIZRUgUAgEAgEAkGlQyipAoFAIBAIBIJKh1BSBQKBQCAQCASVDqGkCgQCgUAgEAgqHUJJFQgEAoFAIBBUOoSSKhAIBAKBQCCodFhdSV25ciVBQUHY29sTFhbGgQMHimy/b98+wsLCsLe3Jzg4mM8//9ygfvXq1XTu3JkaNWpQo0YNevXqxbFjxx54XoFAIBAIBAJBxWFVJXXTpk289NJLvPnmm5w6dYrOnTvTv39/YmJiTLaPjIxkwIABdO7cmVOnTjFnzhxmzJjBjz/+qGuzd+9eRo8ezZ49ezh8+DABAQH06dOHmzdvlnpegUAgEAgEAkHFImk0Go21Jm/fvj2tW7dm1apVurImTZrw+OOPs3jxYqP2r732Gr/++isXLlzQlU2bNo3Tp09z+PBhk3OoVCpq1KjBihUrGD9+fKnmFQgEAoFAIBBULFazpObm5nLixAn69OljUN6nTx8OHTpkss/hw4eN2vft25fjx4+Tl5dnsk9mZiZ5eXl4eHiUel6BQCAQCAQCQcWisNbECQkJqFQqfHx8DMp9fHy4ffu2yT63b9822V6pVJKQkECtWrWM+rz++uvUrl2bXr16lXpegJycHHJycnTHarWae/fu4enpiSRJRZ+sQCCoNGg0GtLS0vDz80Mms7pb/kOHWq3m1q1buLi4iGenQFCFsMaz02pKaj6FH1IajabIB5ep9qbKAd577z2+//579u7di729/QPNu3jxYubPn2+2XiAQVC1iY2OpU6eOtcV46Lh16xb+/v7WFkMgEJSSinx2Wk1J9fLyQi6XG1kv4+Pjjayc+fj6+ppsr1Ao8PT0NCj/4IMPWLRoEbt376ZFixYPNC/AG2+8waxZs3THKSkpBAQEEB0djaura9EnW0p+O3OLOVvPEejhwBePuvLbt0nkpqwCNEwMPo5TUGukG0cBUD+2HJo+Xi5yCATVidTUVOrWrYuLi4u1RXkoyb/usbGxRT47s/NUvL/jIpv+vQFA7Rr2jG1fl6Gt6+Bkp/3qSspOYvsLQ2lzMg0A7yWL8Ojdx+yYFUlyZi437mWgvn2Oq3leaJIiUeZm4xF3AEV2EnkqNZJGSQ/lAeSoy16A4V9D/V6gzAaFPQirteABSU1Nxd/fv0KfnVZTUm1tbQkLC2PXrl088cQTuvJdu3YxZMgQk306dOjAtm3bDMp27txJmzZtsLGx0ZW9//77LFy4kB07dtCmTZsHnhfAzs4OOzs7o3J3d/dyU1KHtHNiwc5oYjLU5Po3xdHuDDJbd9CkI5Pb43b3GNjdf/C4OIO7e7nIIRBUJ/KXqcRSs3XIv+6urq5FPjtdgff/14Hn+mSgAYK8nIzbuLrSf+Um9j89jLbncklZuIBaoa2wq1evnKS3HFdXCPD1gqZ16QRAu/s1T5nto1ZriE/LIelOLPdS07hwOx2PzGt0vvYh6RpHgnIvWS7AtkkGh8rub6HYswAcasC0g+AmVhEEpaMin51WXe6fNWsW48aNo02bNnTo0IEvv/ySmJgYpk2bBmitlzdv3uSbb74BtDv5V6xYwaxZs5g6dSqHDx9mzZo1fP/997ox33vvPebOncuGDRsIDAzUWUydnZ1xdna2aN7Kgou9DV0aeLP7wh1+vxyPpywXSeaERpXOxVRvfB3SCxqLL1yBQFANCTShnBrUe9Yn5sNlRI97jrp387g+cBANDh9CUaNGBUlYdshkEr5u9vi6NQDgUQC6ABPx1munUqm5Ep9GyuWDZCTcpNmVVfhkXy9ybMWeBdo3WUnwcbOCisDO0G4qXPoD2k8D9wBw9CjDsxIISo9VldSRI0eSmJjIggULiIuLIyQkhO3bt1O3bl0A4uLiDGKXBgUFsX37dmbOnMlnn32Gn58fy5cvZ9iwYbo2K1euJDc3l+HDhxvM9fbbbzNv3jyL5q1MDA+rw+4Ld9h2Jo6ZNW3JTLFBA5y4V4dHvaOxkeUvEwklVSAQPJx0CezOmv8bS90XvwXg+swXaPD1t9XWWi6Xy2hcyw1qDbxf8rSuTqXWcD0mljsXD5FyL4EaN/fQPuMv5JiJNhl1QPsCOH3f4NP0cej4Aux6G9JuwehNkJcBNZuC3FYYRQQVhlXjpFZlUlNTcXNzIyUlpdyW+wEycpQ8sugv0nKUzPXxIfnoB6DRWlCfqX8UZ5tcbcMR4dDsCfMDCQQCoOLuXYFpyuv6K9VK5q0YzpiV2iVxpz69CFj+aZmNX5VRq9TcSMri6OVYcq//g+etv2mccZxAyXxEmyKR28Kbd0BEx3iosMaz0+q7+wVF42SnYFyHuqzce40/YhPpbNccZbY2cUGeRv8BIX7ZCgSChxeFTMHzkz/nt8P9efRUNhk7d6POyEDmVLS7wMOATC4jwMuJAK/G0LExMBmlSs3Fu+mcjE7mdEwSztd/o0PGX/SSnSh+QFUuLCjkTtF+GtTtCDlp0PxJUNiWy7kIHi6EkloFGNnWn5V7r3FHUiO3b6tTUpVqPSVVLL8IBIKHHF8nX7zeeA2e1IYLvP7FJ9SfNcfKUlVOFHIZjX1daezryv/aBwAtyVG+ztk76Zy/mcLlm/HcvhmFR/xR5kprsJFURQ949HPtC+CX5wzrhq0Bl1rg4A4+ev6wOelg51yWpyWoZggltQpQ19OJF3s24MtdV5AkO5CcQZNOWp4d3vaZ91sJJVUgEAgebzGKz0ZvpMf3l8j5aj25Q/+HbWCgtcWqEtgp5ITUdiOkthsQALRBrR5G9L15nLuVwvmbKfxzMRafhEP0lk7QUX6O2lJi8QP/OLngvXsAJBfsNaHJY9BoIPy1AAZ+CHXaaCMQyG2MxxE8dAif1FJS0b4Ziek5dFzyNxMTbbG597GufGbjA8gkoMur0OPNcpdDIKjqCJ9U61IR1/9cwln+G/skLaM0KHs8QvOVX5fLPA8rKrWG87dS+f2/OO6kZhOXksW56zdoLMUQJItjsOwQbWSXsZdMpyu3GLkd1OsBdcJAo4FOs+DSdqjVEjIStOWCCkP4pArM4ulsx4g2dbi7+zZ+euV5ajl2chXsf08oqVWEwMBA7O3tOXv2LAqF9hZs06YNH3zwAXv37mX+/Pns37+fzp07A7BixQqOHz9OeHi42THDw8Pp2LEjDRs2LJVMoaGhHD58GAcHh1L1FwgqE828Qtg6tiMtF/6D4u8jZP13FofmIdYWq9ogl0k0r+NG8zpuujKVWkPMvUyu3EkjNiOX768mcCMpi9OxyfiSiLuUQXdZBA1kNxgqP2jZRKocuPyH9gWw513jNq2fgtbjtZu5bBzAIxg0akiK0iYxcBfZzaoyQkmtQkzpFMz8vXH4SQ6gyQJAqZFhRzG+QoJKR05ODmvWrOGZZ54xqgsMDOS1117j0KFDFo8XHh6Ol5eXWSVVpVIhl8vN9o+IiLB4LoGgKvDkwFeJWP84zaM0RL/zNo1/+NHaIlVr5DKJIC8nXdKF0e0CdHUpmXnEpWZxInoAUSnZBP59lbqejkQnZmJHLnWku4RIkXhJKchRM1a+mwDZXcsmPrlO+7JISFtoO1XrciBJEDZRq9DK5FpL7e0zkJkIDftqj8VeD6sjlNQqRKCXEw0aeiBPrI8q9z9Aa0mFB1xSeUjQaDRk5ZWvQu9gI7coNuP8+fOZM2cO48aNw9HR0aBu6NCh7Nmzh61btxpkRTPHV199xfHjx5kxYwb/93//x6JFi4iPj2fjxo3UrFmT8+fP8+mnn3L48GG+//57lEolNjY2fPrpp7Rv3x7QZhBJS0vD2dmZwMBAJk6cyI4dO4iLi2Py5Mn83//9X+kuiEBgJRrWaMjGkW1pvvQY6v/Okxcfj03NmtYW66HEzdEGN0cbGvtql4hn9Wmkq0vPUfLfjRTO3UpBo4EbSZl8mvssf5y9Ta5KjUqZR2MphjDZZVI1TnhLyfhJiUxU7Ci5IKpcOPJZwfEfr5pu12ggXPpd+75GENRsAr3f0fa3dQQbJ62VV24Htk5aC27+c/9WBDj7gGutkstXGYk7DXuXaC3UeeYNHeWFUFKrGCN712P7qbY6JfVKmidtPW9qK1NuQm4G/LsaOs0EV78iRnr4yMpT0fStUjzYSsD5BX1xtC3+tmrdujVdunTh448/5s03Dd00JEliyZIlvPjiiwwePLjYsaZMmcL69euZPXs2gwYNArSW1YMHD3Lq1CkaNNBmr6lfvz6zZs0C4MiRI0yePJmzZ8+aHDM5OZlDhw5x9+5d6tevz8SJE6ldu3axsggElYnefadx+dtjNLwFd7dswm/6C9YWSVAIZzsFHep50qGep0H5+yNaAtpUsXfTc7gQl0patpI9l+L5KyaZb6XpZOQouZOagxPalcU60l0aSzFk4EBn2RmekB/EVcoquVD5CipAUqT2dWl7ycbo9gY0HQL2bpAUDXmZ4FkP/n4Xog9pj3svgNbj4Mou+OEpCOwE/RZr21mCSgnX/oKrf0GD3tpXfrkyC2ydtZZhuS1snqBt2/3/4PoeeHwl1AjUtr97GXJStZvWLm6Hn56G3DTj+XIqfguTUFKrGIFBbqBw1x3vjw8uUFLXPab9h8xOhvgLMOE3q8gosIyFCxfSvn17k+l4+/TpQ+3atVm7dm2px+/UqZNOQQU4deoU7777LomJiSgUCs6fP09ubi62tsbxDMeMGQOAt7c3wcHBREZGCiVVUOV4pNYjLGlbk4a/xBP//XpqPft8tc1CVV2RySR8XO3xcbUH4LGWhsaX/L3fKrWGf6OS2HX+DplJmST5jWJlnpod526TnqPETiHjVlIGNUnCU0qjh+wkgbLbxGpq0kSKoa/8eNkKvnex9lUUvz6vfeVzZYf2BWDrAj3nar/LY46Ad0M4/wu41wWZAoK6gCoPItZr2x/7Qpsl7FAxCSz2LNT+/aQlBHfXKqyVGKGkVjHkChletZy4dc9E5b1rBe9vWhCQ+SHDwUbO+QV9y30OSwkODmb06NEsXLjQZP3SpUsZMmQIM2bMKJUszs4F8Qdzc3MZNmwYe/fuJSwsTLdL05ySam9vr3svl8tRKpWlkkEgsCaSJFF/zFSyt7+L/d1UMs+cxqllqLXFEpQh+T86FHLJpEX29f6Nde81Gg1KtQa1RsOVO+ncTslGkavkQNQ9njkSgyEa6km3yENBT9lJ/KREBssP4SMll/MZ3Sc3zdAd4e4F7d/kaO1f/e/7fIpTUAtjgYIaqfYhAweiND4sz+kDvFKyOR4QoaRWQTxrOxN30Q+N6hZ1nZJMN5KJj7YwkiRZtBRfkcydO5emTZtiY2McEzAsLIxOnTqxatUqunbtWuQ4rq6upKSkmK3Pzs4mLy8Pf3/tTtdPPxXpIgUPBwObDGVr8Hu0vpTH1WVLaPn1RmuLJLASkiRhI9cqtQXxYGFIaG0WPt7cZB+VWoNMmkiuSs2FuDSi8lSsPxrDrvO36d6oJnEp2dRW3cBdkcuBJC9aZexH5lqLvNR4OsjO00F2jjfyptJedoFe8hPsV7dghHxfxSm7wF2NKxfUdfGVtNathrKb3NR4GsW4VWskNMALeS+wRx1KFvYEeTkRmZBxvz6z8NDlTuX6xhZYhGdtJxT2rcnLuEV0Rg2OJ9amTf6Sfz5CSa0SeHt7M2PGDN566y2T9e+++y5NmjQpdpynn36al19+mffff59FixYZ1bu6urJgwQLatWtHQECARb6uAkF1wNHGkZQR3WHhTmwPn0aVno7cWWQ5EliGXKZVau0UckL93QFoH+xZRI/+gNZqm5KVR1q2km9c7chTaVCpNUySSySm57Lrdhq7zt/mfFwqccnZ5CjVpOcoCZTicHN1xzvtPA0cM6iZHcl/6iDspTxqS3fJ1NgzRbGdaI0PURofAA6oWuAppdBWdplT6nrc1Hjxi7oToN3PVZJo+HKZRNeG3sxt4sPA5rVwcywwoKSmpuK2zPKxygIRzL+UWDMgeNR/Cfy67Dfy0rfoyl5ucsCwkVNNeOVKhcolEFQFRDB/62KN63/67mmSB42iZgo4TZtEwEsVu2QpEDwIeSo1mbkqcpQqjly/R2J6Di3quLHv0l1CarvhYm/DndRsWtRxw93RlowcJb5u9tjIZcUPXgJEMH+BRXjWdkaSDIOuf+PxAuPv6S3hipRyAoFAAEBL75a838OPQVtvkfH5WpLrBOE+fLi1xRIILMJGLsPNQQbYMFhv41hYXQ+T7T2cjPcZVFXKVs0WVAjONeywc3IxKPvsViPDRul3KlAiQUWwfft2QkNDjV6bNm2ytmgCQaXHechjuvdx8xdYURKBQGApwpJaBZEkCe8AXzISG6LOu6wtK7z7Wq2EqH8g8FErSCgoDwYMGMCAAQOsLYZAUCUZ1GwY6XyhPcgTCVAEgqqAsKRWUTz9tJun8nHKSTVuFD4A3vXTKqsCgUDwEOPv4s+qiT6649wbN6wojUAgsAShpFZRvPxdtDmH7zMgfhdvpf/PuGFehlZZFQgEgoec0AHjuHt/v0fGP+LHu0BQ2RFKahXFy98ZJMOPLztRxXfKnqY7nP2pZHEoBAKBoJoxotGTHGmm9XK7ffKQlaURCATFIZTUKoqHnxMyG8P0cF4uDrypnGy6w5aJcPF303UCgUBgIbGxsXTr1o2mTZvSokULNm/ebG2RLMbF1gXHZiEAqH/bZWVpBAJBcQgltYqisJHjUcvJoKyWuzaVpVJj5mO9Wca5iQUCwUOHQqFg2bJlnD9/nt27dzNz5kwyMjKsLZbF1O3QBwCZSkPS999bWRqBQFAUQkmtwnj5G2ZNsbeRM7R1bXrlvs8X9iYsqiILVaUgMDCQxo0bo9SLyNCmTRv27t3LvHnzkCSJAwcKkjOsWLGCCRMmlLkc4eHhDBexIgUlpFatWoSGhgJQs2ZNPDw8uHfvnnWFKgH+DVrp3t+ev4DMkyetKI1AICgKoaRWYbzquBQqkXh7UDPu2tRhSXJ34w7y6hPgt1RoNJCbUb4vC/1+c3JyWLNmjcm6wMBAXnvttbI8c8FDxP79+3nsscfw8/NDkiR+/vlnozYrV64kKCgIe3t7wsLCDH4UlYTjx4+jVqvx9/d/QKkrjhCvELb0LXh2pmzdakVpBAJBUQjTWhWmsCUVwM3RhhFt/Ak/FGXcIeoARB+Cxz6BGnXLX8DKRl4mLPIrvt2DMOcW2DoV22z+/PnMmTOHcePG4ejoaFA3dOhQ9uzZw9atW3niiSeKHevgwYM8++yz/Pfff7qyrl278vLLLzNgwAAGDhxIYmIiWVlZhIaGsnr1aqM5BdWHjIwMWrZsycSJExk2bJhR/aZNm3jppZdYuXIljz76KF988QX9+/fn/PnzBAQEABAWFkZOTo5R3507d+Lnp72HEhMTGT9+PF999VX5nlAZo5ApaBAUBuwFIH1/6RR0gUBQ/ggltQrjVccZuV0bVDlaX1Pl/QDVM3o2MK2kRu7X/t06DSb9UUFSCkzRunVrunTpwscff8ybb75pUCdJEkuWLOHFF19k8ODBxY7VqVMncnNzOX78OG3atOH69etcvnyZAQMGIJfL2bBhA56enmg0GqZPn87KlSuZPXt2eZ2awMr079+f/v37m63/6KOPmDx5MlOmTAFg2bJl7Nixg1WrVrF48WIATpw4UeQcOTk5PPHEE7zxxht07Nix2Lb6Cm9qqjams1qtRq1Wm+tWroQ17I7yvpKqvHMHVXY2ku1DvtIkEBSDNe5XoaRWYRycbXH360VipFZJvXXpPKDN2zu+Q12mH53BStvlxh2TIitSzMqDjaPW0lnec1jIwoULad++PdOmTTOq69OnD7Vr12bt2rUWjTVhwgTCw8Np06YN4eHhjBkzBoVCgVqt5uOPP+b3339HqVSSkpJCly5dLJZRUL3Izc3lxIkTvP766wblffr04dAhy0IyaTQaJkyYQI8ePRg3blyx7RcvXsz8+fONymNjY3FxKeyyVDEogluQYQN29xNPxVy8iOTubhVZBIKqQlpaWoXPKZTUKo63vwuJJnTOWb0bMveomV89eVnlK1RlRZIsWoqvKIKDgxk9ejQLFy40Wb906VKGDBnCjBkzih1r/PjxtGrVig8++IB169axfft2ADZs2MC+ffvYv38/Li4uLF++nP3795fpeQiqDgkJCahUKnx8fAzKfXx8uH37tkVj/PPPP2zatIkWLVro/F2//fZbmjdvbrL9G2+8waxZs3THqamp+Pv74+/vj6ura+lOpAzoNbcWn70VB4BXaipOLVpYTRaBoCqQvwpSkQgltYrj5e+CJK+JRhVvUO7uaItX2BD4b4VxJ6Wxr5nAOsydO5emTZtiY2NjVBcWFkanTp1YtWoVXbt2LXKc2rVr06ZNG1566SV8fX1p1qwZAElJSXh6euLi4kJaWhrh4eEEBweXy7kIqg6SJBkcazQaozJzdOrUqUTLfnZ2dtjZ2RmVy2QyZDLr7d39X5P/AR8CcOPpZ3Dq1ImAr1ZbTR6BoLJjjftV7O6v4njVccbGsY/JupkDW9Eib51xhTK7nKUSWIq3tzczZswgLi7OZP27777LzZs3LRpr4sSJfPHFF0ycOFFXNn78eNLT02natClDhw6lc+fOZSK3oGri5eWFXC43sprGx8cbWVerO4OCBxkcZxw8aCVJBAKBOSSNRuTKLA2pqam4ubmRkpJi1SWrlLtZfDPnT3JTteGM6rZoxbA5C3RWkZd/OE3P/2YzQH7MsOO8lIoWVSCoFFSWe7cikCSJrVu38vjjj+vK2rdvT1hYGCtXrtSVNW3alCFDhug2TpUnlen6bx3Zkcank3THjc+fQ7KidVcgqMxY494Vd2MVx9XTHlv7gl2p0WdOkZ2Rrjt+c2ATXlM9aw3RBAKBFUhPTyciIoKIiAgAIiMjiYiIICYmBoBZs2bx1VdfsXbtWi5cuMDMmTOJiYkxuYGvuhP1/GMGx5psscokEFQmhJJaxZFkEh613QzKlHrhXjycbBnXpSmn1PUNOypzK0I8QRmyfft2QkNDjV6bNm2ytmiCSsTx48dp1aoVrVppMyvNmjWLVq1a8dZbbwEwcuRIli1bxoIFCwgNDWX//v1s376dunUfvtjJk9s/x6wpct2xOush3VQqEFRSxMapaoB3gDsxpwqO8woF4Z7aOZgLh+wNOy30Fkv+VYwBAwYwYMAAa4shqOR069aN4ry4pk+fzvTp0ytIosqLq60rN7wlchRgpwRVZiYyFxcSVq7EuWtXHFu1Kn4QgUBQbghLajXAO8Dd4FiZa6ik1nCyJTb0JeOO534uN5kEAoGgqpB932PqysavuPd1OImff0H06P9ZVyiBQCCU1OpAzQDD5f48E35VQ7qZyAqz+anyEkkgEAiqBLuG7+Lu/T0g8jU/cPfjj60rkECgR97NmyR8/jmq5GRri2IVhJJaDahRyzDLUV6OsZJq71Gbf5vNNe6szIWsJONygUAgeAjwdfIlMtC++IYCgRWIGjWau8s+4db//Z+1RbEKQkmtBihs5Ni7NtYdZ6ebTl3WdPBLDFJ8YVj4aWtYGgippuN0CgQCQXWnU1otk+XKJPEDXmBdlHfvApB55KiVJbEOQkmtJtRvO1r3Pu1eosk2TnYKpg/pyj+qZgWFKbHav5f/KE/xBHoEBgbSuHFjQkNDadq0KZ999hlRUVF4eXkZtVEqlbqyNm3asHfvXgDmzZuHJEkcOHBAV79ixQomTJhQ5Nzh4eFcvny51LKHhoaSJXZAC6oZdbr1N1l+pUNH8swk2hAIqguq5ORiN1taC6GkVhN8gr2R24UBkJmSbLZdv2a+zHedb1xh61JOkglMsWXLFiIiItixYwdvvvmmyZzIOTk5rFmzxuwYgYGBvPbaayWatzglVaVSFdk/IiICBweHEs0pEFR2vJ55xmxd+r59FShJyUjauIn4j6qnD21uTAxRY8eSvn+/tUWxiLsrVxI1dizqKhZrN3XHTi4/0oH4pe9ZWxSTCCW1muDl74IkabeoZqenm20nk0mM69yQzcouhhU/TYHcjPIU0epoNBoy8zLL9VXSX6P+/v40bNiQnTt3GtXNnz+fd955h8zMTJN9hw4dSnZ2Nlu3brVorq+++orjx48zY8YMQkND2b59O+Hh4fTr14/x48fTpk0bjh07xkcffUTbtm1p1aoV7dq14+jRgmUmSZJIv///FRgYyPz58+nYsSNBQUEsXLiwROcuEFQWZLa2pI/uZ7JOlZxCwuefk3frVgVLVTy3580j8csvyTp3ztqilDm3XnudrOMniH3a/A+IykTC8k/JOn6ClF9/LZ8J7meRLGvuLF0CwL3w8HIZ/0ERcVKrCV51nOG+knp2z05cPD3pOGKMybaj2vrz6q/NGEGhX6g3T0BQF5N9qgNZyizab2hfrnMc/d9RHG0ci294n//++4+LFy8yZMgQlixZYlDXunVrunTpwscff8ybb75p1FeSJJYsWcKLL77I4MGDi51rypQprF+/ntmzZzNokDZveXh4OAcPHuTUqVM0aNAAgPr16zNr1iwAjhw5wuTJkzl79qzJMZOTkzl06BB3796lfv36TJw4kdq1a1t8/gJBZaHOy6+S/P2fRuV3ly0DIHnrVurv2FHuctz75lsSv/6auuFfY2thggV1etUyMKhzcpBsbXXpu02hNOO2VtnR6LloVQkq5yq/DmFJrSbYO9ng6mWnOz685XuzbW3kMsY98yqvKgv9QpXZlJd4gkIMHz6c0NBQnnnmGdauXYuNjelrv3DhQpYtW0ZioukHdp8+fahduzZr164ttSydOnXSKagAp06domvXroSEhDBt2jTOnz9Pbq7pDGVjxmh/CHl7exMcHExkZGSp5RAIrImPk0+R9XnRMRUix51Fi1DGxXFn8ZLiG+dTPkY2IzQazQP7LubdiedSy1BuzphRZDupok6qjJFkBWrV3eXLuT54CKoiVjfLmoSsBNQadYXNV94IS2o1wt7J8l9wret6sKL+CIjS2+3//UgI7AyPvgj+7cpBQuvioHDg6P/Kd4ekg8Iyf80tW7YQEhKiO46KijLZLjg4mNGjRxe5lL506VKGDBnCjGIe+uZwdnbWvc/NzWXYsGHs3buXsLAwUlNTcXNzIzc3F1tbW6O+9vYFoXvkcrnBRi+BoCohk2TwyTx4cd4Dj5X577/cWbIU37ffwqFFi1KNoTHzw9AU+opReTJr7yyup1xny2NbsJGXzqiRsvUnANJ27S5L0SoPUsFnkbByFQDJGzfiOWVKuU99JO4IU3dOpXfd3nzU7SPLOlXy3wLCklqNaNK5r8FxejHLJdO71WN63osFBdkpcPE3WNNbGz+1miFJEo42juX6Kmr5qrTMnTuX9evXc8uMT1xYWBidOnVi1apVxY7l6upKSor5dLjZ2dnk5eXh7+8PwKefflo6oQWCKkiTviPLZJzocePJPneO6AkTSz1GxqFD3F60yGy9gUWznPwVC7M7ZjfXU65z/M7x8p+sgs4pn7S//yZq9P/IjTFtMdcolWSdPo0mL6/ogWTGcleUC8DXZ7/GRqlhV/SuCpmvIrC6krpy5UqCgoKwt7cnLCzMIKSOKfbt20dYWBj29vYEBwfz+eefG9SfO3eOYcOGERgYiCRJLLvvT6RPfvge/Zevr29ZnpZVCGwRZHC84f9mF9m+TaAHbmHDTVem3iwrsQQPiLe3NzNmzCCuiFA47777LjdvFv+ZPf300yxYsEC3caowrq6uLFiwgHbt2tGlSxfs7OxMjCIQPJzcfncRmf/+a3F7TWYmmmIiZhRF0jffmq/UH7ccFbq8W7dIL/S9rHkgR8aSy5oVEUH02HFknS2/DWI3pj9H1qlTxM0x9v8HuLP0PaJGjuL2O0VvEC03q7YFn3HNmDS+e1/F2L9L/z9X2bDqcv+mTZt46aWXWLlyJY8++ihffPEF/fv35/z58wQEBBi1j4yMZMCAAUydOpX169fzzz//MH36dLy9vRk2bBgAmZmZBAcHM2LECGbOnGl27mbNmrF7d8Fyg1wuL/sTrGDcvAyXmtMS7xbb59mu9eGMiYrMe+ARZKJC8KCYWtoPDAwkISHBbJu5c+cyd25BxrB58+YZ1NerV8+s36g+gwYN0m2ayqdwbNVXX32VV199VXc8e3bBjx19601hGY8frwDrikBgRZK+/Zakb7/F/8svSNq4iVrz5yE5OCJ3djLbJ3X7H7g9NshsfWnRqPX9DstPSb3aoycA/qtX601ebtOZJGqUNg54zIQJNDpu+Y+EolClp5Nz+QoOrUINVsBUZkI4Jn2r/cGQ/MMP1FpgIoxjPpL1bH+dftHuCRh8tAQfkNg4ZZ6PPvqIyZMnM2XKFJo0acKyZcvw9/c3u2z5+eefExAQwLJly2jSpAlTpkxh0qRJfPDBB7o2bdu25f3332fUqFFFWoEUCgW+vr66l7e3d5mfX0UjmVhmKI4AT0eel5lIt5ZRvIIrEAgE1Q3/L78otk3s08+Q/vffXOnchctt2pBz7Rq5MTEkrv0adaGQceWWDEBfSZUg+8IF1Bml2+VvyYao2KlTC6amAjbmmLAcqstwA1LU8BFE/+9/pP72W+GJH2hcSW5KraoY1wWZ2jKNU6NUcu+bb8m+dKmcJXpwrKak5ubmcuLECfr06WNQ3qdPHw4dOmSyz+HDh43a9+3bl+PHj5NXnJ9IIa5cuYKfnx9BQUGMGjWK69evl+wEKim1m/QocZ8Xn5nGr6oOhoU5plOrCio/27dvJzQ01Oi1adMma4smEFR6nLt0wbFt2xL1uffNt1x/bDDx771H/IeGG1ZSfvyRjPJIaam33J++fz+RTwwlcpgZ960i0Gg0xD79DFEjRxWyzhbdp6qTe38lKKWwkvqgrhMlWO5X3rv3wNcy98YNbrw0k6z//kOycKikTZu4s2gRkUMef6C5KwKrLfcnJCSgUqnw8TEM++Hj48Pt27dN9rl9+7bJ9kqlkoSEBGrVMp1/uTDt27fnm2++oWHDhty5c4eFCxfSsWNHzp07h6enp8k+OTk55OTk6I7zMwSp1WrUFt7YFUHYY6O5eeFv3bElstXzduJkcD+IPlxQ+NMU1HXagmttpD0L0dTtBPV7lofIgjKmX79+9OtnOjB5ZfpftRbiGgiKo8aYMSXyPUUCzf3vh6TvvjOoyo2OJmbCBHzmzMG1fz8UZbRqp69Qpt73L89XvFTJyUSOeBLXfv2o+fKsogdSq8m473OaGxWFXXCw2abP/6riSm0JTc8CbShbmU2mMhMPew/LBC9CCVQlJxP77HTchgwpEz/brLPnkLu7Y1uniNjNhZXEUsxroNxbuNyftns3N55/AffRo6j19tslnjOfmy++RPa5c6T9+SfyQMsyR2afO1/q+Soaq4egKrwbWqPRFLlD2lR7U+VF0b9/QZ7m5s2b06FDB+rVq8e6det0QcwLs3jxYubPN/ZDiY2NxcWl8qQUzZMbWpRjzOxULExIx4FkRy3EXiroL33amsRH3sDr8DKkf5YRNeF0mcoqEFiDtDSxSiAoGqcOj5T5mHcWLSLlt98I+kG7oqHRaMjIy8DZ1rmYnmbQs6QWjil677vvyIuNJXH16uKV1BJs7OpyTkOXcxriXylQ7N55pSPRrjl88vp+PB1MG3kMKOK7OmHV52SdOkXWqVPY1qtntl2WMot9N/bR0a8jrrauJtvk3rhB1HCtZbnJxQvm5Smko2apssy3NYf+Z2Gh211+Otvk7zdapqSauG7Ke/fI1ss2JqmMTanJP/5E2u7d1P7wA2SO9xPNlMI10FpYTUn18vJCLpcbWU3j4+ONrKX5+Pr6mmyvUCjMWkAtwcnJiebNm3PlyhWzbd544w0DBTY1NRV/f3/8/f1xdTV9k1gDjb+Gv117kJOqtaa6Ozrg6mXZL/fVHf7kmSMF1lJJo8LrcMFORlOb2QSCqkb+KohAYA65mxuBm38gasSTZTpu9pmCXaqLji5i46WNrOu3jtY+rc320eTlEfvMM9i3bEnNFwtCBha5NG+hb6Ly3r0CxQXQ953UqFRIZjYU58dwzYqIYOwfWqUuYnIEPQNMr7al7tyJzN4e5y7GGQ03X97MmbtnmNdhHqp0y35ALj22lB+v/Ehb37as7buW3NhYlHfu4Nimja5N9oUiFFODkzG8VtFpMTSzrGfBEPqKvoXL/ZKiQP3SqFSkbN2KQ1gYdkGmNyybCtAfPfp/BscyEx973P1shbfCv6JG63Yo79wpl1CJ5YXVlFRbW1vCwsLYtWsXTzzxhK58165dDBkyxGSfDh06sG3bNoOynTt30qZNG7MZeywhJyeHCxcu0LlzZ7Nt7OzsTG7EkslkyCookLKl+ASHEhOhVVJ3fbGcEXPftajfxF6teeqfN1knN92+sp2nQFAaxP+xwBIcmje3vHEpvvQ3XtoIwGcRn7Gm7xqz7dL+3kPGocNkHDpsoKTqW++MQkJZYClL37eP2Gem4TqgYGUx4+BBbIMCufd1OAkrVlB3vekQWNK9FKhnuClMZmaLiyo1lZsztHI3Oh1hVL/g8AIAOtfuTIgFunX6gQPsP/0TTx9Usb3NMegL13pr96oE/fIz9o0aaRuaUNRzrl4l58oVkh/VU0MLKful8RDVKPXDgcl448AbJGUn8aKZ9qm7dpFz+bLuOHnzFm7fj9hizuqbmZdpVJYbHW1wXNTGqX0XttN6uXZTukNr8z+KKhtWfVrPmjWLr776irVr13LhwgVmzpxJTEwM06ZNA7TWy/Hjx+vaT5s2jejoaGbNmsWFCxdYu3Yta9asMQiRk5ubS0REBBEREeTm5nLz5k0iIiK4evWqrs3s2bPZt28fkZGRHD16lOHDh5OamspTTz1VcSdfjvgEFvjmxpy1fIneViGj18CRrFQWnwdeIBAIBFryCikLRZFvEXPI1iBTa5BLRYc/1OTmmC7XV0gKKSfmLKD63F3xGaANkZXPnUWLSN+3j/j33kOdmUmcCRc30AtOr6ecywr5Yt7NvIsyPZ3o+6mTAZTx8WblSclNMfYPNUHs1Kf5bEUevSI0LA43dFWIOvaXnpDGlsfrgx7j5sxZvPFhf6M6HaUxMqoNY9b+dv03/rn1j0GZPjdfMMwOmHXqZPFTaFRo1GruffMtWf/9Z7KNqeX+fGLTYnXvi/ocKhtWVVJHjhzJsmXLdMHF9+/fz/bt26lbty4AcXFxBj6VQUFBbN++nb179xIaGso777zD8uXLdTFSAW7dukWrVq1o1aoVcXFxfPDBB7Rq1YopeinJbty4wejRo2nUqBFDhw7F1taWI0eO6Oat6tRqUODA7lTDQmf2+zwe6sdh+05lLZJAIBBUWzIOHS6+0X1WRqxEee8e6z5WseRrFXJZcQplgYKTGxXFrTff1G6Q0leM9KyBGo3Gos075hTZtB07Cw7yzGRKMuFqoK+k/hn1Jz029+DHdyeSc6XAQHT2wn6UGtNjajQaQyXVAmXRrtBQt9L0EproyVjYChl0x2BmzB9Zhv5yv6ZUK+mWdUrd/gd3Fi0iasST5MbGGtUXZUk1WOLXC5OlLK8QaWWE1de9pk+fTlRUFDk5OZw4cYIuej4r4eHh7N2716B9165dOXnyJDk5OURGRuqsrvkEBgbqYr7pv/TH2bhxI7du3dJZWn/88UeaNm1anqdZodQN8URuFwqAq3fJMmm52NvweP+B5GqqfnKDykpgYCCNGzcmNDSUpk2b8tlnnxEVFYWXl5dRG6VeOr02bdro/o/zs6bpZ2hbsWKFUWD+siA8PJzhw0se2kYgqOoE/fILns9Ow7YMDRi//f05Gf9owywGxmNgSS0uHFH0hImk/PgTMVOmolHpK6YF7y82acrdjz8ucpyc69fJzTW9QShp/56Ccc2FdryvAOrLq68EfXZKa6WNvmmYISoq4QrXUwvCPRqdbynCMelnoVLfV9yVSUmo9HzP/7m82yAmqFpPX9OoTSup/97+ly/PfGnSF/T03dNEpkQWFOg9p9WlU3N177JitVZ5TW4uSrXSoEWOnitAvouDPlIRSqqcgv8zqZgfRhWVxtUSrL67X1D22NorcK3ZmKTYCLJSSx7ceWjr2oz4azVbMieVg3TWQ6PRoMkqxc7NEiA5OFjklL5lyxZCQkKIjY2lefPmJv2hc3JyWLNmDc8884zJMQIDA3nttdfMxhUWCAQPhn2jhtg3aohd/frcernoNNOW8vFqFVkTCxQrG1XB8+KmiegyyrsFiVWU9zcO5924wYoTn6BbtLZwoxRAxqFDxEyabLY+JTuZGvff55jZTKw2oaTq+6TmPwMLx+10S8ymxpqCuKTJOckFY2rUZF8p8NPMVGZZpKBE6f2A1qjVqHNyuNKho0Eb3xc+IPJWwXUMvKMnmFEIKu2fSTu033/2cnvc7d1poNdk7PaxAPz3lHbZXV+p02hMREsogc9yVO9+3OzSEL+DV/h8gIJn9eoMfF9NYn4emV6dpDCtpJ68c5Jvti3kmQ+0ynC93buwrVOHc4nn+PL0l0xuYP7/prwQSmo1xcOvBkmxkJ1h7GxdHJIksXLaQDI/tMNR0vOH0mjKNUd0eaPJyuJS67BynaPRyRNIBrtli8bf35+GDRuyc+dOo7r58+czZ84cxo0bh6OJMYcOHcqePXvYunWrweZDcxw8eJBnn32W//T8mbp27crLL7/MgAEDGDhwIImJiWRlZREaGsrq1atNzisQPGy4DRyIXVAQkUOHFd/YApK+Dte9d8wqUDzS/vjTqG38e++ZHOPPa9t1SqpaZbnlK/mXX4ust+gJf9+6qG81lEworIV3m/t99ovBsUpPobO/GEPO+QJL4a2MW5Q0noxGo0Z5N8GoXHHLMINi5/PmldT8IxulhjyFxPvH3wfgB702S75WcsNTgvvbWFSpBVEJLideYsQBFc4lsIcUtijX3q9V1ocdMLRka9SWhwsrjI2m4EdEijIDexNtnvrzKeZuLpjjwszpBH23nlG/jQIgKj6q1POXFqsv9wvKB99g7TJ/dloCf4d/QfSZiBL1r+lqz1FZqGFhvIUhPQQW899//3Hx4kWTES1at25Nly5d+NjM0p0kSSxZsoQ5c+agsiDWYadOncjNzeX48eMAXL9+ncuXLzNgwADkcjkbNmzg+PHjnD17FldXV1auXPlgJycQVCPsmzbF8ZGyj5/qkAMZR4+RYCYduDk80goUm4xc8+lC9ZeM7ybdZFeU8Q9iAywwyuaHv9JXMvMV0itJV7iWcg0wtqQWhdu/l4tvZIFcqqR7JeoTmRLJwiMFoRY1EuRcj+S791VM/dP0czX4tjZmbD7q1BTd+4SMeEYc1ND/hOHJqzMyiBo7lkS9HyjFUbNgWDQSqJKSLe5bGIWes+ytLMv8UBNuXuHZ3c/inawh7Iqa+Iw7xXcqY4QltZpSNySYf1AASk79sY1Tf2zj5U2FcxQXTciUz2F1q4KCVR3AtwV4BEO7pyHw0bIVupyRHBxodPJEuc9hCcOHD8fe3h5HR0fWrl1rNoTawoULad++vZHvdT59+vShdu3arF271qJ5J0yYQHh4OG3atCE8PJwxY8agUChQq9V8/PHH/P777yiVSlJSUgz8wwUCAfh/+QWXWrUuUQD84gg8E0/MWyWPLPP293o+qUXETE3LTaOGfQ3ybt8moVsv2pdKykLcn0/fX1OmhqTsJIb+OtSgrMhh9PqrTPh+lhS72PgSx7ZNzLzLpkub0LeRJ361GoDepzSsNp28T0dqbipqPcXYxsx+jnsbNpB1/ARZx42/gyzJgidpILVQCE6jNkXU6SupqiIa6m/8Uktw5u4Zflil/X9fOcqWI8VKWrYIS2o1xTvAFZniwdLvedcOZmeLZYaFt8/A+Z8hfMADjW0NJElC5uhYri9LgyRv2bKFiIgIDh06VOSmpODgYEaPHs3ChQvNtlm6dCnz588nM7N4147x48fzww8/kJ2dzbp165g4cSIAGzZsYN++fezfv5///vuP2bNnk52dbdG5CAQPCzJbW5qcO0vN118rszHDtpwrvlExFLWrW6lWokrP4Gq37haNZckTTGNCSb2aeJkum7owcaeKJ/7RlhenYOj3r/2T5RESzFHjyKXiGxWisLVXI4FKbplqFJsWy6PfP8pnhz/Ulekvq+ujTjNv7c7MK/nekZIi15NLbeb0Wl9R0yJKY7ZdvVsVn1JaKKnVFIWtHHtnr+IbFsOjA8eZr8ww9v0RlD1z585l/fr13Lp1y2R9WFgYnTp1YpUFy4W1a9emTZs2vPTSS/j6+tKsmTaodVJSEp6enri4uJCWlkZ4eHhZnoJAUK1w6dHD2iIYUNSyujIvVxuyqgzGyqdASS2wKP96eSveydpl7tH71SiUmmLHKiqaQWn2yOe5WLaSpY+kFcRgXpXcMmPDxye0rlhxqQWhrySTm5s0JH75pdlxTEUQMBrhAbeDKPRCGqjNjPXyVkM5Au7CoKN6ZVZIpyqU1GpMjVqG6WVVpQgr4WSn4JTfaNOV+5aWRixBCfH29mbGjBnEFRHP7t133+XmzZtm6/WZOHEiX3zxhc6KCloLa3p6Ok2bNmXo0KFFZl8TCB52bCtZiuiiVAdlXg65kZFFtCg0lkVKqlYR0984pVGpDCxvjx/WUMO88VDbBw1j9qhYuM74u6nuXRMdikFpX/LMk7Z58MFXhnFO1QrLVKNd0bsAkOvpcSplrlG7r8+FFzlOVMR+i+ZT1/WzqJ0p5BaEoLUxoV+P/1tfca14JVX4pFZj6rZsys0Lu3XHB75fR7dxJQ8hETrhQ5auCOK11EWGFce+hAHvP6iYDx1RJqwagYGBJCQkmG0zd+5c5s6dqzuedz+FXj716tUjN9f44WiKESNGGFkw3Nzc2L17t8n2EyZMKJf4qwKBoGywzTQTzxT47crPdHtltcVjWba7X/v8UOvvNlepDHxQnzxYvHVQrVEz5EhpbKbmBiz5cnSwib1AakXJlDF9JTU9M8WoPiXHuEyfQAsTQN3Iul1kxIOirqS+jKUyUwNqYUkVlCXBoY0Mjk/8trVU40i2TnR7fAr7VC2MK/9aACUIfyIQCASCimPdacs2VebjbIErum53v7JAOZbnKGkZWTLtRxVfti5jkurBfSZVMslin9T8sFv6CmDgemOraPOoslHElVJx52d+Hn2/5VKrmlYIQSmU1GqMR23DbFOSBanyzNE+2JNvas/l+dwXuKdxLqg48CGsaFPqcQVlz/bt2wkNDTV6bdq0ydqiCQTVEqdOnWh06iQNjx3Fd0FBvvvAzZtJ6xhiRclAUXaBCHTkpwFV67mQDfs1kaf/LJmSmPPlujKVSyqDqAtKOaj1fFJf/FnF4COmzyvfNUJfSS2cqhUw2IxUnmiKUFLdkgsEK0loMIPxraCkiuX+aoyNrR2ObnXITLkBgFzxYB/3ikk9afJWHrtzWnPRvsCfkaRIyMsGG1PhgQUVzYABAxgwoOpFXxAIqhK+b79F0oYN+K9ejY3vfYOAgwPuw4ahSk7BqV1bHJqHUNsziFTOWk1OO/OeAKUmf5lfrWdJbXKl5NFANO6uZSYTgKQsC0uq9pUfSOrRCxoevWBaq9u4VHsdTtSrJEluilA+A2LKINuisKQKypqOT87UvZeZSYVmKQ62cp7rXo9s7Iwr/3gV1g8XS/8CgeChoMbo0QRv21agoN5HksvxenoqDqGhAMhdnE30rjhMWfYeFN3GKdWDacAa7xrFNyoJZZBzXiUHFSVTdsOuVYyltHAGr8IUZUnVp6HpQDHFYia6VrkilNRqjl9DD917mezBDeev9G0MwDfK3oYVJ9fB1V1w49gDzyEQCATVBefulsUnLS9sy9WS+mBKoTrPss2eFo+Xm1N8o2JQykFZQiW1ItBIpV+mLzMZxMYpQVnjWbtASXXzDSyTMbfP6MxbygnMyxtfJuMJBAJBdcW5c2f8PvjAwFe1IrHPK3vNJt+Sqsl7QEtqXtmaectquV9dCVcEJU3xSqq+JVWj0RQZh7Z0QgglVVDGyORy/BoPAiA3q2x+HTb1c2VEmD/hqr7GlTlp8O9XcNt6PlgCgUBQmXAbNBCHFiaio1QAb28oe6ugOn/jVM6DZaVTm4gp+iDIVQ+ulGkwjFpQWVBLxS/366/2qzVqgyQFZUG3bTFlOp4lCCX1IcC7rjaof1Za2aW5XDKsBSYDWWx4En5/GT5/tMzmqm4EBgZy9qxWic/OzmbIkCGMGjWKMWPGsGLFCl27RYsWERQURMOGDQkNDcXX15eaNWvqdut/9913BuNOmDDBoL8+4eHhuLu7ExoaSkhICP379ycmJsaoX3h4OJIksX79el3f3377jW7duumOJUmiV69eBuN7eXmZjP+aT1RUFF8WkXGlOD7//HM+/vjjUvcXCKyNJH+wPQGVCV3GqZwHW15XP6AltjCyMlBS5UhlLleZIIG8GJVN0lNK1aihDKIdWBuhpD4EeAdondOz064RdeZMmYwpl0n838AmnFPXNd/o2t9lMldZodFoyMtRleurJMsrqamp9OvXj1q1arFhwwZsbGx0cr788sv8+uuvnDhxgsuXLxMREcG0adMYP348ERERREREMGbMmBKdf69evYiIiODs2bM0btyYmTNnmmwXGBjI3LlzySniC+jatWvs2LHD4rmLU1KVxfi2TZs2zay8AkGVQF59gunk+6Rqch7QEnrDfBa90lAWllS5RnrgDWHlgQawk4rOqKV//mq1uuyX+61A9blrBGbxa1CgSP747hxe3vRbmYw7uVMQs/eN5kPlEtMNvn0CJv4BdTuWyXwPijJXzZcv7ivXOZ7+pCs2dsVbTO7evctTTz1F7969WbKk4PqpVComT55MbGwsu3fvxtm5ZDuDz58/T69evYiJiSEkJISNGzdia2tr1K537968+uqrJscICwtDqVSycuVKs4rhO++8w+uvv06fPn2QLPBTmjZtGjExMYSGhhIQEMCvv/5KYGAgU6dOZffu3fj5+fHhhx8yevRoUlNTyc7OpmfPnnzyySdIksS8efNIT0/ngw8+IDw8nO+//x4PDw/Onj2LnZ0dP/zwA8HBwSW6VgJBRSI9YHSVykS+JVXzgBuVbHcdLgtxdJSFkqrQyCrlcr9GAkld9PnJDJRUFagqSWisB0BYUh8CPOuUT55pSZJ4dUoxm6eul69SWFUZMWIEffr0MVBQQav8Xb9+nd9++63ECipAREQE27Zt48KFC9y5c4cff/zRqI1KpWLz5s2EhYWZHWfx4sUsXbqU1NRUk/WPP/44jo6ObNiwwSK5Pv/8c5o2bUpERAS//vqrrjwmJoa///6b7777Dnd3d7Zt28aJEyc4c+YM169fNyk/wNGjR1myZAn//fcfvXr1YunSpRbJIRBYC7mHp+59rXcXEhAeTpOLF6woUenRlJUltYwp1mfTAhRqiZqbjbNGVQaK2ziln1VKo1KiKYMMXNZGWFIfAmSFfKHUajUyWdn8PvHxrc3GDr+RdeBTJipMLP+m3y6TecoCha2Mpz/pWu5zWMLAgQPZvHkz06dPx9/fX1fevXt39u7dy8GDB+nZs2eJ5x86dCgODg4AtGvXjmvXrunqdu/eTej92I2tW7fmww8/NDtOkyZNGDRoEEuXLqVDhw4m2yxdupTx48czYsSIEsuZz8SJE3WWWLVazWuvvcbBgwfRaDTEx8cTGhrK8OHDjfp16tSJunW1KwQdOnTg008/LbUMAkFFIHd2InDLFiS5DPsmTXTlXs89R8Jnn+mOb4/sgu+myqkk5ZOvpJJb+SyOD4pNJXbjlIpZvtfPfKVRqaiEkbRKjFBSH0ISYlKoGVh2QZRH9O7EqIg4JmaZUFJPhEPr8VDbvNWuopAkyaKl+IrglVdeoVmzZnTr1o09e/YQEKC1dnft2pXnnnuOESNGsGHDBnr37m2yf3Jysm4zU1BQEFu3bgXA3r4g65dcLjfw9ezVqxdbtmyxWMb58+fTsmVLnTJYmE6dOhESEsKqVassHrMw+tbijz76iMTERI4ePYq9vT2zZs0iO9v0Zr+izlMgqKw4hDQzKvN+4Xlkjo7Ev/8+AFLpM6tXGAU+qWW3GbeyIK+kip2kodjd+vrL/SqVCk0ZuD9YG6GkPoREn71VpkqqXCbxzlP9aLNsFcftnzVusLoHzEsps/mqC6+++ioymUynqObTrVs3tmzZwrBhw/juu+/o29c41Je7uzsRERHlKl/t2rWZMmUKixcvNquoLlmyhB49ehS5yQrA1dWVlJSi/weSkpLw9fXF3t6eO3fusHnzZkaOHFlq+asSf/31F3/99Rfx8fGo1YbfkmvXrrWSVIKKosaY/+mU1LqugXh+NJibs17mSktPslLu4ZijoX4xe4w+fUzGC9sqSMNSq8m+fBnHPScqZr4KpCz8WssDSWO4nG8KfQVbrc4jL+5eOUtV/gif1IeE0e+8r3t/cnvZf+k19nWlZ5sQeua8b7rBP5+U+ZzVgdmzZ/P888/TtWtXg52YXbt2ZevWrYwdO5Y//vjDavK9/vrrZv1SAZo2bcrAgQNJT08vcpwWLVrQqFEjQkJCGDx4sMk2M2bM4NChQ4SGhjJp0iSjMFfVlfnz59OnTx/++usvEhISSEpKMngJqj8yvZUBj4bNcB0wgMZnTrNtchMWjpYzZ0Lx9qRME9mqywu1WkX02HEVN2EFIldpSHKq2Dn/CCveei4BxWU91ffJ1ShVxD47/YHkqgxImuoQo8AKpKam4ubmRkpKCq6urtYWxyI+HDlI9378+yvwDggs0/Hj07Jp9+5fPCY7xKe2JuJ1vnASPOuV6ZwCQUmpbPdurVq1eO+99xg3rnp+6Remsl3/ykLyjz+RFRGB79tvISm0SumUnVM4GncUgB8WF+3S8s4oGXM3mrek5snLzt/y5PRutF65t2wGq2RE11LgmaTEuZw8GZ58Q8Gir5XUv79dY+VAGaeCJVZ/WvSHk+oAMpkM5wzLrOU19/5BfLf+DyquAekqFe2uXqnQe1dYUh9Svn1tRpmPWdPFnue712ebugML8kx84d69WOZzCgRVndzcXDp2rBxh2gTWw33YUGq9s0CnoAJm41wer29secu1MW+N+3iIDFUZftvrNk5VQ+QqDbbl7OIe51HwWcW7acNLFYd2ud/yOarLZySU1IeI1gOG6N5r1OXjuzSjZwNAYq2qP4HZhcITbfxfucwpqDwMHjxYlxEr/9W9e3dri1WpmTJlisWhvAQPFxoz67t1bGsaldV0r2N2nFhvySDj1fvDHvCrv5y+PyoDcpUGRTnrd7Z642fYSxbNJ1H87n591KrqsZlUbJx6iOg8+ilObv9Fdxx9JoK6LULLdA5bhYxPR7fihe9PAZBlUwOHPD2/unvXwUMEXa+u6MdAFVhGdnY2X375Jbt376ZFixa6zGP5fPTRR1aSTGBtZreZzajfRjG1xVRgpa7c0ckNuGPQtr5vUyDa5DiTW0+jbl0fbs99i9/bSsTVKNp0d88Zvusm44XfTCujbpEJJTkNq3DDE+oklrxfrcTyV8DbXypQNrNtIcO+iMb3kTQmE5GbpVKmdi0FwpL6EKEolHloy7v/Vy7zDGpRCydb7a/2VmmFvmCXtyqXOQWCqsqZM2cIDQ1FJpNx9uxZTp06pXuVdwSHByEzM5O6desye/Zsa4tSbWnq2ZQTY0/wQqsXsG/ZAgCFtze3ppjwNdR7vl/2gwy9jVQKB0dqjBjBM8/LWddTRqIJd8LvuxaoA7+2l3GguXn1oP6uS2brDjSVSHUoOD4VLBHpY7Z5qbnpUfD+hqdx/YUAiUQfB+OKSkCCS8H7XAXk2EqkF6OoOuSAfU4J0m6/9nYppatcCEvqQ0abx4ZyfNtP5TqHJEmcfKs3HRb/zb0M+E3dkUGyQ+U6p0BQVdEPP1aVePfdd2nfvr21xaj22Mi1lvU6y5eTuGYNHv/7H//lnTRqJzkWKGQHQmRcrSWxeJ12HVlhr61LctHa4rJsjZWdrR1ljN6ntSKWJlJrRJDEopEykCTscjV8+6F27ts1wO4BjXrn/eFcgMSIfwrkfn+4nGVfaucwF9vUVIame87gUXQwkjInwRV2tpJx3Vd7/G0PGTN/0Qqdc3/hZOZUOR0uapi0y/TJlNSiqPrvfCmlrVwIS+pDRtvBwwyO88wES39Q7BRy3h+u/eX/Ym6h2KlfdIWvB0CS6aUpgeBh5caNG9y8edPaYhTLlStXuHjxIgMGDLC2KA8NNj4++M6Zg21gIK62rnzXTfv1fdcVNnWWofDwYEcriZsesC9EMghJZWNXyKIoGaqhEUHa423tJOJqwJ4WEk08mpDpXOB6Mma2nGxDTxQAFoyW8WNHiY+ekOnGzbGVeHO8nB2tJTZ1kbGnxYOpGmqZxOYucgOL6S09S2otM5HaCiup95y1lkt9wnuWXraL5t2AdZwLgEVPyvm5o4wzwdq5cvWuY76SmuIs8WebkstS+HxKw8XaDz5GeSGU1IcMG3vDNYXsYuJbPgg9m/gwtHVtVMjpkvNxQUVcBET/A7/NLLe5BYKqglqtZsGCBbi5uVG3bl0CAgJwd3fnnXfeMQrsbwn79+/nsccew8/PD0mS+Pnnn43arFy5kqCgIOzt7QkLC+PAgQMlmmP27NksXry4xLIJygZ3O3d+6SBjzGw5zz2n4MdOMpxtnFnTT87Mp+Vk20nEu0OyE8TVABtHbWa39r4Flu+XnpazdLiMuePkuo1U3/aU8+I0BZn2Eg4KB643cde1z7ORSDYRP/RsoIxNXbVz6nOltsSavnIy7SX2NZe4427c1xTp9rC2t8zAReBaLe3f6/20GbtOBUsgSazuKyMiSOJkiPGyfqOnnjfYaLQrVOLLfjKu1SqQ848wie3tCtQgfRn13Qn0ydLzmjO34Wl9d+2YWztIzB+j4Ia34bXR150fNOpCWURtiK1ZebOcCSX1IUNhY+iXeieqFJ7lJWBmr4YAxGhMOCWl3S7XuQWCqsCbb77JihUrWLJkCadOneLkyZMsWrSITz/9lLlz55Z4vIyMDFq2bMmKFSZiFQObNm3ipZde4s033+TUqVN07tyZ/v37ExMTo2sTFhZGSEiI0evWrVv88ssvNGzYkIYNG5b6nAUPhqeD1qSYpxd2ysnGiVlhs0CSeKbFM/RrMIjp0+W8PEWOrY3WOPFe1/eY0WoG8zvO55anxIkGMi7Vkcizkfii1xcGczjaOJJVKEHAh0MN00p/3csyFeLFsJd44VkFLzxT0H9Pc2PF6Plpcqa8KOfPNjJem6Tg5clyNnWWseVR7TzXOgcxd6xca7UFdrWWsWiUnO0DDaMd/LliJH37TTdII7q6v5yTDWSs6SNjRyuJN56S83UfrTyzJ8txWfQ22/UsmXPHGafQXjFIxlMvF5guzbkZ/Npe4rln5QZ+vvqkOOmd+33rs5udGwDvjpQRV4KEkGWhpJqykFcWhJL6kCFJEp1GjdcdXz56oVzn8/dwpFN9LwC2qrsaVmpUkBxjolf1JjAwkLNnzwLand1Dhgxh1KhRjBkzxkCxWLRoEUFBQTRs2JDQ0FB8fX2pWbOmLrTTd999ZzDuhAkTzCom4eHhuLu7ExoaSkhIiIFSot8vPDwcSZJYv369ru9vv/1Gt27ddMeSJBllg/Ly8iIqKqrU18Qc+tequrJu3Tq++uornn32WVq0aEHLli2ZPn06q1evJjw8vMTj9e/fn4ULFzJ06FCT9R999BGTJ09mypQpNGnShGXLluHv78+qVat0bU6cOMHZs2eNXn5+fhw5coSNGzcSGBjI7NmzWb16NQsWLDArT05ODqmpqQYv0FqQxat0rwDnAKPr7Khw5KmmT3Fo1CGmt5yOvcwepUJCqZBQSArUajXutu5MDplMXRfjNMctvFoYFmjg715eXPWFNX20qkK0j6Fi+UcbCy1w93XFOx4Sz0+T88zzcjZ0K1A/kpy0Cm98DQm1rGDM2JoSP3aSkWOrLZPLFVzyl3TH+WR6OPDsdDlZtnCkkYSNpxdqtZqoxu4ABhbgdEeJNf3kXPMrGCOmpoR9v17sDpU41lBiwwAn0h0lZk6VM3uynAQX2N9MYn+hzWTyQpbUo40kNj+qtfLedZeM3CryuVYLfugkY8WggvGUam3IqNPBMv5uablqtrnTg6txOcUoqa9NlBMRJLE/pOItriXyZjh27BhhYWHI78db02g0SHofQk5ODr/88gtPPvlk2UopKFPaP/EkBzd+A8CF/V/R79nByGTl93vl09GtaPPubmbmPo2njxtdUu6HKbp7EZY1h0k7IaD8N2BoNBqUxeSYf1AUdnYG90RRpKamMnjwYBo3bszKlSuZNGkSoJVz9uzZ/PPPP5w4cQIPD+2607x580hPT+eDDz4olWy9evViy5YtAMycOZOZM2fy448/GrULDAxk7ty5jBgxAjs707kWr127xo4dO+jbt2+pZBEUcO/ePRo3bmxU3rhxY+7dK9vc27m5uZw4cYLXX3/doLxPnz4cOmTZ5sbFixfrlvrDw8M5e/Ysb731VpHt58+fb1QeGxuLi4uLiR4CS+jo1ZFDCQWfWW5Kru6HZyKJZGRk6OqS7yYTk1tgEEhNN051fPum4cpWlxpdWJ+8njkTDdWEiS/JmXopgIsd/SHT+H9mZduV1LSryfCDwwvmSymYL14v/NXS4TKybeBcYMH3z5vN3uTdc++aPOfsTDN7KFSQ6CYxdYacPAWMSc0gJiaGP/rU5JTDXY41LP6ZfOvmLfJsJD4YJge03xM3vbT9nntOjsbEcz3BTWJrR4nnflPzyRAZRxtrz2Ns4FjWR603av9M/WeIzojmz7g/2dLZcDwnuRMZedrPrKig/a9MkjNH+RjP+Wyj1j2I9YaJu4s9PSOu1IIGcdr3CrcagOlnzW9ttdEZFo2So8oCfi75XA9CiZTUDh06EBcXR82aWtO6m5sbERERBAdr414mJyczevRooaRWMc78dYTQ3uWX8aaGky2v9WvEou0XOZWooEvh/7qT6ypESVXm5LD8qeHFN3wAZqzbYuT3a4q7d+/y1FNP0bt3b5YsWaIrV6lUTJ48mdjYWHbv3o2zs3OJ5j9//jy9evUiJiaGkJAQNm7ciG2h0GMAvXv35tVXXzU5RlhYGEqlkpUrVzJzpmm/4XfeeYfXX3+dPn36WKSU9+rVi2effZZhw7Qb9/bs2cPLL7/MyZMn2bBhA5988gm5ubloNBoWLVr0UG3IyV+aX758uUH5ihUraNmyZZnOlZCQgEqlwsfH0P3Gx8eH27fLx/3mjTfeYNasWbrj1NRU/P398ff3F2lRHwDfm76gF660ad2mBNQosLC6xbnBfSXE38+fAM+COlmaDE4YjhdUNwjuuyZ3rdOVJ1s9yfoYY0Urw0Hi7OBGeDl4wSVjJbV9w/YoZAo4WFDmWcNEjCjgRAND44irrStPtn7SrJLq6mz6/8XNwQ3SCrJueXl4ERAQQM5/En+0tcwAE+BvbJ3Op7CC+tZYOf2Pq1nXU8Y9V4kjjSVU8oI2DWo1gCjjcTrV70TDrIb8GfenUd3/dfg/lv67lJvpNzncRGL0fuP+O1tJRPtINBoxmyZ7ovlP8R8AW54KZvi66xadZz76m7c86zVF/wPb1Uqi9ykNyY7wTS9jt4eKpERKauEUbaZStplL4yaoXDRo15Erx7QPmP3fflquSirAlE7BLNp+ka+UA2gsxdBXfryg0t69XOeujIwYMYKpU6cabT555513CAkJYceOHWatmEURERHBX3/9ha2tLV26dOHHH39k9OjRBm1UKhWbN28mLCzM7DiLFy+me/fuTJ482WT9448/zqpVq9iwYQNjxowpVq5Jkybx9ddf65TU8PBwJk6cCEDfvn0ZPXo0kiQRFRVFx44diY6ONgpqX1157733GDhwILt376ZDhw5IksShQ4eIjY1l+/bt5TJn4R8WhVfFLGXChAnFtrGzszP5vyyTycp1Bae6k+/DCGAvt6euW12D6ymXFSgXdgo7gzoPB+NdQXK9jFR9A/sil8vJVeeanFutUeNqZ6ww2spssVVofxQ7KhzJVGYyuN5gFHLLVA25JC/yf0IhMz2Og43hxilbuS0ymYzz9wrCMB0cpVXCem/pTZYyy+KxTXHRX+Kif8H10ldQoSBsmD7TQ6cT6hPK0bijRnVjm4yle0B3ugd0p/m65tz2kJgyQ06GPdS/BR5pGmolaTd61XGug6ejp4GudbWFJ2BaSf2yn4yn/9SaZv9pIuF/V8P33WT0O64h3w8js4Gfrv3BphLhvWRcraUhItj6G6rKPE5qaR50goqn+4SndUpqXk4aGrUGSVZ+n51MJrH/le50eX8Pz+TN4j/Hmbjk3M+YcuQzuHcNHvsEXHzLTQaFnR0z1m0pt/Hz57CEgQMHsnnzZqZPn46/v7+uvHv37uzdu5eDBw/Ss2fPEs8/dOhQHBy0D+x27dpx7do1Xd3u3bsJDQ0FoHXr1nz44Ydmx2nSpAmDBg1i6dKldOjQwWSbpUuXMn78eEaMGGGRXDNmzOD27ds4OTmxbds2XSalyMhIxowZw40bN1AoFCQkJBAdHU39+vUtPe0qTdeuXbl8+TKfffYZFy9eRKPRMHToUKZPn46fn1/xA5QALy8v5HK5kdU0Pj7eyLoqqNzoK4l/DPsDB4WhoiaTCpQ9W7nhaoqTjYlt+sDy7ss5GX+SAUHalYz85efCqDVqcpTGrlP6ivHh/x3mctJl6rnXY8tly567RekPL7Z+kdQcYzcFwOjc1RqtUlbLqRZxGVpzcr5Sby+3N6mk6l+v0tK+Vnsa1Whkcvynmj4FQLCbYcbFFT1W0NW/q1H71Pubqy75g37k2gBXrcVXTYFPgI3ClpGva69999Mapv2hrVvdV8buVjK6nVHT8BZs6CbT+soCdnlqWkZpuO4LkpcHnwyW4Zij3YwGsKdl5dDlRDD/hxQXTy+D49uRqdSq52amddkQ4OnII8EeHLl+j6GpL7PLTm+5+fKfsPUZGP+L+QEeEEmSLFqKrwheeeUVmjVrRrdu3dizZw8BAdoHT9euXXnuuecYMWIEGzZsoHfv3ib7Jycn6zYzBQUFsXXrVgDs9c5PLpejVBbkb9b3SbWE+fPn07JlS+rWNd5kAdCpUydCQkIMNtyYw97enuHDh7N+/Xpq1KhBr1698PTULgGOGjWKDz74gMcffxwADw8Pssspfm9lxc/Pj3ffNb3EWZbY2toSFhbGrl27eOKJJ3Tlu3btYsiQIeU+v6DsCHIN0r33cvAyqpdLBQpjYSXVnDKYb83LJzMv02Q7lUZFtsr4HtVXzmSSjMYejY1kKYr8di29W3L67mmDuinNp/DhcdM/rBWSoSpzOekyAEMbDOWziM8M6uwUdvkupzra12pfKiVVQkKjF1Dqqz5fAfDt+W+N2uZbV70dvRlcbzC/XtPuzSiJBRfg0C2tcUnfkupg46BzSfg7VOLfhhJfD9nArl3aVa63x8pxzIE0x4LP/VATiTvucm54wfO2bvzTrHKuapRYST1//rzuV7hGo+HixYuk34+1mZBQ+fP5Ckxz5XhcuSupAF9PaEeTt/7kiqYOax0nMSlzbUHl9b3w7xpoa3qJubrx6quvIpPJdIpqPt26dWPLli0MGzaM7777zuTmJHd393JPmVm7dm2mTJnC4sWLzSqqS5YsoUePHuRYsCFt0qRJTJo0CXd3d958801deVJSEoGBgQCsX7+epCQzkbmrEWfOnCEkJASZTMaZM2eKbNuiRYsi6wuTnp7O1atXdceRkZFERETg4eFBQEAAs2bNYty4cbRp04YOHTrw5ZdfEhMTw7Rp00p1LgLr0COgB5NDJtPEs4nJehfbgk1phZVUgF3Dd7H85HK2Xd9mdg6VpmD7+tgmY1FpVHx/8XvUGjXxmfFG7Zt4mJblbtZds3OYarey10pO3jnJC3+/YFBvzp2w8Ph5am2KK1MKoJ3ccLVraIOhzAqbVSol1V5h2iqbozJ+Huor0mE+YTolVd/6bAmBroFGcxS2jKc5SmBfcJ4quUSaY6GBJIlr9xdqmnk10xUv67aMv2L+KvL/oiIp8afSs2dPXQiczMxMBg0aRGhoKK1atTIKSyOo3Ax78x3d+6v/3kSlLHng8JLiYCtn/yvdcbCRs/heN+MGv88yLqvGzJ49m+eff56uXbsaPIC7du3K1q1bGTt2LH/88YfV5Hv99dd1IYNM0bRpUwYOHKj7oVoU7dq1A7RKU58+fXTln3zyCU888QSdOnXi9OnTOqtydSY0NFT3oz7/+Zn/XNV/tWrVqsRjHz9+nFatWun6zpo1i1atWul24I8cOZJly5axYMECQkND2b9/P9u3bzf7Q0RQOZEkiZfCXqJvoOkIG2E+BT7ntjJjJdXXyZeedYt2KWpQowEAdZzr8Fq712ju1RzQKq+RKZFG7Zd0XmJUBpCQVTIDlqutK938u1ncfmDwQINjR4VWIzNlwZ3SfIrufU3HmrzZ/k3c7NxKpaQWdjPIx5Tiqm+9zpfPnIxFMaP1DAAylQVWbieFsfuGBg0Na5iPZRzgUvCc1bfEN/VsyqLOi0okU3lSIktqZKTxP6Wg6hLYohVyGxtUeXkkxX5G9H9NCW5Vq9znDfB0pFdTH7advlXuc1VGCscTnTVrlsHu53w6d+7M3bsFFoJ58+YVOW7hmJr6oaomTJhgdpOLfr/C7dzd3UlMNEz4UNiasWbNGtasWVOkbPmYink6duxYxo4dqzt+//33de/LI/ZqZSAyMhJvb2/d+7KkW7duxW5gnT59OtOnTy/TeQWVi2D3At9HO4VpX/nu/t0Z33S8TvkszPLuy/nm/DeMb6qNrZ2vUKk1au5la0MWNfZozMV7F43m1EelNpOaqRhkkkznXwoYLK3rU9fV8AfWtJbaVQFTltQh9YbQ3Ku5VkmTwEZmo5vLHEFuQdR0rGm06amOcx3dddAn35JrDn1/4vz5zdGwRkOd+wIUWIL1XTFMWcpVGhW5KtMb3wrLqG+Jzb8Oy7svZ8aeGUXKVhGU6KdD3bp1LXoJqg629vm/BHM58H35birS57V+jbBVyBiaM48su0L+VKkPp/IqeHioW7euzrISHR1N7dq1jZ6jtWvXJjo62sqSCqoqHvYerOy5klW9VplVhGSSjFfavkK/oH4m6+u41GFO+znUcdEmqc/feZ+ryiU1V7vCsrjTYsY0GcNPg38yK4u5DViFKZxQYFDwIEBr3StMvr8rGCt6vk7aDbimlFRJkqjnXg8buY1Bv6KU1AUdF+j8TfNpXbM1izubTg08rsk4POzN5FXFMDJDYUvqxJCJBscvtn7R4DhfIU3PK1i9MqW8q9Vqk24H+ZhTUvMjOuj7JluTEimp9+7d48aNGwZl586dY+LEiTz55JNs2LChTIUTlD9ZaQVLuQnRO7hxMZLdX60kJf5Ouc5bp4YjT3Woy0lNQzqrviA3oHNB5UdNIKf45WNB5WPw4MFGS9bdu1eOh11lpXv37iaD9qekpIhrJ3ggOtfpTKfancpsvHyFKt8fVSbJCHQL5PV2r+tcA0zRJ1Dr3uNp78n3A783qKvpUJDSVN+PFuDN9m8y95G5fNZTu/kpX/kEaFSjke69qZBPYH45vqSYUnbX9V+n22lfGG9Hb/Y8uYcn6j9hst7LvsAwU9jqOrP1TP4cVhBHtfCmsHxLar4CX8e5DhLGG+GUGqXFSqr+dXK3c9e9L0rRrihKtNz/3HPPUatWLV3omPj4eDp37oyfnx/16tVjwoQJqFQqxo0bVy7CCsoeV28fUu8WKKSb3tY6qt+6dJ7x75tOsVlWvNirIX9diOd6QgZfyEfxQn4kaYDFtWHgRw/NJqrqwq+//mptEaoc5mKUJiYm4uRkOlSQQGAN8q2NtzK0q13BbsEW7U7vU7cP6wesp55bPZxtDROUpOel80qbV9h4aSNvtH/DoM7RxpEnGxUkBxrWYBjbr2+niWcTXRpR0IaaMkX/oP5svbLVwD+3NJgL2VUUMklmIKM+Pk4+eNh7kJSdZOSqIEmSgaJYeGNVviV1UsgkXG1dGdd0nMloAkq1kmyl+SgpTzd/mvePv8+QekOQSTJ+e+I3clQ5Bj8UVvdZzZJjS4hOjTa5Ua4iKJGSeuTIEb7++mvd8TfffIOHhwcREREoFAo++OADPvvsM6GkViEGz3qD9W+8ZFR+Nyaq3Od2tlPwwZMtGbryENsuZfFCYbea32cJJVVQbRk6dCig/VKaMGGCQcB7lUrFmTNn6NixfJNsCAQlofDStLnd/IWRJImW3gXZ015p8wrvH9f6nmcpsxjfbDzjm40vdhxHG0e+H6S1xM47NE9X7mHvwac9PuWFv19gWINhunI7uR3r+q+zSMai0F+eL8zr7V5nybElzGk/x6jOnJIK8PsTv5Oel46ng3E2Ln3LaOFrbifTPifqudfjtXavmR2/OJ/U8c3GE+YTplOSCyvLoPWHXdt3LecSzzHqt1H0D+zPBS6YHbM8KNFy/+3btwkKKojN9vfff/PEE0+gUGh13cGDB3PlypUSCbBy5UqCgoKwt7cnLCyMAwcOFNl+3759hIWFYW9vT3BwMJ9//rlB/blz5xg2bBiBgYFIksSyZcvKZN7qik+wdQOmtw6oQb9mvlxW+7FZPtC4Qbp1fr0JBOWNm5sbbm5uaDQaXFxcdMdubm74+vry9NNPs369cVpKgcBaFN6QV1pXgnFNx+mWmB+p9Uipxii8+tDNvxunx59mXsd5pRpPnyfqP8GrbQvieLvaGmbX0o88MKbJGA6OOsjoxoaZ/UC75G4OZ1tnA/cFffT9Ywtbqt0tzNCYrcw2O393f60bUTOvZkaWbVM082zGodGHeKvDWxbNXZaUyJLq6upKcnKybnPUsWPHDNImSpJkUbzEfDZt2sRLL73EypUrefTRR/niiy/o378/58+fNxmGJjIykgEDBjB16lTWr1/PP//8w/Tp0/H29talW8zMzCQ4OJgRI0aYzTte0nmrO32mzWDn58uLb1hOLB3egnNxKbxybwyKusE8cefTgsqfn4WxP1pNNoGgvMhflQoMDGT27NliaV9Q6dH3cXRUONIjoEepxpEkiV+G/MKWK1sY1WhUqcYwtRmsLLJGAdR3r0/PgJ6silhFHZc6OkXxhVYv8Pv133mn4zsG7c1ZWovb5W+OopRUU4kbTJGck2yy/N8x/xrFirUEF1sXUrPNhyMsL0r0ibZr147ly5ejVqvZsmULaWlp9OhR8E96+fJlgxSPxfHRRx8xefJkpkyZQpMmTVi2bBn+/v5mM9h8/vnnBAQEsGzZMpo0acKUKVOYNGmSQaidtm3b8v777zNq1Cizuc9LOm91p3n3PsU3KkfcHGyY01+7bDQzugMXOhR8nlzdDXfOQewxyHu4shAJHg7efvttoaAKqgT68T9/HvIz9orSZ/Cr5VyLF1q9gLejd6n6T2k+BW8Hb6Y2n1pqGQrzXOhzDAgawKjGo/Bz9mPXiF18N+A7Xf3TLZ7ml8d/sdiaWdRyf1HoW4n1l/snhxTv/pbvVmEqji1oExBUpfT1JbKkvvPOO/Tq1Yv169ejVCqZM2cONWrU0NVv3LiRrl2Nc9CaIjc3lxMnTvD6668blPfp04dDhw6Z7HP48GGDIOAAffv2Zc2aNeTl5WFjU3S8sdLOC5CTk2NgJc4PcK5Wq1Gryz8Ifnnz2Kw32PaRYTiNijyvvs18eKxFLbadiWPiHjuO6D/7Vmn98jQhw9AM/cr0AAKBhVTG+3XLli388MMPxMTEkJtr6Ed28uRJK0klEBiinwq1lnP5x9QuipqONflrxF9lqnDlx1fNpzQbpvRpVKMRB28eLHE/mZ79UC6TM/eRufyX8B/PtHym2L75lte1Z9ca1fUP6l9iWaxNiZTU0NBQLly4wKFDh/D19aV9+/YG9aNGjaJpU+N4ZqZISEhApVLh4+NjUO7j46NLu1qY27dvm2yvVCpJSEigVq3ib5rSzAuwePFi5s+fb1QeGxuLi4uLiR5VC1uf2tSoU5ekGwVxGc+duIqLt3GQ4PLimTA3tp2JIwvTFnDp7I9Et6l4nxhB9SItLc3aIhiwfPly3nzzTZ566il++eUXJk6cyLVr1/j333957rnnrC2eQKCjpNmRypvKbhF8usXT2MptS+wWob/c72nvyZONnjSIclAURUVb6F23d4nkqAyUSEkF8Pb2ZsiQISbrBg40sfGlGAr/k5kLx1JUe1PlZT3vG2+8YZAVKDU1FX9/f/z9/XF1dTXbryrh7R+gp6TacPeiimZhFeuju3GqG6NWH+VHVSeGyY1/gQbkXYO6HcFMBhWBoDiKSvNqDVauXMmXX37J6NGjWbduHa+++irBwcG89dZbJuOnCgTW4rF6j7Ejageda3cuvrEARxtHpoeWPLObJEms7rOaHGWOyd3/RVE4ruqHXT/k5X0vA5CeW/Xij5dISf3mm28sajd+fPGhJLy8vJDL5UbWy/j4eCMrZz6+vr4m2ysUCjw9LfsgSzMvgJ2dnUkfV5lMpsvCUdXxrF1H7yiPiD+W0qr3Mmr4uleYDI/U86JbI29evjSdtcoB/OTwDnbqAj8o2XdDoe1UGPhBEaMIBOapbPdrTEyMLtSUg4ODztI7btw4HnnkEVasKN94xQKBpTgoHFjT17IUyIIHoyRRD/SD8ReOq/qI3yMEuAQQkxZDW9+2ZSZfRVEiJXXChAk4OzujUCjM5oaWJMkiJdXW1pawsDB27drFE08UZGXYtWuXWUtthw4d2LZtm0HZzp07adOmjUX+qKWd92HBztEwFIVGlcC+737n8ZfHVKgcn48No/HcPzmnCaR95jIi7Av54fy7WiipgmqDr68viYmJunSoR44coWXLlkRGRpp9zgoEAkE+E0ImcCTuCP0C+/Fn1J8Gda62rmx+bDNJOUnUdq5tJQlLT4lMCk2aNMHW1pbx48ezb98+kpKSjF4lWZ6aNWsWX331FWvXruXChQvMnDmTmJgYpk3TOi+/8cYbBgrvtGnTiI6OZtasWVy4cIG1a9eyZs0aZs+erWuTm5tLREQEERER5ObmcvPmTSIiIrh69arF8z6s1AwKNiq7cTGBjGTLw4qVBfY2cva/oo3jlowLs+psRFPXRDw+jQbuXga1qkLlEwjKkh49euh+fE+ePJmZM2fSu3dvRo4cafBDWiAQCEzhauvKhoEbGN9sPOcTz+vK3+7wNqB1O6iKCiqU0JJ67tw5jh49ytq1a+nSpQv169dn8uTJjBkzplR+mSNHjiQxMZEFCxYQFxdHSEgI27dv18VhjYuLIyYmRtc+KCiI7du3M3PmTD777DP8/PxYvny5LkYqwK1bt2jVqpXu+IMPPuCDDz6ga9eu7N2716J5H1b8mzan0+inOPh9QYYOlVLD2f03aT/YWIEtTwI8Hfl4ZEtmbjrNT1fVpNV7mdXo+ai+3wDCJsD+9+CR56DfogqVTyAoK7788ktdxIFp06bh4eHBwYMHeeyxxx76H84CgaBkONo4kpardRnyc/azsjQPjqQp5XpSVlYWmzdv5uuvv+bYsWM8/vjjrF271mxs0upGamoqbm5upKSkVJuNUwA5mRmsmDhSd6xw7IW9Syij32qPq5dDET3Lh59O3mDWD6cB+LbhQTrHrDTdcF5KBUolqMpU13u3qiCuv0BQfvT8oSfxWdpMjZ/3+pxHaz9aZmNb494t8e7+fBwcHBg/fjyBgYG8/fbbbNy4kRUrVjw0Smp1xc7RibotWhF95hQAzu5KsrPUHPjhCgOnt6hweYa2rsPp2GTWHY5m3OVO/NVaot75z4wbJlwFL+umeBUILOXMmTMWt23RouLvO4FAUDWxlReEjWzn286KkpQNpVJSb968ybp16/j666/JyMhg7NixrFq1yiCwv6Dq0rxHH52SmnxrLw4erYk6k8CFQ7do0rHilw9e6deYdYe1obF6n+zAuja16Hz2/wwbrX8CXvqvwmUTCEpDaGgokiQVuzFKkiRUKuFzLRAILEM/AYGN3LIN5ZWZEimpP/zwA19//TX79u2jb9++fPjhhwwcOBC5vHIF+BU8GAHNQw2OvWqnc/eGM39/c5G6IV44ulZcgH8AZzsFf7/clR4f7kONjHHHg7nq5oYiR2+JPzlGu5Gqkgd3FggAIiNNpywUCASCB2H+o/OZumMqz7WqHolASuSTKpPJCAgIYMyYMUXGFJ0xY0aZCFeZqe5+VXejI/nm1RcAcHL3RCU9BUCbgYG0f6xiN1HlcyomiSdWalPX+pLIzy0O43t5Q0EDnxDoPR/q94KcNNCowd7NKrIKKi/V/d6t7IjrLxCUL2qN2iBrVVlhjXu3REpqYGBgsZmdJEni+vXrDyxYZae6P2g1Gg0fjXpMd9yk2wIiTycDMOmDTjg4V6w1NZ+Lt1Ppt+wAAB6ONhxzfxPFvcvGDV1qQU46zL4Mto7aMmFpFVA5791r166xbNkyLly4gCRJNGnShBdffJF69epZW7QypzJef4FAUDzWuHdLpGpHRUURGRlZ5OvAgQPlJaugApEkia5jJ+mO8zL+xMFF69/yV/gFa4lFY19X9r3SDVd7Bfcy8wiNn8uN0JnGDdPiIDcNdr8NKTcgKxmWt4I/51S4zAJBUezYsYOmTZty7NgxWrRoQUhICEePHqVZs2bs2rXL2uIJBAKB1Sh1CKrC3L59m0WLFrF69WqysrKK71DFeVisAR+OHKR7H9Lzaa6edEZhI2PEG23x8HMqomf5EpmQwYjPD5OQnoOEmnaKq2xSzDPfwbc53L6/sUqEq3qoqWz3bqtWrejbty9LliwxKH/99dfZuXMnJ0+etJJk5UNlu/4CgcAyKr0lNTk5mTFjxuDt7a0LpK9Wq3nrrbcIDg7m8OHDrF27trxkFViBKZ8W5Gk++9eX+Aa7ocxT89tnp60oFQR5ObF6fBgAGmQcVTbkt6EXwLWO6Q639Xb+bxgJedX/h5SganDhwgUmT55sVD5p0iTOnz9voodAIBA8HJRISZ0zZw779+/nqaeewsPDg5kzZzJo0CAOHjzIH3/8wb///svo0aPLS1aBFXCr6UPNoAK/uJAuWp/OtMRs/v3durnFWwXU4K+Xu+qOn99wipdqfYumyZCiO17+Ew5+XM7SCQSW4e3tTUREhFF5REQENWvWrHiBBAKBoJJQIiX1999/5+uvv+aDDz7g119/RaPR0LBhQ/7++2+6du1a/ACCKknfaS/q3v/28Vu0HxyERp3F0V/OcGL7CTT3Uzpag3rezhx4tTv2Ntp/5Z9PxzE+/TkSZsfD4E/Nd9y3VOunqs/fC+GwmYxWAkE5MXXqVJ5++mmWLl3KgQMHOHjwIEuWLOGZZ57h6aeftrZ4AoFAYDVK5JNqY2NDdHQ0fn7agO6Ojo4cO3aMkJCQchOwsvIw+VXl5WSzfPxw3XGXsZPYv77AraNVv6H0mDjJVNcKIzU7jxbzdhqUvdCjPi9nfgIR35nv+Nhy8GulDVkVPkBb9tY9kBWK/avKg2oQGFlQ+e5djUbDsmXL+PDDD7l16xYAfn5+vPLKK8yYMaPYiCpVjcp2/QUCgWVU+hBUcrmc27dv4+3tDYCLiwtnzpwhKCio3ASsrDxsD9pbly/y/dzZZusnLtuERy3rbaTKZ8uJG8zeXOAvK6Hmnyfl+NVrAR83s2yQ0Zvgt5nQ8QXoMB3+XQM73oQhK6D58OL7Cyo1lfneTUtLA7TP1upKZb7+AoHAPJVeSZXJZPTv3x87OzsAtm3bRo8ePXByMlROfvrpp7KVshLyMD5oN8ydTdzliybr7GvM4tnPuiGTl30A4ZJyMiaJofeD/uczd1BTxrf2wObAe9B4EPy1AGIOmRlBj8dXwc/PFhyLyABVnofx3q1MiOsvEFRNKr2SOnHiRIvaff3116UWqKrwMD5oLxzYw/YVH5qss68xC/8mNXhsRmilWZ6c9+s5wg9FGZR9O7kdj9bzQiaT4PIO2PBkCQdN0SYFSLsNLr4iOUAVpDLcu61bt+avv/6iRo0atGrVqsh7RoSgEggElQFr3LuKkjR+GJRPgXmadO5O407dDDJR6RN7IYlfP4lg8IxQJJn1lbd5g5sxtHVtBq/4R1c2bs0xABr7uvBstxCGzEuBc1th8wTLBr32N3z7hPb94BXQelwZSy14GBgyZAjnz5/n0Ucf5fHHH7e2OAKBQFApKbNg/g8bD7M14Pa1K3w3xzDLk3/oHO5GZwPQqL0vXf/XCBs7uanuFU6uUs3gFQe5eDvNqG5Gj/o816M+dpo8sLEHZS5c3Q075kBSZPGDh44Fn6bg3QicfbRJA0yRkQgZ8VCzyQOejeBBqSz3rkwmo1WrVkyePJkxY8bg5uZmNVkqkspy/QUCQcmo9Mv9ggIe9gft8d+2su/bgkD/do5O1H/kZa6dSteVDZ3dmlr13a0gnWnUag1fH4rind9MB0hvH+TBe8NbUNfTSbukv2MOxB6Dm8ctn8TOFXJSofkIGLq6wB1goS8os+C5f8G7YRmcjaC0VJZ7Nz/5yQ8//EBeXh7Dhg1j0qRJdO/e3WoyVQSV5foLBIKSUekzTgkE+dRr097gOCczA89asXR43E9X9vOyU5zZE0vc1etsXvh/3Lp8oaLFNEAmk5jcKYiz8/vy5oAm1HA0DCl1NPIeXd/fy+Twf/k54haavotg6l/wv83Qdqplk+Skav/+txnmu2uzW4FWQQWIOqD9a8XYsoLKQYcOHVi9ejW3b99m1apVxMbG0qtXL+rVq8e7777LjRs3rC2iQCAQWBVhSS0lwhoANy6cZdO81w3KFDa2PDb7Y/74/JquLCdlDRq1dlf8y5t+q1AZi+N2Sjbv7bjITydvmqxv7OvChI6BDGxRC5d75+DqLrj4O9w6ZfkkDfvD5T+07wd+BKk34d+v4Om94BGstdru/wBqt4L6vbTtslPh+Bpo+jh4PHwh3sqTynzvXrt2ja+//ppvvvmGuLg4evfuzfbt260tVplSma+/QCAwj1jur0KIB62WD0cOMlnea/KL3I6pxdXj8WQnfaQr7zRmOe0HB1eUeCUiLTuPBdvOs/mEaQtWbXcHbiZn8Ub/xjzTtR4c/xpsHKDFSK3VtDSM/VGr9B6/nxzhuX8h/hxc3wsnwrVljQbC4yvBoZRzCAyo7Pdueno63333HXPmzCE5ORmVSmVtkcqUyn79BQKBaYSSWoUQD1otqQnxrH7OdLapDsNHo9bU4+iPC3Vl9jVm4e7jyNDZrXFwsa0oMUvMvst3mb7+BBm5RSsIT7SqzfwhzZDFHsH5u0HQ+x1w9YMfJ5etQO2fhf5LtO+v7IYageBVv2zneEiorPfuvn37WLt2LT/++CNyuZwnn3ySyZMn88gjj1hbtDKlsl5/gUBQNEJJrUKIB20BOZmZ7An/knP7dhfb1r7GLN17mUyi58QmyGQyglp4IbepfC7SarWG+LQcztxI5ulvTxTZtk9TH0a3CyA+LZueHMPr9zJWVB9fBcdWw637cTPnJoBMAXER4NUQbK2f8asqUJnu3djYWMLDwwkPDycyMpKOHTsyefJknnzySaMkKdWFynT9BQKB5QgltQohHrTGFN7xb4om3V7lekQ2klQQolejUVIrWMnA53th71R5ratqtYajkffYcymef64mcO5WarF93hnSjMSMXNrU9aBtoBt2F38peytrPrMuat0PbJ1h/VBw94chnxm2SbsDTt4gq3w/CCqKynLv9u7dmz179uDt7c348eOZNGkSjRo1spo8FUVluf4CgaBkCCW1CiEetKa5evwov7z/TpFt/Bo2oWm3GRzcfAWAvIwdqHLPoXDoiptvR+o29+TRYfWxtS9RrgmrcDU+nfnbznHgSoJF7RUyiVru9rT0c+XFWudoQDRkJhb4n5YFCntQamPW0m8p3L0AednQagysu5+I4bUocKihfX/uZ/hrPgxfC36tyk6OSkpluXcHDx7M5MmTGTRoEHJ55YgpXBFUlusvEAhKhlBSqxDiQWuerLRUVk4do921boaOI8ZQt2U7jm/bz5WjP+rK7WvMIv9f0sHFlv7PNMe7rgs2tua/xDNTU3B0tX4g9HsZudzLyOHS7XTCD0Xyb1SSxX0l1LzWLIWwR/vg7yLhe/l72DW3bAV084eUWO17uR28eVtrUZ13/9p5NYTn/y3bOSsh4t61LuL6CwRVE6GkViHEg7ZoNBoNWakpfD/3FZLvxFncT24bgkadjEaTh63LaCTJcFm6x/gm1Kzrgp2jDc417Di7Zxc7Pv+Eem3a03faizi4VK7PQqPRkJyZxw/HY0nOymPV3mvFd9Lj9ZaZ1PJvgPLKboZFv0NiyCQ8z64tG+FqNoXAznDsC+2xsw/Mvmy67c0T8Ocb0Gch+Lcrm/mthLh3rYu4/gJB1UQoqVUI8aC1jNysTMJnP4erlzc3L5rO9GQOW7eJKGw9UCvN/4vqh7dydPPh2S+L9omtDKjVGtKylSRk5PD90Rj+vhTP9bsZFvdXoCRMusJ8r78IzL2ETG5DQq+P8ft19IMJ5uIHL54GNHD6e61vq28L+Kyt3uT2MHE7JEVrU8HmZoJ/W7NDVkbEvWtdxPUXCKomQkmtQogHbcnRaDTcjY7k29dmWNwnqFUbIk8dR6ZwRG7XG5miFnkZfyKzCUSm8Cc37VuD9gEthjPwhREobGXY2juU9SmUO0qVmvi0HN79/QLHo+9Rz9uZQ9cSi+mlASRkqPnOZhEd5OeZkzeZRTYVpLDPvgLONY3LVUptBi5Hj4qRw0LEvWtdxPUXCKomQkmtQogHbenJTE3h90+W4t+sJSnxtzm7d3eR/qulRWHfATefINxr5tF76iic3OzIzkjH3sm5zOcqT1RqDbdTs/n51E2u3U3nzI0UgrycuHwnjejEzGL7u5HODMVWfKR73NF4MFnxh64u1SkQ14yoBxeyQV/otxiSoyEjAUKGwzeDtWlgX/oP3AMefI6iiP1Xm73LybPYpuLetS7i+gsEVROhpFYhxIO2bDmz+092rV5RrnPYOdcmJ12b/nTSJ99Rw9eNlPg7OLi4YOvgWK5zlycJ6TnsvXSXG0mZLNt9pdj29uTgIyWRqnEkBWfeUnxDfekmSbjQW3YCeymvfASd+AfU7Qhxp+HYl9D9TW2EAbUS7Fy0bTQakKSCPpf+hL8WwBOfQ60Wpse9vhe+GaId67WoYsUQ9651EddfIKiaCCW1CiEetGVP2r0E9q//mov/7CMgpAUxZ8+U21xy+3bYOzclIyEcR7eaPP3ZV+TlqshOz8PdxxGNRoOkryxZSPq9RK78e5hmXXpUCsVXo9GgVGsI/yeK+LRsTsemcCzqXlE9eFexljGKv8pHoIAOEHPYuHzAByC3hW0zYOR6aHI/VFZ+5AGPYJhxyvSYf7wGRz+/3z6lWBHEvWtdxPUXCKomQkmtQogHbcUQH3WdzNQUnNxrsOuLT4m7eqlc5rFzn0lexnbUeVfxqN2S1LvnsHNyovWAIdQMrId/0xDkiuLjtq6dOY2kWzcI6d6bvtNeLBdZy5JcpZqkzFwycpTcSs7mp5M3+OnUTV29HBW+3CMZZxbZrGGI/BBn1EG0kEWWr2B9FkKdtrC2r/bYzg3eiCmoT7sDqTehdmvY/orWMgtCSa0CiOsvEFRNhJJahRAPWuuhVqmIjDhBRtI9crOzCAoNY/3rL6HMy9W1adqlB5GnjpOVVnxWKEvwD+lDSPdBBLaog4OLDWq1BrlcGx7rxoWzuHrVxNW7Jh+OHASAvbMLz635vkzmthYqtYbEjByW/nGJ3/+7RXaeWq9WQy/ZSR6TH+agOoTeshMESrdpKLtpdrwHZsJ28G8PWffgk5aQlwnTDmqtqKfWa9sIJbXSI66/QFA1EUpqFUI8aCsX+XFZbezskdvYILufwSfxRgxpiQn8uOitMplHkrlj6/I/JJk9Di42NO9iy/712gxbM779heXjhgBg7+TMc2s3lsmclZXMXCWX76Rz5HoiP564wZX4dPrJjvGRzSocpRzyNHJsJFX5CtF+WsFSPwgltQogrr9AUDURSmoVQjxoqxYqpZKkWzfIy8khLyebze+8iVyhQKVUlmo8G6eBSPKa5KZ+rStzqDGArKTtANg6ONH/hU+p19rbpG+rRq3myrFD+NZvhKuXd+lOqpKiUmvIzFXiYm8DuZmoz/5E4oV95DnU5GSmN4Ouvl1+k78aqQ15lZcNPz8LDfpA6GhQ5YHcBhD3blkQGRnJpEmTuHPnDnK5nCNHjuDk5GRRX3H9BYKqiVBSqxDiQVs9UKtV/LR4HtFnTuEdGIxfg0ac3vVH8R2LQ7LDznUiqtzLeAU0wcXTjtb9WuJe0xlbBzmXj+xlx6pl2Do48EL4Zp0sd6Oj8K4biExWzXO552VDUiRk3gPP+nB9D+rsVPJqt0f58wvIk6OwVxZvFTXHBmUP/qf4G4CMXu/htGcujP4e6vcU924Z0LVrVxYuXEjnzp25d+8erq6uKCzw2Qbx7BQIqipCSa1CiAdt9eXmxfOkJ93Dv1lzzu//m4SYKM7tK4Pd7pITMrk3oEGtjNYVj12ygRq1HDny03r+/WUL7YYMp/P/Jhh1z8vORmFnV6qoA1UWjQbUKog/j3LHXBRRex9ouM099tE+dg11x64Q924pOXfuHC+++CK7d+8uVX/x7BQIqiZCSa1CiAftw0f0mQhUqjwObFhHQkxUmY1r5/4ikiQ3SPFau+lo2gzqTN3mvmQkKclKu8n3c18mbODjdB07qczmrnIoc7QhrDITQW6H8mYEioPvl2iI1BwNbkvSqu29u3//ft5//31OnDhBXFwcW7du5fHHHzdos3LlSt5//33i4uJo1qwZy5Yto3PnzhaN//PPPxMeHo5arebGjRsMHz6cOXPmWCyfeHYKBFUTa9y7lq3PCAQC6rYIBSC4VUGu+tSEeJLibvHPD+uJu3yxVOPmJH9iVHbz/PfcPP89MkVdFI7dyE1dB8DxbT+RmdGWGj4yku+qeHRYA1w8ql7611KjsIPgbgWHTQbBI0/Dvevw41RIiTHf9yEhIyODli1bMnHiRIYNG2ZUv2nTJl566SVWrlzJo48+yhdffEH//v05f/48AQHazGBhYWHk5OQY9d25cyd5eXkcOHCAiIgIatasSb9+/Wjbti29e/cu93MTCAQPF8KSWkqENUBQGJVSSUJsNBf/2ceNC2dp0qkbCltblLl57An/oszmkdk0Qp1XEC9WktXA1nUM9cP8yEr5h5a9HiGwZQtS7tzG3dev1O4Bsef/4/hvW+kx4RncavqUlfjlz/G1WheBM5tAbqdVbK8VuGtUd0uqPpIkGVlS27dvT+vWrVm1apWurEmTJjz++OMsXry42DEPHz7M/Pnz+fPPPwF4/32tJfuVV16xSCbx7BQIqibCkioQVGHkCgU+QfXwCapnVFe7URPWv/FSmcyjr6ACaNRJ5CSv4Nx9Pez68d+xcWhAXtYVFI69qRcWQtf/PYqLhz3Jd26TnphAnaYhBmOc3vUHd6Ov03PSs0gybfzXH+a/AWh9YZ98a1GZyF4htLnvDtFuakFZbgb8NlOruD7E5ObmcuLECV5//XWD8j59+nDo0CGLxmjbti137twhKSkJNzc39u/fzzPPPGO2fU5OjoFVNjVVG7tYrVajVqvNdRMIBJUMa9yvQkkVCCoAn+D6vLzpN4OyrLRU4q5cIjXhLp6163DpyD+c3vl7mcyXl3UFAGXmLi4d2MWVo39iY/8oOalfAaBw6ErXMd2IPr2Thh06sfurzwCo1+YRgkLDDMZKvFENltBtnWDol9pXaioscbO2RFYhISEBlUqFj4+hZdzHx4fbt29bNIZCoWDRokV06dIFjUZDnz59GDRokNn2ixcvZv78+UblsbGxuLi4lOwEBAKB1UhLS6vwOYWSKhBYCQcXV4JbF/i3+jdrQZcxE1DY2JJ8J47oM6ewd3LmxoVzZKWnkpaYwO2rl0s1lzr3Ajm5F3THyqx9/PXVPgCu/ntYV5544zYBISrio6IK+pYwluz5/X9zbt9uBr30Og4uYjm3MlLYBUSj0ZTILaR///7079/forZvvPEGs2bN0h2npqbi7++Pv7+/WO4XCKoQ+asgFYlQUgWCSoStvXYTlIdfHTz86gDQpHN3QKtI5OVko1FriD13hozkJC4c3MOjI8fx06K3DdLClpZ9365i37erDMqyM9LJTEnm8pF/8Khdh61LFyDJZEz4cKXJRAR/fKaNUnB06ya6jZ9qVC+wHl5eXsjlciOraXx8vJF1tayws7PDzs7OqFwmkyG771oiEAgqP9a4X63+hFi5ciVBQUHY29sTFhbGgQMHimy/b98+wsLCsLe3Jzg4mM8//9yozY8//kjTpk2xs7OjadOmbN261aB+3rx5SJJk8PL19S3T8xIIyhpJkrC1d8DO0ZH6bR+hZe/+jJr/Hv5Nm/Pi+p94edNvzNq4jf8t/JCwQU/Q/7lZPDbzdZr37PvAc696eix/rV3F5nfeRJmbQ152FmtfepoPRw7ii2efIi0xgXu3bvDtay/q+mRnZBB1+iQ/zH+Du2UYsktQemxtbQkLC2PXrl0G5bt27aJjx45WkkogEAhMY1VLqiWhUPSJjIxkwIABTJ06lfXr1/PPP/8wffp0vL29daFWDh8+zMiRI3nnnXd44okn2Lp1K08++SQHDx6kffv2urGaNWtmEIxaLq/mGX4EDwWSJFGrQSNqNWikK2v4SCd6T30ejUZNQkw0do5OXD76D7UbNSU3K5OtS+ejVqlKPJcqLw+A9HuJfDl9glG9XK7gx0VvAfDNK8/Tc/J0rp88xsAZr2Bjb8+tixfwCa6Pjb196U5WYJL09HSuXr2qO46MjCQiIgIPDw8CAgKYNWsW48aNo02bNnTo0IEvv/ySmJgYpk2bZkWpBQKBwBirhqAqaSiU1157jV9//ZULFwp866ZNm8bp06c5fFjrVzdy5EhSU1P544+C1Jb9+vWjRo0afP/994DWkvrzzz8TERFRatlFGBVBdUKjVnPhn33cunwRB2dnglu3Iz05lV1ffkdOZp5BhixLadlnoMmNYG0HD8PZw5M94V9Sv+0jDJn9f+TlZKOw1S4JH9r8HT7BDajfpr1RX3OkxN8hPvo69ds8UqxvZXW/d/fu3Uv37t2Nyp966inCw8MB7QrWe++9R1xcHCEhIXz88cd06dKlQuSr7tdfIKiuPFQhqEoTCuXw4cP06dPHoKxv376sWbOGvLw8bGxsOHz4MDNnzjRqs2zZMoOyK1eu4Ofnh52dHe3bt2fRokUEBweblVeEURFUdxo/2pXGj3bVHfsA9b4IQ6PREHvhPJcPXyDq9CkykrNR510pdjxzkQouH/mHlHitT+TVf49wNyaKb1+dgUajpuu4yRz5cSMAM7//1aCfMjeX1LvxeNSuYzTmVy9MBuCxWXOo3/aRIuWq7vdrt27dKM72MH36dKZPn15BEgkEAkHpsJqSWppQKLdv3zbZXqlUkpCQQK1atcy20R+zffv2fPPNNzRs2JA7d+6wcOFCOnbsyLlz5/D09DQ5twijIniocXahYe92NOzdDgBVnprok3e4uOcqytwcVDknUCtjLRoqX0HN55tXnte93/ftGt37tbOexbGGJ21GjMHW0Yn9qz/l7tVLPDppOr6NmnLzv1Ok3rlN4579dH0uHD2ErY9fkfNbI4yKQCAQCEqO1Xf3lzQUiqn2hcuLG1M/dErz5s3p0KED9erVY926dQahUvQRYVQEAkOC6gXSbYR2SV6tnsjVf+/w376bZCSeJeXuHZRZBx9o/JS4m6TE3eTYt5m0HjCEu1e1SQxuRfxLWPee/PiaVrlt9sijuj4uLi4m/dn1sUYYFYFAIBCUHKspqaUJheLr62uyvUKh0FlAzbUpKryKk5MTzZs358oV80uYIoyKQGAemQwad/CjcQc/oC1p97JJuj2VmxfvEXU2gYTYm2jUGaiVUaiy/y3R2HeuX+WPFR/qjiNP/suOlct0xzFnI3Tvk27f4tjPm2n4SCc8/GqbkVXcrwKBQFAVsJqSqh8K5YknntCV79q1iyFDhpjs06FDB7Zt22ZQtnPnTtq0aYONjY2uza5duwz8Unfu3FlkeJWcnBwuXLhA586dH+SUBALBfVw87HHxsCegqScdhjYAIDUhixM7ook9153UxAw0qkTUypvIbOqhzNqHOi/S4vEvHS4IVXd06w+691ERJ4iKOMHJP35l+urvyu6EBAKBQFDhWHW5v7hQKG+88QY3b97km2++AbQ7+VesWMGsWbOYOnUqhw8fZs2aNbpd+wAvvvgiXbp0YenSpQwZMoRffvmF3bt3c/BgwdLj7NmzeeyxxwgICCA+Pp6FCxeSmprKU089VbEXQCB4iHD1cqD7mMZAYwCyM/K4dOQ2107Fc+tKDUCJWnkLNJkos0+iUSUgyT3QqO6WeK6s1BQAbl66QMSO3+gx8RmR/UogEAiqGFZVUkeOHEliYiILFizQhULZvn07devWBSAuLo6YmIK84UFBQWzfvp2ZM2fy2Wef4efnx/Lly3UxUgE6duzIxo0b+b//+z/mzp1LvXr12LRpk0GM1Bs3bjB69GgSEhLw9vbmkUce4ciRI7p5BQJB+WPvZEPLnv607OmPWq0hNSGLayfjOfLzdeS2TQzaqlUJKLOPoVHGoVGnWDT+to+XcPmI9sfpxX/28eyX63F0cy/r0xAIBAJBOWHVOKlVGRHrTyCoGFQqNf9svsp/e2/oyrSPrTw0qnsos0+AJtuiWK7dn5qKR71GBDVuIu5dK1FZn53Fbdoty3E1Gg1qlQpJksjOSAfA0dUNtVpF5KkT+DcNIS8nB2VuLnZOTmSmpKBW5uHo5o6tgyMKW1sykpOwc3RCg4aslBTO7fuLZl17YmNvj4OLKxqNhtM7t5OdnoZ/SEt869Un9vxZvAMCtTKo1eTlZGNjZ0/M2dPYOTkT1CqMO9eucjc6Eht7e1w8vMjNzkKSJOKuXiKkex/io66TevcOe8K/JKB5KINefBWFjS1qtYozf+1AJpNTr017FDY2RJ05hbOHJ3euXUGtUqHRaMjJSCcvJxuvgCBqN2pCelIiNnYOZKYmc+qPbSjs7Og99XmSb98iKy0V/2YtcHKvAYBKqeTezVhiz50hPekewa3acG7fX+RmZ2Fja8fNS+fp+ORYTu/cjruPL3ZOzjTv2Rd7J2ds7Oy5eGg/Hn518KzjT+KNWJxq1ODCgT0oc3PJSE5CrVLR8JFONHzkUdQqFZkpydyJvMbRnzZSq0FjGnXoTGpCPKl34wlq1Yb0e4nYOTlzcvsvKGxtqdWgMW41fXD3rYVcYcOlQ/sJCGmJRx1/NCoVkREnycnMQJmbS/R/p2jdfzBJt26izMvF2cOTy4cP4ubjS0BIS+o0DQG1hqvHj3Bw4zf0e/YlnD29uHfzBmq1ipsXz2Nr70DjR7uizM3Byb2Gdtwzpzi46VuyUlN4/NW3CG7VhqTbt8hOTyNi53bcavoQsXM7bQY+TkDzlnj41UGj1hD9XwTedYNwdHNDlZdH1OmT1Ayqh0at5uq/R6gZVI9bUdfpOuJ/FXrvCiW1lFTWB61AUN1JvJlOQmwaibcyuHzsDtnpeaiU2tinauVd1MoolFnm0ytn5+Xxf1t3invXSuQ/OxPi76BMT+PY1h+oGVSPgOYtiTx1goSYKLzrBhHUqg0KGxvcfHxR2Npx/eQx5HIFkkxOVnoq2enpZCTfI/VuPI5u7mjUalw8vbl58Rzx0dextbPHxsERZw9Prh47hL2zC561/UmIjSY7Ix0HF1fsHJ3wa9iYc/v+AqBBu47YOjoSdfokdo5ONO3SAyc3dzJSkkGj4W5MFPFR16nbvCVyhQ1Xjh0i9W48jR/tSl5ONvduxpKXk0P6vUST5+5dN4i70Zb7XgsElQlrPDuFklpKhJIqEFQuVCo1107Gc/SX69g55hJ36R9kijqolLGoso/o2gkl1brkPzsXPtEH+/sbXgUCQeXHGs9Oq8dJFQgEgrJALpfRsK0vDdv6AqBSduHWlWRuXEri5J8dUeVFo8o5C3lnrSypoGpiC+SW6/gyRS006mQTftc22Dj1RpV7CXXeNV2pwqE7SDLUebH/3969B0V1n28Af87ZGwssKxcR8IKYmBAkWgNJ1HipsT8FNYmpVuMgwd4sXlGnTTSaapxabaejjqOSMWPtdLTFcdTUGHPBNGoMKCmKIdHcGrxEQQRhucmyu+f9/UHcZgumQtA9a57PzM6w3/Pdc56z7L687Nk9C0UNg6Jav/7wYQtEmiFaPUzBowHFCnFXAEoQNE85VLUboFjgcX0ORQmCwZwEV9O7MJjiAdUGQOBxnobBfD88ztOt2woaBigmaK4vASUYqiESnpazUAyR0FxfAEoQFDUUqrEnoFgAcUM1JUBz/RuKYoWn5SygmGEKSYeihkG0eohWC63lc4i4oBpjoJr6ta4fGlrbEw80dwXEUwmDeQBEnFAUC6CogHgANRSa6zwgTojWAINlIDyuz6Ea46DABCgmiDQD4oZodYA4oRi6wWBOBhQzAA8UxQxAgWh1UNQIuJ3F8DQXtd7BSjBUQ3cYglKhKMEQzQHRrkHzXIPRMujr2zW03t9wQ1FD4XF+BNXYC4BA81wFpOXr34cTqjEWihoKwAR3cxEgzVDNrWc/0Vr+DcDl/d2qxt5QjLGACFRjNDyuMihKEFRDNKAGQTXEQPNUQzzVX/++SiBaDRTVDsUQDdFqIJ4qGMwPQjFEAuICoLU+Ljy1gKK2/uy+5PtQU0KhqCFQDJFQ1XBo2jUYTPdBc18AXB07fWBX4CupncRXUokCi4jAUXkdRW99inFZD/G56yc+r6Sa7YC0/nE3hU4AoAAi0DxXAGmBauwNd/NxaK7PYQh6pLUxgXz9B1egGGMA8UA1dIdIE0RzwGAeAECDooZCRIM1tAXXGyytt0Pr20IUpfX1GdEaIZoDihrxdWPVBM11DoohGopqbc2jWKEo/zm3rogGiBNQgtB6RooKqIbwr5uPG3Okdb2KCkUN897um+sBAKPFALfT4zNmtZlwvd6FnveHw1HZhIYaJ4wWA+59qDs8Lg0tTjcMKlB71YmWZjdUVUFdVTPCultRX3UdIkC3HsGI6h0KZ6MLzY1uNNQ043q9CxFxIbh2uRFDJvXDlbI6iCaI7d8NzfUu1Nc0Q/MIQsMtsEUE4VxpNZocTgSFmtC9tw2KqkBRFVSeq0Pcfd3gbHBB0wSaJggOM8PePRi1VxrhavbgWkUjDEYVPe8LR3CYGVCAxlonImJD4Lh6HWWnqxCfHInQCAtC7BbUVTXD2eSC1WZGfXUzInuFwmBQ8ElhOWquNCE6PgzhMcGwd7ei5koT/n3yKkxmFfHJUThXWoWQbhbYIizo1iMYdVXN0DwauvcJQ3OjC0azipqKJjTVOtH/kR6oPFcHg8mAxhonbJFBMFsNqL7U6M158cw1RPYKhcVqhNFkwLXyBkBRENUrFLH32PHVpzWoutgAU5ABqqLgWnkjTEEG2MKDcOVcHULDLWiqa4HbpaFvciQie4XC1expna8qcLtaH4NXL9aj4ZoTziYXEgZ1hy0yCI21TigKYLWZUVd1HWeOXUZs/26IiAlBRZkDtoggXLvciOv1LeiVGI6vPqnxbjs0IgiOyqbW9ThaEBEbgrAoK8q/qEVNRSNCulmgGlRExIXA49KgqArOFpTDFm5BdEIYPC0aWprdcLV44GnRUFfdjOrLDXhwVC+E2C2Ijrfh7L/O4/9mDObh/kDAJpUoMPG561837v83/lyMQSPvgbPJhYovHejRt7WpiOlnR1h3KwwGFU11Lag8X4c+AyJR/VUDDEYV5f+uRZ8BkRBN4HFrsNrMMJpVGIytDeCNDym1922EzutumC0GuN0aFAAGowpFbfthKbfLg5brHhjNKkxmA5rqWtDocCI6vu3jRUTQct0No9kAg1GFx93aAChK228/JApk/qidbFI7iX/oiAITn7v+xfufKDD547nL7wckIiIiIt1hk0pEREREusMmlYiIiIh0h00qEREREekOm1QiIiIi0h02qURERESkO2xSiYiIiEh32KQSERERke6wSSUiIiIi3WGTSkRERES6wyaViIiIiHSHTSoRERER6Q6bVCIiIiLSHTapRERERKQ7bFKJiIiISHfYpBIRERGR7rBJJSIiIiLdYZNKRERERLrDJpWIiIiIdIdNKhERERHpDptUIiIiItIdNqlEREREpDtsUomIiIhId9ikEhEREZHusEklIiIiIt1hk0pEREREusMmlYiIiIh0h00qEREREekOm1QiIiIi0h02qURERESkO2xSiYiIiEh32KQSERERke6wSSUiIiIi3WGTSkRERES6wyaViIiIiHSHTSoRERER6Q6bVCIiIiLSHTapRETUIevXr8eAAQOQlJSEBQsWQET8HYmI7kJ+b1K3bNmChIQEBAUFISUlBe+99963zj9y5AhSUlIQFBSEfv364eWXX24zZ8+ePUhKSoLFYkFSUhL27dv3nbdLRETA1atXsWnTJhQXF6O0tBTFxcU4fvy4v2MR0V3Ir03qrl27sHDhQixbtgynTp3CiBEjkJ6ejgsXLrQ7v6ysDOPHj8eIESNw6tQpvPDCC1iwYAH27NnjnVNYWIhp06YhMzMTp0+fRmZmJqZOnYoTJ050ertERPQfbrcbzc3NcLlccLlciI6O9nckIrobiR898sgjkp2d7TOWmJgoS5YsaXf+c889J4mJiT5jv/rVr2TIkCHe61OnTpW0tDSfOePGjZNnnnmm09ttj8PhEADicDhu+TZE5H93+3P3yJEjMnHiRImNjRUAsm/fvjZzNm/eLH379hWLxSIPPfSQHD16tEPb2Lhxo9hsNgkPD5elS5d26LZ3+/1PdLfyx3PXb6+ktrS0oLi4GGPHjvUZHzt2LAoKCtq9TWFhYZv548aNw7/+9S+4XK5vnXNjnZ3ZLhFRoGhsbMSgQYOwadOmdpffypGklJQUJCcnt7lcvnwZNTU1OHDgAM6dO4dLly6hoKAAR48evVO7R0TfI0Z/bbiqqgoejwc9evTwGe/RowcqKiravU1FRUW7891uN6qqqhAbG3vTOTfW2ZntAoDT6YTT6fRedzgcAIDa2lpomvY/9paI9KKurg4A7toP+6SnpyM9Pf2my9etW4ef//zn+MUvfgEA2LBhA9566y3k5uZizZo1AIDi4uKb3n737t249957ERERAQCYMGECjh8/jpEjR7Y7n7WT6O7gj9rptyb1BkVRfK6LSJux/zX/v8dvZZ0d3e6aNWvw0ksvtRmPj4+/6W2ISL+qq6tht9v9HeOOunEkacmSJT7jHTmS1Lt3bxQUFKC5uRkmkwmHDx/GrFmzbjqftZPo7nIna6ffmtSoqCgYDIY2r15WVla2eZXzhpiYmHbnG41GREZGfuucG+vszHYBYOnSpVi8eLH3em1tLeLj43HhwoWA/ENXV1eH3r174+LFiwgLC/N3nA5jfv8K5PwOhwN9+vTxvhL4fdLZI0nfNGTIEIwfPx6DBw+GqqoYM2YMnnzyyZvOZ+3UF+b3r0DO74/a6bcm1Ww2IyUlBfn5+Xj66ae94/n5+Xjqqafavc3QoUPx2muv+Yy9/fbbSE1Nhclk8s7Jz8/HokWLfOYMGzas09sFAIvFAovF0mbcbrcH3APtm8LCwpjfj5jff1TV72fg85uOHkn6b6tXr8bq1atvaS5rpz4xv38Fcv47WTv9erh/8eLFyMzMRGpqKoYOHYqtW7fiwoULyM7OBtD6H/ilS5fw17/+FQCQnZ2NTZs2YfHixfjlL3+JwsJCbNu2DX//+9+968zJycHIkSPxhz/8AU899RT+8Y9/4NChQzh27Ngtb5eI6G7U2SNJRET+4Ncmddq0aaiursaqVatQXl6O5ORkHDx40PtepfLycp9PnCYkJODgwYNYtGgRNm/ejLi4OGzcuBGTJ0/2zhk2bBjy8vKwfPlyvPjii7jnnnuwa9cuPProo7e8XSKiu1FnjyQREfmD3z84NWfOHMyZM6fdZX/5y1/ajI0aNQonT5781nVOmTIFU6ZM6fR2b4XFYsGKFSvaPYwVCJjfv5jffwI5+61oaGjAF1984b1eVlaGkpISREREoE+fPn4/khTo9z/z+xfz+48/sityt56HhYjoe+jw4cMYPXp0m/GsrCzvP/5btmzBH//4R++RpPXr19/0FFJERP7CJpWIiIiIdOf7+/FWIiIiItItNqlEREREpDtsUjtpy5YtSEhIQFBQEFJSUvDee+/5OxLWrFmDhx9+GDabDdHR0Zg0aRI+/fRTnzkigpUrVyIuLg5WqxU//OEP8fHHH/vMcTqdmD9/PqKiohASEoInn3wSX3311Z3cFaxZswaKomDhwoUBk/3SpUuYMWMGIiMjERwcjB/84Ac+Xy+p5/xutxvLly9HQkICrFYr+vXrh1WrVvl8baWe8h89ehRPPPEE4uLioCgKXn31VZ/lXZW1pqYGmZmZsNvtsNvtyMzMRG1tbZfvz/eFHusmwNrp7+ysnaydNyXUYXl5eWIymeSVV16RM2fOSE5OjoSEhMj58+f9mmvcuHGyfft2+eijj6SkpEQmTJggffr0kYaGBu+ctWvXis1mkz179khpaalMmzZNYmNjpa6uzjsnOztbevbsKfn5+XLy5EkZPXq0DBo0SNxu9x3Zj6KiIunbt68MHDhQcnJyAiL7tWvXJD4+XmbOnCknTpyQsrIyOXTokHzxxRcBkf93v/udREZGyoEDB6SsrEx2794toaGhsmHDBl3mP3jwoCxbtkz27NkjAGTfvn0+y7sqa1pamiQnJ0tBQYEUFBRIcnKyTJw4sUv35ftCr3VThLXTn9lZO+9s/kCrnWxSO+GRRx6R7Oxsn7HExERZsmSJnxK1r7KyUgDIkSNHRERE0zSJiYmRtWvXeuc0NzeL3W6Xl19+WUREamtrxWQySV5ennfOpUuXRFVVefPNN2975vr6eunfv7/k5+fLqFGjvIVW79mff/55GT58+E2X6z3/hAkT5Gc/+5nP2I9//GOZMWOG7vP/d6HtqqxnzpwRAHL8+HHvnMLCQgEgn3zyyW3bn7tVoNRNEdbOO5mdtZO189vwcH8HtbS0oLi4GGPHjvUZHzt2LAoKCvyUqn0OhwMAvN+zW1ZWhoqKCp/sFosFo0aN8mYvLi6Gy+XymRMXF4fk5OQ7sn9z587FhAkT8KMf/chnXO/Z9+/fj9TUVPzkJz9BdHQ0Bg8ejFdeeSVg8g8fPhzvvPMOPvvsMwDA6dOncezYMYwfPz4g8n9TV2UtLCyE3W73+SKQIUOGwG636+65rneBVDcB1s47mZ210/+PnRv0WDv9fjL/QFNVVQWPx9PmKwR79OjR5qsG/UlEsHjxYgwfPhzJyckA4M3XXvbz589755jNZoSHh7eZc7v3Ly8vDydPnsQHH3zQZpnes3/55ZfIzc3F4sWL8cILL6CoqAgLFiyAxWLBs88+q/v8zz//PBwOBxITE2EwGODxeLB69WpMnz7dm03P+b+pq7JWVFQgOjq6zfqjo6N19VwPBIFSNwHWzv+ew9r57Vg7/zPndtRONqmdpCiKz3URaTPmT/PmzcOHH36IY8eOtVnWmey3e/8uXryInJwcvP322wgKCrrpPD1mBwBN05Camorf//73AIDBgwfj448/Rm5uLp599lnvPL3m37VrF3bs2IG//e1vGDBgAEpKSrBw4ULExcUhKyvLO0+v+dvTFVnbm6+353og0XvdBFg7Ozrnu2LtvDnWTn66v8OioqJgMBja/DdQWVnZ5r8Pf5k/fz7279+Pd999F7169fKOx8TEAMC3Zo+JiUFLSwtqampuOud2KC4uRmVlJVJSUmA0GmE0GnHkyBFs3LgRRqPRu209ZgeA2NhYJCUl+Yw98MADuHDhgjcboN/8v/nNb7BkyRI888wzePDBB5GZmYlFixZhzZo1AZH/m7oqa0xMDK5cudJm/VevXtXNcz1QBELdBFg7WTs7jrWz/TldVTvZpHaQ2WxGSkoK8vPzfcbz8/MxbNgwP6VqJSKYN28e9u7di3/+859ISEjwWZ6QkICYmBif7C0tLThy5Ig3e0pKCkwmk8+c8vJyfPTRR7d1/8aMGYPS0lKUlJR4L6mpqcjIyEBJSQn69eun2+wA8Nhjj7U5Zc1nn32G+Ph4APq+7wGgqakJqupbDgwGg/c0KnrP/01dlXXo0KFwOBwoKiryzjlx4gQcDoffn+uBRs91E2DtZO3sPNbO21w7O/QxKxKR/5xKZdu2bXLmzBlZuHChhISEyLlz5/yaa/bs2WK32+Xw4cNSXl7uvTQ1NXnnrF27Vux2u+zdu1dKS0tl+vTp7Z5eolevXnLo0CE5efKkPP7443f0NCo3fPMTqnrPXlRUJEajUVavXi2ff/657Ny5U4KDg2XHjh0BkT8rK0t69uzpPY3K3r17JSoqSp577jld5q+vr5dTp07JqVOnBICsW7dOTp065T2dUVdlTUtLk4EDB0phYaEUFhbKgw8+yFNQdZJe66YIa6c/s7N23tn8gVY72aR20ubNmyU+Pl7MZrM89NBD3lOV+BOAdi/bt2/3ztE0TVasWCExMTFisVhk5MiRUlpa6rOe69evy7x58yQiIkKsVqtMnDhRLly4cIf3pm2h1Xv21157TZKTk8VisUhiYqJs3brVZ7me89fV1UlOTo706dNHgoKCpF+/frJs2TJxOp26zP/uu++2+1jPysrq0qzV1dWSkZEhNptNbDabZGRkSE1NTZfvz/eFHuumCGunCGtnZ7F23t7aqYiIdOy1VyIiIiKi24vvSSUiIiIi3WGTSkRERES6wyaViIiIiHSHTSoRERER6Q6bVCIiIiLSHTapRERERKQ7bFKJiIiISHfYpBIRERGR7rBJJfoOFEXBq6++6u8YREQBhbWTbgWbVApYM2fOhKIobS5paWn+jkZEpFusnRQojP4OQPRdpKWlYfv27T5jFovFT2mIiAIDaycFAr6SSgHNYrEgJibG5xIeHg6g9XBSbm4u0tPTYbVakZCQgN27d/vcvrS0FI8//jisVisiIyMxa9YsNDQ0+Mz585//jAEDBsBisSA2Nhbz5s3zWV5VVYWnn34awcHB6N+/P/bv3+9dVlNTg4yMDHTv3h1WqxX9+/dv84eBiOhOY+2kQMAmle5qL774IiZPnozTp09jxowZmD59Os6ePQsAaGpqQlpaGsLDw/HBBx9g9+7dOHTokE8hzc3Nxdy5czFr1iyUlpZi//79uPfee3228dJLL2Hq1Kn48MMPMX78eGRkZODatWve7Z85cwZvvPEGzp49i9zcXERFRd25O4CIqBNYO0kXhChAZWVlicFgkJCQEJ/LqlWrREQEgGRnZ/vc5tFHH5XZs2eLiMjWrVslPDxcGhoavMtff/11UVVVKioqREQkLi5Oli1bdtMMAGT58uXe6w0NDaIoirzxxhsiIvLEE0/IT3/6067ZYSKiLsDaSYGC70mlgDZ69Gjk5ub6jEVERHh/Hjp0qM+yoUOHoqSkBABw9uxZDBo0CCEhId7ljz32GDRNw6effgpFUXD58mWMGTPmWzMMHDjQ+3NISAhsNhsqKysBALNnz8bkyZNx8uRJjB07FpMmTcKwYcM6ta9ERF2FtZMCAZtUCmghISFtDiH9L4qiAABExPtze3OsVustrc9kMrW5raZpAID09HScP38er7/+Og4dOoQxY8Zg7ty5+NOf/tShzEREXYm1kwIB35NKd7Xjx4+3uZ6YmAgASEpKQklJCRobG73L33//faiqivvuuw82mw19+/bFO++8850ydO/eHTNnzsSOHTuwYcMGbN269Tutj4jodmPtJD3gK6kU0JxOJyoqKnzGjEaj9w32u3fvRmpqKoYPH46dO3eiqKgI27ZtAwBkZGRgxYoVyMrKwsqVK3H16lXMnz8fmZmZ6NGjBwBg5cqVyM7ORnR0NNLT01FfX4/3338f8+fPv6V8v/3tb5GSkoIBAwbA6XTiwIEDeOCBB7rwHiAi6jjWTgoEbFIpoL355puIjY31Gbv//vvxySefAGj99GheXh7mzJmDmJgY7Ny5E0lJSQCA4OBgvPXWW8jJycHDDz+M4OBgTJ48GevWrfOuKysrC83NzVi/fj1+/etfIyoqClOmTLnlfGazGUuXLsW5c+dgtVoxYsQI5OXldcGeExF1HmsnBQJFRMTfIYhuB0VRsG/fPkyaNMnfUYiIAgZrJ+kF35NKRERERLrDJpWIiIiIdIeH+4mIiIhId/hKKhERERHpDptUIiIiItIdNqlEREREpDtsUomIiIhId9ikEhEREZHusEklIiIiIt1hk0pEREREusMmlYiIiIh0h00qEREREenO/wMdYo11UguS2wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 700x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the figure here is not the same as the one in the paper\n",
    "# the figure in the paper is the average result of 10 runs\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(1, 2, figsize=(7, 3))\n",
    "axs[0].plot(np.sqrt(NN_train_losses), label='NN_train')\n",
    "axs[0].plot(np.sqrt(NN_val_losses), label='NN_val')\n",
    "\n",
    "axs[0].plot(np.sqrt(PINN_train_losses), label='PINN_train')\n",
    "axs[0].plot(np.sqrt(PINN_val_losses), label='PINN_val')\n",
    "\n",
    "axs[0].plot(np.sqrt(NNOPT_train_losses), label='KKT-hPINN_train')\n",
    "axs[0].plot(np.sqrt(NNOPT_val_losses), label='KKT-hPINN_val')\n",
    "\n",
    "axs[0].grid(True, alpha=0.4, linestyle='-', axis='y')\n",
    "axs[0].set_xlabel('Epochs')\n",
    "axs[0].set_ylabel('RMSE')\n",
    "axs[0].set_xlim(0, 1000)\n",
    "axs[0].set_ylim(0, 2e-2)\n",
    "axs[0].legend(frameon=False, prop={'size': 8})\n",
    "\n",
    "\n",
    "axs[1].plot(NN_train_violations, label='NN_train')\n",
    "axs[1].plot(NN_val_violations, label='NN_val')\n",
    "\n",
    "axs[1].plot(PINN_train_violations, label='PINN_train')\n",
    "axs[1].plot(PINN_val_violations, label='PINN_val')\n",
    "\n",
    "axs[1].plot(NNOPT_train_violations, label='KKT-hPINN_train')\n",
    "axs[1].plot(NNOPT_val_violations, label='KKT-hPINN_val')\n",
    "\n",
    "axs[1].set_yscale('log')\n",
    "axs[1].grid(True, alpha=0.4, linestyle='-', axis='y')\n",
    "axs[1].set_xlabel('Epochs')\n",
    "axs[1].set_ylabel('Violation')\n",
    "axs[1].set_xlim(0, 1000)\n",
    "axs[1].set_ylim(1e-8, 1e-1)\n",
    "# axs[1].legend(frameon=False, prop={'size': 8})\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "XAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
